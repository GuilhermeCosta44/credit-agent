{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25664905-52aa-4d32-8675-2636da631c38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c88021d-f606-40cb-adab-52870f8e1dd1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %pip install scikit-learn==1.4.1.post1\n",
    "# !pip install --upgrade optbinning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56117a4c-1292-47e5-b389-895607339d7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nLooking in indexes: https://svc_nexus_data_pipeline%40picpay.com:****@nexus-prod.limbo.work/repository/picpay-pypi-hosted/simple, https://pypi.org/simple/\nCollecting optbinning\n  Using cached optbinning-0.20.1-py3-none-any.whl (213 kB)\nCollecting ortools<9.12,>=9.4\n  Using cached ortools-9.11.4210-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28.1 MB)\nRequirement already satisfied: numpy>=1.16.1 in /databricks/python3/lib/python3.10/site-packages (from optbinning) (1.23.5)\nRequirement already satisfied: scikit-learn>=1.0.2 in /databricks/python3/lib/python3.10/site-packages (from optbinning) (1.1.1)\nCollecting ropwr>=1.0.0\n  Using cached ropwr-1.1.0-py3-none-any.whl (17 kB)\nRequirement already satisfied: matplotlib in /databricks/python3/lib/python3.10/site-packages (from optbinning) (3.7.0)\nRequirement already satisfied: scipy>=1.6.0 in /databricks/python3/lib/python3.10/site-packages (from optbinning) (1.10.0)\nRequirement already satisfied: pandas in /databricks/python3/lib/python3.10/site-packages (from optbinning) (1.5.3)\nCollecting pandas\n  Using cached pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.8 MB)\nCollecting immutabledict>=3.0.0\n  Using cached immutabledict-4.2.2-py3-none-any.whl (4.7 kB)\nCollecting absl-py>=2.0.0\n  Using cached absl_py-2.3.1-py3-none-any.whl (135 kB)\nCollecting protobuf<5.27,>=5.26.1\n  Using cached protobuf-5.26.1-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\nCollecting tzdata>=2022.7\n  Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.10/site-packages (from pandas->optbinning) (2022.7)\nRequirement already satisfied: python-dateutil>=2.8.2 in /databricks/python3/lib/python3.10/site-packages (from pandas->optbinning) (2.8.2)\nCollecting cvxpy>=1.1.14\n  Using cached cvxpy-1.7.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (1.2 MB)\nRequirement already satisfied: joblib>=1.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn>=1.0.2->optbinning) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn>=1.0.2->optbinning) (2.2.0)\nRequirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.10/site-packages (from matplotlib->optbinning) (23.2)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.10/site-packages (from matplotlib->optbinning) (0.11.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib->optbinning) (1.4.4)\nRequirement already satisfied: pyparsing>=2.3.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib->optbinning) (3.0.9)\nRequirement already satisfied: contourpy>=1.0.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib->optbinning) (1.0.5)\nRequirement already satisfied: pillow>=6.2.0 in /databricks/python3/lib/python3.10/site-packages (from matplotlib->optbinning) (9.4.0)\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.10/site-packages (from matplotlib->optbinning) (4.25.0)\nCollecting clarabel>=0.5.0\n  Using cached clarabel-0.11.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\nCollecting osqp>=1.0.0\n  Using cached osqp-1.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (355 kB)\nCollecting scipy>=1.6.0\n  Using cached scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\nCollecting scs>=3.2.4.post1\n  Using cached scs-3.2.9-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (12.1 MB)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->optbinning) (1.16.0)\nRequirement already satisfied: cffi in /databricks/python3/lib/python3.10/site-packages (from clarabel>=0.5.0->cvxpy>=1.1.14->ropwr>=1.0.0->optbinning) (1.15.1)\nRequirement already satisfied: setuptools in /databricks/python3/lib/python3.10/site-packages (from osqp>=1.0.0->cvxpy>=1.1.14->ropwr>=1.0.0->optbinning) (65.6.3)\nRequirement already satisfied: jinja2 in /databricks/python3/lib/python3.10/site-packages (from osqp>=1.0.0->cvxpy>=1.1.14->ropwr>=1.0.0->optbinning) (3.1.2)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.10/site-packages (from cffi->clarabel>=0.5.0->cvxpy>=1.1.14->ropwr>=1.0.0->optbinning) (2.21)\nRequirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.10/site-packages (from jinja2->osqp>=1.0.0->cvxpy>=1.1.14->ropwr>=1.0.0->optbinning) (2.1.1)\nInstalling collected packages: tzdata, scipy, protobuf, immutabledict, absl-py, scs, pandas, osqp, clarabel, ortools, cvxpy, ropwr, optbinning\n  Attempting uninstall: scipy\n    Found existing installation: scipy 1.10.0\n    Not uninstalling scipy at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e0c4b62-89a3-4d15-b24e-66337b21928f\n    Can't uninstall 'scipy'. No files were found to uninstall.\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 4.24.0\n    Not uninstalling protobuf at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e0c4b62-89a3-4d15-b24e-66337b21928f\n    Can't uninstall 'protobuf'. No files were found to uninstall.\n  Attempting uninstall: absl-py\n    Found existing installation: absl-py 1.0.0\n    Not uninstalling absl-py at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e0c4b62-89a3-4d15-b24e-66337b21928f\n    Can't uninstall 'absl-py'. No files were found to uninstall.\n  Attempting uninstall: pandas\n    Found existing installation: pandas 1.5.3\n    Not uninstalling pandas at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e0c4b62-89a3-4d15-b24e-66337b21928f\n    Can't uninstall 'pandas'. No files were found to uninstall.\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npetastorm 0.12.1 requires pyspark>=2.1.0, which is not installed.\ndatabricks-feature-engineering 0.2.1 requires pyspark<4,>=3.1.2, which is not installed.\nydata-profiling 4.2.0 requires pandas!=1.4.0,<2,>1.1, but you have pandas 2.3.3 which is incompatible.\nydata-profiling 4.2.0 requires scipy<1.11,>=1.4.1, but you have scipy 1.15.3 which is incompatible.\ntensorflow-cpu 2.14.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.26.1 which is incompatible.\ntensorboard-plugin-profile 2.14.0 requires protobuf<5.0.0dev,>=3.19.6, but you have protobuf 5.26.1 which is incompatible.\nmlflow-skinny 2.9.2 requires protobuf<5,>=3.12.0, but you have protobuf 5.26.1 which is incompatible.\ngoogleapis-common-protos 1.62.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\ngoogle-api-core 2.15.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\ndatabricks-feature-engineering 0.2.1 requires protobuf<5,>=3.12.0, but you have protobuf 5.26.1 which is incompatible.\nSuccessfully installed absl-py-2.3.1 clarabel-0.11.1 cvxpy-1.7.3 immutabledict-4.2.2 optbinning-0.20.1 ortools-9.11.4210 osqp-1.0.5 pandas-2.3.3 protobuf-5.26.1 ropwr-1.1.0 scipy-1.15.3 scs-3.2.9 tzdata-2025.2\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nLooking in indexes: https://svc_nexus_data_pipeline%40picpay.com:****@nexus-prod.limbo.work/repository/picpay-pypi-hosted/simple, https://pypi.org/simple/\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.10/site-packages (4.64.1)\nCollecting tqdm\n  Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\nInstalling collected packages: tqdm\n  Attempting uninstall: tqdm\n    Found existing installation: tqdm 4.64.1\n    Not uninstalling tqdm at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e0c4b62-89a3-4d15-b24e-66337b21928f\n    Can't uninstall 'tqdm'. No files were found to uninstall.\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nydata-profiling 4.2.0 requires pandas!=1.4.0,<2,>1.1, but you have pandas 2.3.3 which is incompatible.\nydata-profiling 4.2.0 requires scipy<1.11,>=1.4.1, but you have scipy 1.15.3 which is incompatible.\nSuccessfully installed tqdm-4.67.1\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nLooking in indexes: https://svc_nexus_data_pipeline%40picpay.com:****@nexus-prod.limbo.work/repository/picpay-pypi-hosted/simple, https://pypi.org/simple/\nCollecting mlflow==2.11.2\n  Using cached mlflow-2.11.2-py3-none-any.whl (19.7 MB)\nRequirement already satisfied: pyyaml<7,>=5.1 in /databricks/python3/lib/python3.10/site-packages (from mlflow==2.11.2) (6.0)\nRequirement already satisfied: scikit-learn<2 in /databricks/python3/lib/python3.10/site-packages (from mlflow==2.11.2) (1.1.1)\nRequirement already satisfied: markdown<4,>=3.3 in /databricks/python3/lib/python3.10/site-packages (from mlflow==2.11.2) (3.4.1)\nRequirement already satisfied: requests<3,>=2.17.3 in /databricks/python3/lib/python3.10/site-packages (from mlflow==2.11.2) (2.28.1)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /databricks/python3/lib/python3.10/site-packages (from mlflow==2.11.2) (3.1.27)\nRequirement already satisfied: numpy<2 in /databricks/python3/lib/python3.10/site-packages (from mlflow==2.11.2) (1.23.5)\nRequirement already satisfied: cloudpickle<4 in /databricks/python3/lib/python3.10/site-packages (from mlflow==2.11.2) (2.0.0)\nRequirement already satisfied: pytz<2025 in /databricks/python3/lib/python3.10/site-packages (from mlflow==2.11.2) (2022.7)\nRequirement already satisfied: entrypoints<1 in /databricks/python3/lib/python3.10/site-packages (from mlflow==2.11.2) (0.4)\nCollecting protobuf<5,>=3.12.0\n  Using cached protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\nRequirement already satisfied: pyarrow<16,>=4.0.0 in /databricks/python3/lib/python3.10/site-packages (from mlflow==2.11.2) (8.0.0)\nRequirement already satisfied: scipy<2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e0c4b62-89a3-4d15-b24e-66337b21928f/lib/python3.10/site-packages (from mlflow==2.11.2) (1.15.3)\nRequirement already satisfied: pandas<3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e0c4b62-89a3-4d15-b24e-66337b21928f/lib/python3.10/site-packages (from mlflow==2.11.2) (2.3.3)\nRequirement already satisfied: matplotlib<4 in /databricks/python3/lib/python3.10/site-packages (from mlflow==2.11.2) (3.7.0)\nCollecting alembic!=1.10.0,<2\n  Using cached alembic-1.17.0-py3-none-any.whl (247 kB)\nRequirement already satisfied: Flask<4 in /databricks/python3/lib/python3.10/site-packages (from mlflow==2.11.2) (2.2.5)\nCollecting querystring-parser<2\n  Using cached querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\nRequirement already satisfied: sqlalchemy<3,>=1.4.0 in /databricks/python3/lib/python3.10/site-packages (from mlflow==2.11.2) (1.4.39)\nRequirement already satisfied: Jinja2<4,>=2.11 in /databricks/python3/lib/python3.10/site-packages (from mlflow==2.11.2) (3.1.2)\nRequirement already satisfied: packaging<24 in /databricks/python3/lib/python3.10/site-packages (from mlflow==2.11.2) (23.2)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /databricks/python3/lib/python3.10/site-packages (from mlflow==2.11.2) (0.4.2)\nRequirement already satisfied: click<9,>=7.0 in /databricks/python3/lib/python3.10/site-packages (from mlflow==2.11.2) (8.0.4)\nRequirement already satisfied: gunicorn<22 in /databricks/python3/lib/python3.10/site-packages (from mlflow==2.11.2) (20.1.0)\nCollecting docker<8,>=4.0.0\n  Using cached docker-7.1.0-py3-none-any.whl (147 kB)\nCollecting graphene<4\n  Using cached graphene-3.4.3-py2.py3-none-any.whl (114 kB)\nRequirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /databricks/python3/lib/python3.10/site-packages (from mlflow==2.11.2) (4.11.3)\nCollecting typing-extensions>=4.12\n  Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\nRequirement already satisfied: Mako in /databricks/python3/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow==2.11.2) (1.2.0)\nRequirement already satisfied: tomli in /databricks/python3/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow==2.11.2) (2.0.1)\nRequirement already satisfied: urllib3>=1.26.0 in /databricks/python3/lib/python3.10/site-packages (from docker<8,>=4.0.0->mlflow==2.11.2) (1.26.14)\nRequirement already satisfied: Werkzeug>=2.2.2 in /databricks/python3/lib/python3.10/site-packages (from Flask<4->mlflow==2.11.2) (2.2.2)\nRequirement already satisfied: itsdangerous>=2.0 in /databricks/python3/lib/python3.10/site-packages (from Flask<4->mlflow==2.11.2) (2.0.1)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /databricks/python3/lib/python3.10/site-packages (from gitpython<4,>=3.1.9->mlflow==2.11.2) (4.0.11)\nCollecting graphql-core<3.3,>=3.1\n  Using cached graphql_core-3.2.6-py3-none-any.whl (203 kB)\nRequirement already satisfied: python-dateutil<3,>=2.7.0 in /databricks/python3/lib/python3.10/site-packages (from graphene<4->mlflow==2.11.2) (2.8.2)\nCollecting graphql-relay<3.3,>=3.1\n  Using cached graphql_relay-3.2.0-py3-none-any.whl (16 kB)\nRequirement already satisfied: setuptools>=3.0 in /databricks/python3/lib/python3.10/site-packages (from gunicorn<22->mlflow==2.11.2) (65.6.3)\nRequirement already satisfied: zipp>=0.5 in /databricks/python3/lib/python3.10/site-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow==2.11.2) (3.11.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.10/site-packages (from Jinja2<4,>=2.11->mlflow==2.11.2) (2.1.1)\nRequirement already satisfied: pillow>=6.2.0 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.11.2) (9.4.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.11.2) (1.4.4)\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.11.2) (4.25.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.11.2) (3.0.9)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.11.2) (0.11.0)\nRequirement already satisfied: contourpy>=1.0.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.11.2) (1.0.5)\nRequirement already satisfied: tzdata>=2022.7 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e0c4b62-89a3-4d15-b24e-66337b21928f/lib/python3.10/site-packages (from pandas<3->mlflow==2.11.2) (2025.2)\nRequirement already satisfied: six in /usr/lib/python3/dist-packages (from querystring-parser<2->mlflow==2.11.2) (1.16.0)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow==2.11.2) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow==2.11.2) (3.4)\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow==2.11.2) (2.0.4)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn<2->mlflow==2.11.2) (2.2.0)\nRequirement already satisfied: joblib>=1.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn<2->mlflow==2.11.2) (1.2.0)\nRequirement already satisfied: greenlet!=0.4.17 in /databricks/python3/lib/python3.10/site-packages (from sqlalchemy<3,>=1.4.0->mlflow==2.11.2) (2.0.1)\nRequirement already satisfied: smmap<6,>=3.0.1 in /databricks/python3/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow==2.11.2) (5.0.0)\nInstalling collected packages: typing-extensions, querystring-parser, protobuf, graphql-core, graphql-relay, docker, alembic, graphene, mlflow\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.4.0\n    Not uninstalling typing-extensions at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e0c4b62-89a3-4d15-b24e-66337b21928f\n    Can't uninstall 'typing_extensions'. No files were found to uninstall.\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 5.26.1\n    Uninstalling protobuf-5.26.1:\n      Successfully uninstalled protobuf-5.26.1\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatabricks-feature-engineering 0.2.1 requires pyspark<4,>=3.1.2, which is not installed.\nortools 9.11.4210 requires protobuf<5.27,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\nSuccessfully installed alembic-1.17.0 docker-7.1.0 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 mlflow-2.11.2 protobuf-4.25.8 querystring-parser-1.2.4 typing-extensions-4.15.0\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nLooking in indexes: https://svc_nexus_data_pipeline%40picpay.com:****@nexus-prod.limbo.work/repository/picpay-pypi-hosted/simple, https://pypi.org/simple/\nRequirement already satisfied: shap in /databricks/python3/lib/python3.10/site-packages (0.44.0)\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.10/site-packages (from shap) (1.23.5)\nRequirement already satisfied: pandas in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e0c4b62-89a3-4d15-b24e-66337b21928f/lib/python3.10/site-packages (from shap) (2.3.3)\nRequirement already satisfied: scikit-learn in /databricks/python3/lib/python3.10/site-packages (from shap) (1.1.1)\nRequirement already satisfied: cloudpickle in /databricks/python3/lib/python3.10/site-packages (from shap) (2.0.0)\nRequirement already satisfied: packaging>20.9 in /databricks/python3/lib/python3.10/site-packages (from shap) (23.2)\nRequirement already satisfied: tqdm>=4.27.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e0c4b62-89a3-4d15-b24e-66337b21928f/lib/python3.10/site-packages (from shap) (4.67.1)\nRequirement already satisfied: scipy in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e0c4b62-89a3-4d15-b24e-66337b21928f/lib/python3.10/site-packages (from shap) (1.15.3)\nRequirement already satisfied: slicer==0.0.7 in /databricks/python3/lib/python3.10/site-packages (from shap) (0.0.7)\nRequirement already satisfied: numba in /databricks/python3/lib/python3.10/site-packages (from shap) (0.56.4)\nRequirement already satisfied: setuptools in /databricks/python3/lib/python3.10/site-packages (from numba->shap) (65.6.3)\nRequirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /databricks/python3/lib/python3.10/site-packages (from numba->shap) (0.39.1)\nRequirement already satisfied: tzdata>=2022.7 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e0c4b62-89a3-4d15-b24e-66337b21928f/lib/python3.10/site-packages (from pandas->shap) (2025.2)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.10/site-packages (from pandas->shap) (2022.7)\nRequirement already satisfied: python-dateutil>=2.8.2 in /databricks/python3/lib/python3.10/site-packages (from pandas->shap) (2.8.2)\nRequirement already satisfied: joblib>=1.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn->shap) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn->shap) (2.2.0)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nLooking in indexes: https://svc_nexus_data_pipeline%40picpay.com:****@nexus-prod.limbo.work/repository/picpay-pypi-hosted/simple, https://pypi.org/simple/\nCollecting optuna\n  Using cached optuna-4.5.0-py3-none-any.whl (400 kB)\nRequirement already satisfied: sqlalchemy>=1.4.2 in /databricks/python3/lib/python3.10/site-packages (from optuna) (1.4.39)\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.10/site-packages (from optuna) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.10/site-packages (from optuna) (23.2)\nRequirement already satisfied: tqdm in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e0c4b62-89a3-4d15-b24e-66337b21928f/lib/python3.10/site-packages (from optuna) (4.67.1)\nCollecting colorlog\n  Using cached colorlog-6.10.1-py3-none-any.whl (11 kB)\nRequirement already satisfied: alembic>=1.5.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e0c4b62-89a3-4d15-b24e-66337b21928f/lib/python3.10/site-packages (from optuna) (1.17.0)\nRequirement already satisfied: PyYAML in /databricks/python3/lib/python3.10/site-packages (from optuna) (6.0)\nRequirement already satisfied: tomli in /databricks/python3/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (2.0.1)\nRequirement already satisfied: typing-extensions>=4.12 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e0c4b62-89a3-4d15-b24e-66337b21928f/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.15.0)\nRequirement already satisfied: Mako in /databricks/python3/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.2.0)\nRequirement already satisfied: greenlet!=0.4.17 in /databricks/python3/lib/python3.10/site-packages (from sqlalchemy>=1.4.2->optuna) (2.0.1)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /databricks/python3/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.1)\nInstalling collected packages: colorlog, optuna\nSuccessfully installed colorlog-6.10.1 optuna-4.5.0\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nLooking in indexes: https://svc_nexus_data_pipeline%40picpay.com:****@nexus-prod.limbo.work/repository/picpay-pypi-hosted/simple, https://pypi.org/simple/\nCollecting optuna-integration\n  Using cached optuna_integration-4.5.0-py3-none-any.whl (99 kB)\nRequirement already satisfied: optuna in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e0c4b62-89a3-4d15-b24e-66337b21928f/lib/python3.10/site-packages (from optuna-integration) (4.5.0)\nRequirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.10/site-packages (from optuna->optuna-integration) (23.2)\nRequirement already satisfied: tqdm in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e0c4b62-89a3-4d15-b24e-66337b21928f/lib/python3.10/site-packages (from optuna->optuna-integration) (4.67.1)\nRequirement already satisfied: PyYAML in /databricks/python3/lib/python3.10/site-packages (from optuna->optuna-integration) (6.0)\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.10/site-packages (from optuna->optuna-integration) (1.23.5)\nRequirement already satisfied: colorlog in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e0c4b62-89a3-4d15-b24e-66337b21928f/lib/python3.10/site-packages (from optuna->optuna-integration) (6.10.1)\nRequirement already satisfied: alembic>=1.5.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e0c4b62-89a3-4d15-b24e-66337b21928f/lib/python3.10/site-packages (from optuna->optuna-integration) (1.17.0)\nRequirement already satisfied: sqlalchemy>=1.4.2 in /databricks/python3/lib/python3.10/site-packages (from optuna->optuna-integration) (1.4.39)\nRequirement already satisfied: Mako in /databricks/python3/lib/python3.10/site-packages (from alembic>=1.5.0->optuna->optuna-integration) (1.2.0)\nRequirement already satisfied: typing-extensions>=4.12 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e0c4b62-89a3-4d15-b24e-66337b21928f/lib/python3.10/site-packages (from alembic>=1.5.0->optuna->optuna-integration) (4.15.0)\nRequirement already satisfied: tomli in /databricks/python3/lib/python3.10/site-packages (from alembic>=1.5.0->optuna->optuna-integration) (2.0.1)\nRequirement already satisfied: greenlet!=0.4.17 in /databricks/python3/lib/python3.10/site-packages (from sqlalchemy>=1.4.2->optuna->optuna-integration) (2.0.1)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /databricks/python3/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna->optuna-integration) (2.1.1)\nInstalling collected packages: optuna-integration\nSuccessfully installed optuna-integration-4.5.0\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nLooking in indexes: https://svc_nexus_data_pipeline%40picpay.com:****@nexus-prod.limbo.work/repository/picpay-pypi-hosted/simple, https://pypi.org/simple/\nRequirement already satisfied: lightgbm in /databricks/python3/lib/python3.10/site-packages (4.1.0)\nRequirement already satisfied: scipy in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e0c4b62-89a3-4d15-b24e-66337b21928f/lib/python3.10/site-packages (from lightgbm) (1.15.3)\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.10/site-packages (from lightgbm) (1.23.5)\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "#Pacotes de instalação\n",
    "\n",
    "!pip install --upgrade optbinning\n",
    "!pip install --upgrade tqdm\n",
    "!pip install mlflow==2.11.2\n",
    "!pip install shap\n",
    "!pip install optuna\n",
    "!pip install optuna-integration\n",
    "!pip install lightgbm\n",
    "!pip install xgboost\n",
    "!pip install catboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db0a2151-059b-43bd-a55e-33c8d636d234",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc459068-a4a2-4ef8-bd6e-65168171e6ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CVXPY) Jan 14 05:25:05 PM: Encountered unexpected exception importing solver GLOP:\nRuntimeError('Unrecognized new version of ortools (9.11.4210). Expected < 9.10.0. Please open a feature request on cvxpy to enable support for this version.')\n(CVXPY) Jan 14 05:25:05 PM: Encountered unexpected exception importing solver PDLP:\nRuntimeError('Unrecognized new version of ortools (9.11.4210). Expected < 9.10.0. Please open a feature request on cvxpy to enable support for this version.')\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as f\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from pyspark.sql.types import IntegerType, DoubleType, FloatType, StringType, StructField, StructType, BooleanType, NumericType\n",
    "import numpy as np\n",
    "from scipy.stats import ks_2samp, chi2_contingency\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import DataFrame\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from pyspark.ml.feature import Bucketizer\n",
    "from datetime import datetime\n",
    "# from pyspark.sql.functions import col, sum as spark_sum\n",
    "from optbinning import BinningProcess\n",
    "import re\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import ModelSignature, infer_signature\n",
    "import shap\n",
    "import optuna\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import json\n",
    "import matplotlib.font_manager as fm\n",
    "import os\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 600)\n",
    "pd.set_option('display.max_columns', 600)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71bf3661-e3eb-453f-8cf6-9a365071447b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Funções"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "351cdda2-9bcc-4af2-aa5a-6a1285af5126",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a93875ee-477f-4102-993e-fe65bc2f456e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculando o Gini com inversão do score - função auxiliar\n",
    "def calculate_auc(group, score, target):\n",
    "        # Invertendo o score\n",
    "        # Calculando o AUC\n",
    "        auc = roc_auc_score(group[target], group[score])\n",
    "        # Corrigindo o AUC se for menor que 0.5\n",
    "        if auc < 0.5:\n",
    "            auc = 1 - auc\n",
    "        return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "067739dd-3751-4608-9925-d50e8beb2d14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_ks2_metric(data_spark, score, target, segment):\n",
    "\n",
    "    \"\"\"\n",
    "    Calcula a métrica KS2 (Kolmogorov-Smirnov) para um conjunto de dados Spark segmentado.\n",
    "\n",
    "    Args:\n",
    "        data_spark (DataFrame): DataFrame Spark contendo os dados de entrada.\n",
    "        score (str): Nome da coluna que contém as pontuações a serem avaliadas.\n",
    "        target (str): Nome da coluna que contém o target (deve ser binário, com valores 0 e 1).\n",
    "        segment (list): Lista de colunas que serão usadas para segmentar os dados.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame Spark contendo a métrica KS2 calculada para cada segmento.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: Se qualquer coluna especificada em `score`, `target` ou `segment` não estiver presente no DataFrame de entrada (`data_spark`).\n",
    "        ValueError: Se a coluna target (`target`) contiver valores diferentes de 0 e 1.\n",
    "\n",
    "    Example:\n",
    "        >>> df_ks2 = get_ks2_metric(data_spark=df_spark, score='score_column', target='target_column', segment=['segment_column'])\n",
    "    \"\"\"\n",
    "    \n",
    "    #validando se a lista esta presente na tabela de input pu no objeto do modelo\n",
    "    if score not in data_spark.columns:\n",
    "        raise ValueError(f\"A feature {score} definido no parâmetro score não esta presente na tabela de input, parâmetro data_spark.\")\n",
    "\n",
    "    if target not in data_spark.columns:\n",
    "        raise ValueError(f\"A feature {target} definido no parâmetro target não esta presente na tabela de input, parâmetro data_spark.\")\n",
    "\n",
    "    target_value  = data_spark.select(target).distinct().rdd.flatMap(lambda row: row).collect()\n",
    "    result_bool = all(value in [1, 0] for value in target_value)\n",
    "\n",
    "    if result_bool == False:\n",
    "        raise ValueError(f\"A variavel {target} especificada no parâmetro target possui os seguintes valores {target_value}, logo o processo binning foi desenvolvido para problemas de classificação assumindo somente valores (0,1).\")\n",
    "\n",
    "    #validando se a lista esta presente na tabela de input pu no objeto do modelo\n",
    "    list_not_in = [column for column in segment if column not in data_spark.columns]\n",
    "\n",
    "    if list_not_in != []:\n",
    "        raise ValueError(f\"A lista de features {list_not_in} do parâmetro segment não esta presente na tabela de input, parâmetro data_spark.\")\n",
    "\n",
    "    data_pandas = data_spark.toPandas()\n",
    "    result = (data_pandas[data_pandas[score] >= 0]\n",
    "              .groupby(segment)\n",
    "              .apply(lambda group: ks_2samp(group[score][group[target] == 1], group[score][group[target] == 0])[0])\n",
    "              .round(4)\n",
    "              .reset_index(name=f'ks2_{score.lower()}')\n",
    "              .sort_values(segment))\n",
    "    return(spark.createDataFrame(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "692b709e-7511-4916-9fdc-9fe2d3f3bc6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_auc_metric(data_spark, score, target, segment):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calcula a métrica AUC (Area Under the Curve) para um conjunto de dados Spark segmentado.\n",
    "\n",
    "    Args:\n",
    "        data_spark (DataFrame): DataFrame Spark contendo os dados de entrada.\n",
    "        score (str): Nome da coluna que contém as pontuações a serem avaliadas.\n",
    "        target (str): Nome da coluna que contém o target (deve ser binário, com valores 0 e 1).\n",
    "        segment (list): Lista de colunas que serão usadas para segmentar os dados.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame Spark contendo a métrica AUC calculada para cada segmento.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: Se qualquer coluna especificada em `score`, `target` ou `segment` não estiver presente no DataFrame de entrada (`data_spark`).\n",
    "        ValueError: Se a coluna target (`target`) contiver valores diferentes de 0 e 1.\n",
    "\n",
    "    Example:\n",
    "        >>> df_auc = get_auc_metric(data_spark=df_spark, score='score_column', target='target_column', segment=['segment_column'])\n",
    "    \"\"\"\n",
    "\n",
    "    #validando se a lista esta presente na tabela de input pu no objeto do modelo\n",
    "    if score not in data_spark.columns:\n",
    "        raise ValueError(f\"A feature {score} não esta presente na tabela de input, parâmetro data_spark.\")\n",
    "\n",
    "    if target not in data_spark.columns:\n",
    "        raise ValueError(f\"A feature {target} não esta presente na tabela de input, parâmetro data_spark.\")\n",
    "\n",
    "    #validando se o target é binario\n",
    "\n",
    "    target_value  = data_spark.select(target).distinct().rdd.flatMap(lambda row: row).collect()\n",
    "    result_bool = all(value in [1, 0] for value in target_value)\n",
    "\n",
    "    if result_bool == False:\n",
    "        raise ValueError(f\"A variavel {target} especificada no parâmetro target possui os seguintes valores {target_value}, logo o processo binning foi desenvolvido para problemas de classificação assumindo somente valores (0,1).\")\n",
    "\n",
    "    data_pandas = data_spark.toPandas()\n",
    "    data_pandas[\"score_invert\"] = 1000-data_pandas[score]\n",
    "\n",
    "    result = (\n",
    "        data_pandas[data_pandas[score] >= 0]\n",
    "        .groupby(segment)\n",
    "        .apply(lambda group: calculate_auc(group = group, target = target, score = 'score_invert'))\n",
    "        .round(4)\n",
    "        .reset_index(name=f'auc_{score.lower()}')\n",
    "        .sort_values(segment)\n",
    "    )\n",
    "    return spark.createDataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "245bec4c-7f5f-476e-896d-2be512c767e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_gini_metric(data_spark, score, target, segment):\n",
    "\n",
    "    \"\"\"\n",
    "    Calcula a métrica Gini para um conjunto de dados Spark segmentado.\n",
    "\n",
    "    Args:\n",
    "        data_spark (DataFrame): DataFrame Spark contendo os dados de entrada.\n",
    "        score (str): Nome da coluna que contém as pontuações a serem avaliadas.\n",
    "        target (str): Nome da coluna que contém o target (deve ser binário, com valores 0 e 1).\n",
    "        segment (list): Lista de colunas que serão usadas para segmentar os dados.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame Spark contendo a métrica Gini calculada para cada segmento.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: Se qualquer coluna especificada em `score`, `target` ou `segment` não estiver presente no DataFrame de entrada (`data_spark`).\n",
    "        ValueError: Se a coluna target (`target`) contiver valores diferentes de 0 e 1.\n",
    "\n",
    "    Example:\n",
    "        >>> df_gini = get_gini_metric(data_spark=df_spark, score='score_column', target='target_column', segment=['segment_column'])\n",
    "    \"\"\"\n",
    "\n",
    "    #validando se a lista esta presente na tabela de input pu no objeto do modelo\n",
    "    if score not in data_spark.columns:\n",
    "        raise ValueError(f\"A feature {score} definido no parâmetro score não esta presente na tabela de input, parâmetro data_spark.\")\n",
    "\n",
    "    if target not in data_spark.columns:\n",
    "        raise ValueError(f\"A feature {target} definido no parâmetro target não esta presente na tabela de input, parâmetro data_spark.\")\n",
    "\n",
    "    target_value  = data_spark.select(target).distinct().rdd.flatMap(lambda row: row).collect()\n",
    "    result_bool = all(value in [1, 0] for value in target_value)\n",
    "\n",
    "    if result_bool == False:\n",
    "        raise ValueError(f\"A variavel {target} especificada no parâmetro target possui os seguintes valores {target_value}, logo o processo binning foi desenvolvido para problemas de classificação assumindo somente valores (0,1).\")\n",
    "\n",
    "    #validando se a lista esta presente na tabela de input pu no objeto do modelo\n",
    "    list_not_in = [column for column in segment if column not in data_spark.columns]\n",
    "\n",
    "    if list_not_in != []:\n",
    "        raise ValueError(f\"A lista de features {list_not_in} do parâmetro segment não esta presente na tabela de input, parâmetro data_spark.\")\n",
    "\n",
    "    data_pandas = data_spark.toPandas()\n",
    "    data_pandas[\"score_invert\"] = 1000-data_pandas[score]\n",
    "\n",
    "    result = (\n",
    "        data_pandas[data_pandas[score] >= 0]\n",
    "        .groupby(segment)\n",
    "        .apply(lambda group: 2 * calculate_auc(group = group, score = \"score_invert\", target = target) - 1)\n",
    "        .round(4)\n",
    "        .reset_index(name=f'gini_{score.lower()}')\n",
    "        .sort_values(segment)\n",
    "    )\n",
    "    return spark.createDataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "921578be-2aae-4a6a-ae05-83c0320eb787",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_metric_perfomance_multiple(data_spark, list_score, target, list_segment, metric = \"ks2\"):\n",
    "\n",
    "    \"\"\"\n",
    "    Calcula as principais métricas de performance (KS2, Gini, AUC) para um conjunto de dados Spark segmentado.\n",
    "\n",
    "    Args:\n",
    "        data_spark (DataFrame): DataFrame Spark contendo os dados de entrada.\n",
    "        list_score (list): Lista de colunas que contêm as pontuações a serem avaliadas.\n",
    "        target (str): Nome da coluna que contém o target (deve ser binário, com valores 0 e 1).\n",
    "        list_segment (list): Lista de colunas que serão usadas para segmentar os dados.\n",
    "        metric (str, opcional): Métrica a ser calculada. As opções possíveis são 'ks2', 'gini', 'auc'. O valor default é\n",
    "        'ks2'.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame Spark contendo as métricas calculadas para cada segmento.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: Se a métrica especificada em `metric` não for uma das opções válidas.\n",
    "        ValueError: Se qualquer coluna especificada em `score`, `target` ou `segment` não estiver presente no DataFrame de entrada (`data_spark`).\n",
    "        ValueError: Se a coluna target (`target`) contiver valores diferentes de 0 e 1.\n",
    "\n",
    "    Example:\n",
    "        >>> df_metrics = get_metric_perfomance_multiple(data_spark=df_spark, list_score=['score1', 'score2'], target='target_column', list_segment=['segment_column'], metric='ks2')\n",
    "    \"\"\"\n",
    "\n",
    "    list_possible_metrics = ['ks2', 'gini', 'auc']\n",
    "    metric_result_valid = [column for column in list_possible_metrics if column in metric.lower()]\n",
    "\n",
    "    if metric_result_valid == []:\n",
    "        raise ValueError(f\"A Métrica {metric} especificada no parâmetro metric não esta presente nas possibilidades: {list_possible_metrics}. Escolha uma dessas informações para retorno da performance.\")\n",
    "\n",
    "    metric = metric.lower()\n",
    "\n",
    "    if metric == \"ks2\":\n",
    "        score_ini = list_score[0]\n",
    "        print(f'Calculando KS2 da Feature {score_ini}')\n",
    "        result_ini = get_ks2_metric(data_spark = data_spark, score = score_ini, target = target, segment = list_segment)\n",
    "        if len(list_score) > 1:\n",
    "            for i in list_score[1:]:\n",
    "                print(f'Calculando KS2 da Feature {i}')\n",
    "                result = get_ks2_metric(data_spark = data_spark, score = i, target = target, segment = list_segment)\n",
    "                \n",
    "                result_ini = result_ini.join(result, on = list_segment, how = 'outer')\n",
    "\n",
    "    if metric == \"auc\":\n",
    "        score_ini = list_score[0]\n",
    "        print(f'Calculando AUC da Feature {score_ini}')\n",
    "        result_ini = get_auc_metric(data_spark = data_spark, score = score_ini, target = target, segment = list_segment)\n",
    "        \n",
    "        if len(list_score) > 1:\n",
    "            for i in list_score[1:]:\n",
    "                print(f'Calculando AUC da Feature {i}')\n",
    "                result = get_auc_metric(data_spark = data_spark, score = i, target = target, segment = list_segment)\n",
    "                \n",
    "                result_ini = result_ini.join(result, on = list_segment, how = 'outer')\n",
    "\n",
    "    if metric == \"gini\":\n",
    "        score_ini = list_score[0]\n",
    "        print(f'Calculando GINI da Feature {score_ini}')\n",
    "        result_ini = get_gini_metric(data_spark = data_spark, score = score_ini, target = target, segment = list_segment)\n",
    "        if len(list_score) > 1:\n",
    "            for i in list_score[1:]:\n",
    "                print(f'Calculando GINI da Feature {i}')\n",
    "                result = get_gini_metric(data_spark = data_spark, score = i, target = target, segment = list_segment)\n",
    "                result_ini = result_ini.join(result, on = list_segment, how = 'outer')\n",
    "    return(result_ini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fce7328-60f4-4903-9dd9-9bf24174590c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# def get_psi_metric(data_spark_ref, data_spark_test, feature, reference_test):\n",
    "    \n",
    "#     \"\"\"\n",
    "#     Calcula a métrica PSI (Population Stability Index) para um conjunto de dados Spark de referência e teste.\n",
    "\n",
    "#     Args:\n",
    "#         data_spark_ref (DataFrame): DataFrame Spark contendo os dados de referência.\n",
    "#         data_spark_test (DataFrame): DataFrame Spark contendo os dados de teste.\n",
    "#         feature (str): Nome da coluna que contém a feature a ser avaliada.\n",
    "#         reference_test (str): Nome da coluna que contém a referência para os dados de teste.\n",
    "\n",
    "#     Returns:\n",
    "#         DataFrame: DataFrame Spark contendo a métrica PSI calculada para cada grupo de referência.\n",
    "\n",
    "#     Raises:\n",
    "#         ValueError: Se qualquer coluna especificada em `feature` ou `reference_test` não estiver presente no DataFrame de entrada (`data_spark_ref` ou `data_spark_test`).\n",
    "\n",
    "#     Example:\n",
    "#         >>> df_psi = get_psi_metric(data_spark_ref=df_ref, data_spark_test=df_test, feature='feature_column', reference_test='reference_column')\n",
    "#     \"\"\"\n",
    "\n",
    "\n",
    "#     #validando se a lista esta presente na tabela de input pu no objeto do modelo\n",
    "#     if feature not in data_spark_ref.columns:\n",
    "#         raise ValueError(f\"A feature {feature} definido no parâmetro feature não esta presente na tabela de input, parâmetro data_spark_ref.\")\n",
    "\n",
    "#     #validando se a lista esta presente na tabela de input pu no objeto do modelo\n",
    "#     if feature not in data_spark_test.columns:\n",
    "#         raise ValueError(f\"A feature {feature} para o cálculo não esta presente na tabela de input, parâmetro data_spark_test.\")\n",
    "\n",
    "#     #validando se a lista esta presente na tabela de input pu no objeto do modelo\n",
    "#     if reference_test not in data_spark_test.columns:\n",
    "#         raise ValueError(f\"A feature {reference_test} para o cálculo não esta presente na tabela de input, parâmetro data_spark_test.\")\n",
    "\n",
    "#     #Calculando Volumetria da referencia\n",
    "#     df_table_ref = data_spark_ref\n",
    "#     size_df_table_ref = df_table_ref.groupBy(f.col(feature)).agg(f.count(\"*\").alias(\"Volume_Ref\"))\n",
    "#     total_volume = size_df_table_ref.select(f.sum(f.col(\"Volume_Ref\"))).collect()[0][0]\n",
    "#     size_df_table_ref = size_df_table_ref.withColumn(\"prop_ref\", f.col(\"Volume_Ref\")/total_volume)\n",
    "\n",
    "#     #Calculando a Volumetria do teste\n",
    "#     df_table_test = data_spark_test\n",
    "#     size_df_table_test = df_table_test.groupBy(feature, reference_test).agg(f.count(\"*\").alias(\"Volume_Test\"))\n",
    "#     total_volume_teste = size_df_table_test.groupBy(reference_test).agg(f.sum(f.col(\"Volume_Test\")).alias(\"Volume_Test_Grupo\"))\n",
    "#     size_df_table_test = size_df_table_test.join(total_volume_teste, how = \"left\", on = [reference_test])\n",
    "#     size_df_table_test = size_df_table_test.withColumn(\"prop_test\", f.col(\"Volume_Test\")/f.col(\"Volume_Test_Grupo\"))\n",
    "\n",
    "#     #Calculando PSI\n",
    "#     Tabela = size_df_table_test.join(size_df_table_ref, how = \"left\", on = feature)\n",
    "#     Tabela = Tabela.withColumn(\"PSI\", (f.col(\"prop_ref\") - f.col(\"prop_test\"))*f.log(f.col(\"prop_ref\")/f.col(\"prop_test\")))\n",
    "#     PSI_Geral = Tabela.groupBy(reference_test).agg(f.round(f.sum(f.col(\"PSI\")), 4).alias(f\"PSI_{feature}\"))\n",
    "\n",
    "#     return(PSI_Geral)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57132942-786e-4552-adcf-2f6763f4efdd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# def get_psi_metric_multiple_features(data_spark_ref, data_spark_test, list_features, reference_test):\n",
    "    \n",
    "#     \"\"\"\n",
    "#     Calcula a métrica PSI (Population Stability Index) para múltiplas features em conjuntos de dados Spark de referência e teste.\n",
    "\n",
    "#     Args:\n",
    "#         data_spark_ref (DataFrame): DataFrame Spark contendo os dados de referência.\n",
    "#         data_spark_test (DataFrame): DataFrame Spark contendo os dados de teste.\n",
    "#         list_features (list): Lista de colunas que contêm as features a serem avaliadas.\n",
    "#         reference_test (str): Nome da coluna que contém a referência para os dados de teste.\n",
    "\n",
    "#     Returns:\n",
    "#         DataFrame: DataFrame Spark contendo a métrica PSI calculada para cada feature em cada grupo de referência.\n",
    "\n",
    "#     Raises:\n",
    "#         ValueError: Se qualquer coluna especificada em `feature` ou `reference_test` não estiver presente no DataFrame\n",
    "#         de entrada (`data_spark_ref` ou `data_spark_test`).\n",
    "\n",
    "#     Example:\n",
    "#         >>> df_psi = get_psi_metric_multiple_features(data_spark_ref=df_ref, data_spark_test=df_test, list_features=['feature1', 'feature2'], reference_test='reference_column')\n",
    "#     \"\"\"\n",
    "\n",
    "#     feature_ini = list_features[0]\n",
    "#     result_ini = get_psi_metric(data_spark_ref = data_spark_ref, data_spark_test = data_spark_test, feature = feature_ini, reference_test = reference_test)\n",
    "    \n",
    "#     if len(list_features) > 1:\n",
    "#         for i in list_features[1:]:\n",
    "#             result = get_psi_metric(data_spark_ref = data_spark_ref, data_spark_test = data_spark_test, feature = i, reference_test = reference_test)\n",
    "#             result_ini = result_ini.join(result, on = reference_test, how = 'outer')\n",
    "#     return(result_ini.orderBy(reference_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e2fa2be-8451-432d-a42f-b486936b4636",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_psi_metric_multiple_features(data_spark_ref, data_spark_test, list_features, reference_test):\n",
    "    \"\"\"\n",
    "    Calcula a métrica PSI (Population Stability Index) para múltiplas features em conjuntos de dados Spark de referência e teste.\n",
    "\n",
    "    Args:\n",
    "        data_spark_ref (DataFrame): Dados de referência.\n",
    "        data_spark_test (DataFrame): Dados de teste.\n",
    "        list_features (list): Lista de features para calcular PSI.\n",
    "        reference_test (str): Nome da coluna com o grupo de teste.\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Tabela com features e valores de PSI para cada grupo.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Verificação de colunas ausentes\n",
    "    missing_cols = [feat for feat in list_features if feat not in data_spark_ref.columns or feat not in data_spark_test.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"As seguintes colunas estão ausentes em um dos datasets: {missing_cols}\")\n",
    "    if reference_test not in data_spark_test.columns:\n",
    "        raise ValueError(f\"A coluna '{reference_test}' está ausente em data_spark_test.\")\n",
    "\n",
    "    # Criando expressão stack\n",
    "    stack_args = \", \".join([f\"'{col}', `{col}`\" for col in list_features])\n",
    "    stack_expr = f\"stack({len(list_features)}, {stack_args}) as (feature, value)\"\n",
    "\n",
    "    # ---- Referência ----\n",
    "    stacked_ref = data_spark_ref.selectExpr(stack_expr)\n",
    "    stacked_ref = stacked_ref.groupBy(\"feature\", \"value\").agg(f.count(\"*\").alias(\"Volume_Ref\"))\n",
    "    total_ref = stacked_ref.groupBy(\"feature\").agg(f.sum(\"Volume_Ref\").alias(\"Total_Ref\"))\n",
    "    stacked_ref = stacked_ref.join(total_ref, on=\"feature\", how=\"left\")\n",
    "    stacked_ref = stacked_ref.withColumn(\"prop_ref\", f.col(\"Volume_Ref\") / f.col(\"Total_Ref\"))\n",
    "\n",
    "    # ---- Teste ----\n",
    "    stacked_test = data_spark_test.selectExpr(reference_test, *[f\"`{col}`\" for col in list_features])\n",
    "    stacked_test = stacked_test.selectExpr(reference_test, stack_expr)\n",
    "    stacked_test = stacked_test.groupBy(\"feature\", \"value\", reference_test).agg(f.count(\"*\").alias(\"Volume_Test\"))\n",
    "    total_test = stacked_test.groupBy(\"feature\", reference_test).agg(f.sum(\"Volume_Test\").alias(\"Total_Test\"))\n",
    "    stacked_test = stacked_test.join(total_test, on=[\"feature\", reference_test], how=\"left\")\n",
    "    stacked_test = stacked_test.withColumn(\"prop_test\", f.col(\"Volume_Test\") / f.col(\"Total_Test\"))\n",
    "\n",
    "    # ---- PSI ----\n",
    "    psi_table = stacked_test.join(stacked_ref, on=[\"feature\", \"value\"], how=\"left\")\n",
    "    psi_table = psi_table.withColumn(\n",
    "        \"PSI\", \n",
    "        (f.col(\"prop_ref\") - f.col(\"prop_test\")) * f.log(f.col(\"prop_ref\") / f.col(\"prop_test\"))\n",
    "    )\n",
    "\n",
    "    # ---- Resultado final: PSI por feature e por grupo ----\n",
    "    psi_final = (\n",
    "        psi_table.groupBy(\"feature\")\n",
    "        .pivot(reference_test)\n",
    "        .agg(f.round(f.sum(\"PSI\"), 4))\n",
    "        .orderBy(\"feature\")\n",
    "    )\n",
    "\n",
    "    return psi_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8942f3f7-7b15-4464-b563-193f38bfeac0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_iv_metric_multiple_features(data_spark, list_features, target, segment):\n",
    "    \"\"\"\n",
    "    Calcula o Information Value (IV) para múltiplas features, pivotando os segmentos para colunas.\n",
    "\n",
    "    Args:\n",
    "        data_spark (DataFrame): Dados contendo as features categorizadas, target e segmento.\n",
    "        list_features (list): Lista de features categóricas ou binned para calcular IV.\n",
    "        target (str): Nome da coluna target (esperado binário: 0 e 1).\n",
    "        segment (str): Nome da coluna de segmentação para gerar colunas no output.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Tabela com IV calculado para cada feature e cada segmento nas colunas.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: Se qualquer coluna especificada não estiver presente no DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    # ---- Validação ----\n",
    "    missing_cols = [feat for feat in list_features if feat not in data_spark.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"As seguintes colunas estão ausentes no dataframe: {missing_cols}\")\n",
    "    if target not in data_spark.columns:\n",
    "        raise ValueError(f\"A coluna target '{target}' não está presente no dataframe.\")\n",
    "    if segment not in data_spark.columns:\n",
    "        raise ValueError(f\"A coluna segment '{segment}' não está presente no dataframe.\")\n",
    "\n",
    "    # ---- Criando expressão stack ----\n",
    "    stack_args = \", \".join([f\"'{col}', `{col}`\" for col in list_features])\n",
    "    stack_expr = f\"stack({len(list_features)}, {stack_args}) as (feature, value)\"\n",
    "\n",
    "    # ---- Preparação dos dados ----\n",
    "    df_stacked = data_spark.selectExpr(segment, stack_expr, target)\n",
    "\n",
    "    # ---- Contagem de Good e Bad por grupo ----\n",
    "    grouped = (\n",
    "        df_stacked.groupBy(segment, \"feature\", \"value\")\n",
    "        .agg(\n",
    "            f.sum(f.when(f.col(target) == 0, 1).otherwise(0)).alias(\"good\"),\n",
    "            f.sum(f.when(f.col(target) == 1, 1).otherwise(0)).alias(\"bad\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # ---- Totais de Good e Bad por segmento e feature ----\n",
    "    totals = grouped.groupBy(segment, \"feature\").agg(\n",
    "        f.sum(\"good\").alias(\"total_good\"),\n",
    "        f.sum(\"bad\").alias(\"total_bad\")\n",
    "    )\n",
    "\n",
    "    # ---- Calculando proporções ----\n",
    "    final = grouped.join(totals, on=[segment, \"feature\"], how=\"left\")\n",
    "    final = final.withColumn(\n",
    "        \"dist_good\", f.when(f.col(\"total_good\") == 0, 0).otherwise(f.col(\"good\") / f.col(\"total_good\"))\n",
    "    ).withColumn(\n",
    "        \"dist_bad\", f.when(f.col(\"total_bad\") == 0, 0).otherwise(f.col(\"bad\") / f.col(\"total_bad\"))\n",
    "    )\n",
    "\n",
    "    # ---- Calculando WOE ----\n",
    "    final = final.withColumn(\n",
    "        \"WOE\",\n",
    "        f.when((f.col(\"dist_good\") == 0) | (f.col(\"dist_bad\") == 0), 0)\n",
    "         .otherwise(f.log(f.col(\"dist_good\") / f.col(\"dist_bad\")))\n",
    "    )\n",
    "\n",
    "    # ---- Calculando IV ----\n",
    "    final = final.withColumn(\n",
    "        \"IV_component\",\n",
    "        (f.col(\"dist_good\") - f.col(\"dist_bad\")) * f.col(\"WOE\")\n",
    "    )\n",
    "\n",
    "    # ---- Agregando IV final por feature e segmento ----\n",
    "    iv_agg = (\n",
    "        final.groupBy(segment, \"feature\")\n",
    "        .agg(f.round(f.sum(\"IV_component\"), 6).alias(\"IV\"))\n",
    "    )\n",
    "\n",
    "    # ---- Fazendo pivot para que os segmentos fiquem nas colunas ----\n",
    "    iv_pivot = (\n",
    "        iv_agg.groupBy(\"feature\")\n",
    "        .pivot(segment)\n",
    "        .agg(f.first(\"IV\"))\n",
    "        .orderBy(\"feature\")\n",
    "    )\n",
    "\n",
    "    return iv_pivot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c284dff6-75c3-4903-a1f7-a350b8aa6c8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def gains_table(data_spark, score, bin_score, target):\n",
    "\n",
    "    \"\"\"\n",
    "    Gera uma tabela de ganhos (gains table) para um conjunto de dados Spark, utilizando uma pontuação e um binning score.\n",
    "\n",
    "    Args:\n",
    "        data_spark (DataFrame): DataFrame Spark contendo os dados de entrada.\n",
    "        score (str): Nome da coluna que contém as pontuações a serem avaliadas.\n",
    "        bin_score (str): Nome da coluna que contém os binning scores.\n",
    "        target (str): Nome da coluna que contém o target (deve ser binário, com valores 0 e 1).\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame Spark contendo a tabela de ganhos.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: Se qualquer coluna especificada em `score`, `bin_score` ou `target` não estiver presente no DataFrame de entrada (`data_spark`).\n",
    "        ValueError: Se a coluna target (`target`) contiver valores diferentes de 0 e 1.\n",
    "\n",
    "    Example:\n",
    "        >>> df_gains = gains_table(data_spark=df_spark, score='score_column', bin_score='bin_score_column', target='target_column')\n",
    "    \"\"\"\n",
    "\n",
    "    #validando se a lista esta presente na tabela de input pu no objeto do modelo\n",
    "    if score not in data_spark.columns:\n",
    "            raise ValueError(f\"A feature {score} definido no parâmetro score não esta presente na tabela de input, parâmetro data_spark.\")\n",
    "\n",
    "    #validando se a lista esta presente na tabela de input pu no objeto do modelo\n",
    "    if bin_score not in data_spark.columns:\n",
    "        raise ValueError(f\"A feature {bin_score} para o cálculo não esta presente na tabela de input, parâmetro data_spark.\")\n",
    "\n",
    "    if target not in data_spark.columns:\n",
    "        raise ValueError(f\"A variavel {target} especificada no parâmetro target não esta presente no tabela de input, especificado no parâmetro data_spark.\")\n",
    "      \n",
    "       #validando se o target é binario\n",
    "    target_value  = data_spark.select(target).distinct().rdd.flatMap(lambda row: row).collect()\n",
    "    result_bool = all(value in [1, 0] for value in target_value)\n",
    "\n",
    "    if result_bool == False:\n",
    "            raise ValueError(f\"A variavel {target} especificada no parâmetro target possui os seguintes valores {target_value}, logo o processo binning foi desenvolvido para problemas de classificação assumindo somente valores (0,1).\")\n",
    "\n",
    "\n",
    "    #funcao para gerar o o gains_table\n",
    "    from pyspark.sql.functions import col, sum as spark_sum, round as spark_round\n",
    "\n",
    "    df_table = data_spark\n",
    "\n",
    "    #criando soma de bons\n",
    "    df_table = df_table.withColumn(\"target2\", 1 - f.col(target))\n",
    "    #Tabela descritivas\n",
    "    table_gain = (\n",
    "        df_table.groupBy(bin_score)\n",
    "        .agg(f.min(score).alias(\"minimo\"),\n",
    "             f.max(score).alias(\"maximo\"),\n",
    "             f.count(\"*\").alias(\"volume\"),\n",
    "             f.sum('target2').alias(\"bons\"),\n",
    "             f.sum(target).alias(\"maus\"),\n",
    "             f.round(f.mean(target), 4).alias(\"badrate\")\n",
    "             )\n",
    "        .orderBy(f.col(bin_score))\n",
    "        )\n",
    "    #criando informações acumuladas\n",
    "    # Definindo a janela de agregação\n",
    "    windowSpec = Window.orderBy(f.col(bin_score)).rowsBetween(Window.unboundedPreceding, 0)\n",
    "\n",
    "    # Realizando a soma cumulativa\n",
    "    table_gain = table_gain.withColumn(\"acm\", spark_sum(f.col(\"volume\")).over(windowSpec))\n",
    "    table_gain = table_gain.withColumn(\"acm_bons\", spark_sum(f.col(\"bons\")).over(windowSpec))\n",
    "    table_gain = table_gain.withColumn(\"acm_maus\", spark_sum(f.col(\"maus\")).over(windowSpec))\n",
    "\n",
    "\n",
    "    table_gain = table_gain.withColumn(\"badrate_acm\",  f.round(f.col(\"acm_maus\")/f.col(\"acm\"), 4))\n",
    "\n",
    "    total_volume = table_gain.select(spark_sum(f.col(\"volume\"))).collect()[0][0]\n",
    "    total_bons = table_gain.select(spark_sum(f.col(\"bons\"))).collect()[0][0]\n",
    "    total_maus = table_gain.select(spark_sum(f.col(\"maus\"))).collect()[0][0]\n",
    "\n",
    "    table_gain = table_gain.withColumn(\"perc_acm_volume\", f.round(f.col(\"acm\")/total_volume, 4))\n",
    "    table_gain = table_gain.withColumn(\"bons_acm_volume\", f.round(f.col(\"acm_bons\")/total_bons, 4))\n",
    "    table_gain = table_gain.withColumn(\"maus_acm_volume\", f.round(f.col(\"acm_maus\")/total_maus, 4))\n",
    "\n",
    "    table_gain = table_gain.orderBy(f.col(bin_score))\n",
    "\n",
    "    return(table_gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0c61df6d-0107-4fa7-87db-ddfaf0803111",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_features_descriptive_report(\n",
    "    df_spark,\n",
    "    features,\n",
    "    segment=\"referencia_concessao\",\n",
    "    target=\"bad\",\n",
    "    save_path=\"painel_badrate_moderno.jpeg\",\n",
    "    titulos_custom=None  # \uD83C\uDD95 dicionário de títulos\n",
    "):\n",
    "    \"\"\"\n",
    "    Gera um painel visual em formato JPEG apresentando a evolução e a distribuição\n",
    "    do bad rate (percentual de inadimplência) para um conjunto de variáveis categóricas.\n",
    "\n",
    "    Para cada variável categórica, a função produz dois gráficos lado a lado:\n",
    "    \n",
    "      1️⃣ **Gráfico \"Safra a Safra\" (à esquerda):**\n",
    "          - Exibe a evolução temporal (por referência de concessão) da distribuição percentual\n",
    "            das categorias (barras empilhadas).\n",
    "          - Inclui sobreposição de linhas mostrando o bad rate de cada categoria.\n",
    "    \n",
    "      2️⃣ **Gráfico \"Distribuição Geral\" (à direita):**\n",
    "          - Exibe a distribuição percentual geral de cada categoria.\n",
    "          - Inclui linha representando o bad rate total da categoria.\n",
    "          - Mostra rótulos de porcentagem nas barras e valores de bad rate nos pontos.\n",
    "\n",
    "    O painel completo (com todos os pares de gráficos) é salvo em um único arquivo `.jpeg`.\n",
    "\n",
    "    ---\n",
    "    **Visual:**\n",
    "    - Estilo minimalista (sem grid).\n",
    "    - Paleta neutra para barras e verde para linha de bad rate.\n",
    "    - Eixos e textos arredondados (sem casas decimais).\n",
    "    - Legendas compactas centralizadas abaixo do gráfico de safra.\n",
    "\n",
    "    ---\n",
    "    Args:\n",
    "        df_spark (pyspark.sql.DataFrame):\n",
    "            DataFrame do PySpark contendo os dados a serem analisados.\n",
    "        features (list[str]):\n",
    "            Lista das variáveis categóricas que serão analisadas no painel.\n",
    "        segment (str, opcional):\n",
    "            Nome da coluna de referência temporal ou de concessão (ex.: \"safra\").\n",
    "            Default é `\"referencia_concessao\"`.\n",
    "        target (str, opcional):\n",
    "            Nome da variável resposta binária (0/1) utilizada para cálculo do bad rate.\n",
    "            Default é `\"bad\"`.\n",
    "        save_path (str, opcional):\n",
    "            Caminho e nome do arquivo de saída JPEG a ser salvo.\n",
    "            Default é `\"painel_badrate_moderno.jpeg\"`.\n",
    "        titulos_custom : dict[str, str], opcional\n",
    "            Dicionário com títulos customizados. Ex: {\"uf\": \"Unidade Federativa\"}.\n",
    "\n",
    "    ---\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "        (A função **não retorna valores**; gera e salva o painel no caminho especificado.)\n",
    "\n",
    "    ---\n",
    "    Raises:\n",
    "        ValueError:\n",
    "            Caso alguma variável especificada em `features`, `segment` ou `target`\n",
    "            não esteja presente no DataFrame de entrada.\n",
    "        Exception:\n",
    "            Qualquer erro relacionado ao processo de conversão de Spark → Pandas\n",
    "            ou à renderização dos gráficos.\n",
    "\n",
    "    ---\n",
    "    Exemplo:\n",
    "        >>> gerar_painel_badrate_por_feature(\n",
    "        ...     df_spark=df_spark_spark,\n",
    "        ...     features=['canal_venda', 'tipo_cliente', 'uf'],\n",
    "        ...     segment='safra',\n",
    "        ...     target='bad_flag',\n",
    "        ...     save_path='painel_badrate_2025.jpeg',\n",
    "        ...     titulos_custom='titulos_custom.jpeg',\n",
    "\n",
    "        ... )\n",
    "        ✅ Painel salvo em: /caminho/para/painel_badrate_2025.jpeg\n",
    "\n",
    "    ---\n",
    "    Notas:\n",
    "        - O gráfico é salvo automaticamente no diretório de execução, caso `save_path` não seja informado.\n",
    "        - Requer as bibliotecas:\n",
    "            `seaborn`, `matplotlib`, `pandas`, e `pyspark.sql.functions`.\n",
    "        - É recomendável utilizar um subconjunto da base caso o DataFrame seja muito grande,\n",
    "          pois a conversão para Pandas é feita internamente para gerar os gráficos.\n",
    "    \"\"\"\n",
    "\n",
    "    # === \uD83C\uDFA8 Estilo visual ===\n",
    "    # Tenta usar Montserrat; fallback automático\n",
    "    font_name = \"Montserrat\"\n",
    "    available_fonts = [f.name for f in fm.fontManager.ttflist]\n",
    "    if font_name not in available_fonts:\n",
    "        font_name = \"DejaVu Sans\"\n",
    "\n",
    "    sns.set_theme(style=\"white\")\n",
    "    plt.rcParams.update({\n",
    "        \"font.family\": font_name,\n",
    "        \"font.size\": 10,\n",
    "        \"axes.titlesize\": 13,\n",
    "        \"axes.titleweight\": \"bold\",\n",
    "        \"axes.edgecolor\": \"black\",\n",
    "        \"axes.linewidth\": 0.8\n",
    "    })\n",
    "\n",
    "    n_feat = len(features)\n",
    "    fig, axes = plt.subplots(n_feat, 2, figsize=(14, 6 * n_feat))\n",
    "    if n_feat == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for i, var_cat in enumerate(features):\n",
    "\n",
    "        # \uD83C\uDD95 Título customizado (ou nome da variável)\n",
    "        titulo_exibido = titulos_custom.get(var_cat, var_cat) if titulos_custom else var_cat\n",
    "\n",
    "        # === 1️⃣ Agregado por safra e categoria ===\n",
    "        agg = (\n",
    "            df_spark.groupBy(segment, var_cat)\n",
    "              .agg(\n",
    "                  f.count(\"*\").alias(\"n\"),\n",
    "                  f.mean(f.col(target)).alias(\"bad_rate\")\n",
    "              )\n",
    "        )\n",
    "\n",
    "        total_safra = agg.groupBy(segment).agg(f.sum(\"n\").alias(\"n_total\"))\n",
    "\n",
    "        df_spark_join = (\n",
    "            agg.join(total_safra, on=segment, how=\"left\")\n",
    "               .withColumn(\"pct\", (f.col(\"n\") / f.col(\"n_total\")) * 100)\n",
    "               .withColumn(\"bad_rate\", f.col(\"bad_rate\") * 100)\n",
    "        )\n",
    "\n",
    "        pdf_spark = df_spark_join.toPandas()\n",
    "\n",
    "        # === 2️⃣ Pivot para empilhamento ===\n",
    "        dist_pivot = pdf_spark.pivot(index=segment, columns=var_cat, values=\"pct\").fillna(0)\n",
    "        bad_rate_pivot = pdf_spark.pivot(index=segment, columns=var_cat, values=\"bad_rate\").fillna(0)\n",
    "\n",
    "        # === 3️⃣ Agregado geral ===\n",
    "        agg_cat = (\n",
    "            df_spark.groupBy(var_cat)\n",
    "              .agg(\n",
    "                  f.count(\"*\").alias(\"n\"),\n",
    "                  (f.mean(f.col(target)) * 100).alias(\"bad_rate\")\n",
    "              )\n",
    "        )\n",
    "        total = agg_cat.agg(f.sum(\"n\").alias(\"total\")).collect()[0][\"total\"]\n",
    "        agg_cat = agg_cat.withColumn(\"pct\", (f.col(\"n\") / f.lit(total)) * 100)\n",
    "        pdf_spark_cat = agg_cat.toPandas().sort_values(var_cat)\n",
    "\n",
    "        # ===== \uD83C\uDFAF Controle inteligente do título =====\n",
    "        # Diminui a fonte se o título for muito grande\n",
    "        titulo_len = len(titulo_exibido)\n",
    "        fs = 15\n",
    "        if titulo_len > 80:\n",
    "            fs = 13\n",
    "        if titulo_len > 120:\n",
    "            fs = 11\n",
    "\n",
    "        axes[i][0].set_title(\n",
    "            titulo_exibido,\n",
    "            loc=\"left\",\n",
    "            fontsize=fs,\n",
    "            fontweight=\"bold\",\n",
    "            pad=20   # reduzido para não esmagar a figura\n",
    "        )\n",
    "\n",
    "        # Ajuste de margem superior por linha (evita compressão quando o título é grande)\n",
    "        fig.subplots_adjust(top=0.93)\n",
    "\n",
    "        # === 4️⃣ Gráfico à esquerda: Safra a Safra (empilhado) ===\n",
    "        ax1 = axes[i][0]\n",
    "        dist_pivot.plot(\n",
    "            kind=\"bar\",\n",
    "            stacked=True,\n",
    "            ax=ax1,\n",
    "            alpha=0.85,\n",
    "            width=0.85,\n",
    "            edgecolor=\"white\"\n",
    "        )\n",
    "        # ax1.set_title(f\"{titulo_exibido} — Evolução Safra a Safra\")\n",
    "        ax1.set_ylabel(\"% de categorias\")\n",
    "        ax1.set_xlabel(\"Safra\")\n",
    "        ax1.set_xticklabels(dist_pivot.index, rotation=45, ha=\"right\")\n",
    "        ax1.spines['top'].set_visible(False)\n",
    "        ax1.spines['right'].set_visible(False)\n",
    "        ax1.grid(False)\n",
    "        ax1.legend(title=var_cat, bbox_to_anchor=(0.5, -0.35), loc=\"upper center\", ncol=3)\n",
    "\n",
    "        # Linha de bad rate (eixo secundário)\n",
    "        ax1b = ax1.twinx()\n",
    "        for cat in bad_rate_pivot.columns:\n",
    "            ax1b.plot(\n",
    "                bad_rate_pivot.index,\n",
    "                bad_rate_pivot[cat],\n",
    "                marker=\"o\",\n",
    "                linewidth=2,\n",
    "                label=f\"{cat} (bad)\"\n",
    "            )\n",
    "        ax1b.set_ylabel(\"Bad rate (%)\")\n",
    "        ax1b.set_ylim(bottom=0)\n",
    "        ax1b.spines['top'].set_visible(False)\n",
    "        ax1b.grid(False)\n",
    "\n",
    "        # === 5️⃣ Gráfico à direita: Distribuição geral ===\n",
    "        ax2 = axes[i][1]\n",
    "        bars = ax2.bar(\n",
    "            pdf_spark_cat[var_cat],\n",
    "            pdf_spark_cat[\"pct\"],\n",
    "            color=\"#D3D3D3\",\n",
    "            alpha=0.85,\n",
    "            edgecolor=\"white\"\n",
    "        )\n",
    "        ax2.set_ylabel(\"% de registros\")\n",
    "        ax2.set_xlabel(var_cat)\n",
    "        ax2.tick_params(axis=\"x\", rotation=45)\n",
    "        # ax2.set_title(f\"{titulo_exibido} — Distribuição Geral\")\n",
    "        ax2.grid(False)\n",
    "        ax2.spines['top'].set_visible(False)\n",
    "        ax2.spines['right'].set_visible(False)\n",
    "\n",
    "        # Eixo esquerdo (sem casas decimais)\n",
    "        ax2.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{int(x)}\"))\n",
    "\n",
    "        # Adiciona % nas barras\n",
    "        for bar, pct in zip(bars, pdf_spark_cat[\"pct\"]):\n",
    "            ax2.text(\n",
    "                bar.get_x() + bar.get_width() / 2,\n",
    "                bar.get_height(),\n",
    "                f\"{pct:.0f}%\",\n",
    "                ha=\"center\",\n",
    "                va=\"bottom\",\n",
    "                fontsize=9\n",
    "            )\n",
    "\n",
    "        # Linha + valores de bad rate\n",
    "        ax2b = ax2.twinx()\n",
    "        ax2b.plot(\n",
    "            pdf_spark_cat[var_cat],\n",
    "            pdf_spark_cat[\"bad_rate\"],\n",
    "            color=\"#71C898\",\n",
    "            marker=\"o\",\n",
    "            linewidth=2\n",
    "        )\n",
    "        ax2b.set_ylabel(\"Bad rate (%)\", color=\"black\")\n",
    "        ax2b.set_ylim(bottom=0)\n",
    "        ax2b.grid(False)\n",
    "        ax2b.spines['top'].set_visible(False)\n",
    "        ax2b.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{int(x)}\"))\n",
    "\n",
    "        # Valores de bad rate nos pontos\n",
    "        for x, y in zip(pdf_spark_cat[var_cat], pdf_spark_cat[\"bad_rate\"]):\n",
    "            ax2b.text(\n",
    "                x,\n",
    "                y,\n",
    "                f\"{y:.0f}%\",\n",
    "                ha=\"center\",\n",
    "                va=\"bottom\",\n",
    "                fontsize=9,\n",
    "                color=\"#008060\",\n",
    "                fontweight=\"bold\"\n",
    "            )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    abs_path = os.path.abspath(save_path)\n",
    "    plt.savefig(abs_path, dpi=300, bbox_inches=\"tight\", format=\"jpeg\")\n",
    "    plt.close(fig)\n",
    "    print(f\"✅ Painel salvo em: {abs_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a796bff3-f4f4-47b8-a637-0c5f34894afc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "057fac03-2efc-4298-bfe8-7ff8215abf26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# def CrammerVCorrelation(data_spark, target, nsample = 100000):\n",
    "\n",
    "#     \"\"\"\n",
    "#     Calcula a correlação de Cramer's V para todas as variáveis em um DataFrame Spark, excluindo a variável target e outra para com todas as variáveis com a variável target.\n",
    "\n",
    "#     Args:\n",
    "#         data_spark (DataFrame): DataFrame Spark contendo os dados de entrada.\n",
    "#         target (str): Nome da coluna que contém o target.\n",
    "#         nsample (int, opcional): Tamanho máximo da amostra para o cálculo da correlação. O valor default é 100000.\n",
    "\n",
    "#     Returns:\n",
    "#         tuple: Dois DataFrames Pandas:\n",
    "#             - DataFrame de correlações de Cramer's V entre todas as variáveis, excluindo a variável target.\n",
    "#             - DataFrame de correlações de Cramer's V filtrado para a variável target e ordenado por valor.\n",
    "\n",
    "#     Raises:\n",
    "#         ValueError: Se o tamanho da amostra for menor ou igual a zero.\n",
    "        \n",
    "#     Example:\n",
    "#         >>> df_corr_matrix, df_target_corr = CrammerVCorrelation(data_spark=df_spark, target='target_column')\n",
    "#     \"\"\"\n",
    "\n",
    "#     #Transformando em pandas\n",
    "#     data_pandas = data_spark.toPandas()\n",
    "#     # Avaliando tamanho da amostra\n",
    "#     sizedata = len(data_pandas)\n",
    "#     # Validando o tamanho da amostra\n",
    "#     if sizedata > nsample:\n",
    "#         print(f\"O dataframe definido no parâmetro data_spark tem um tamanho de {sizedata}. Foi selecionada uma amostra com tamanho {nsample} para calculo do V-Crammer\")\n",
    "\n",
    "#         data_pandas = data_pandas.sample(frac=nsample/sizedata, random_state=42)\n",
    "    \n",
    "\n",
    "#     def cramers_V(var1, var2) :\n",
    "#         crosstab =np.array(pd.crosstab(var1, var2, rownames=None, colnames=None)) # Cross table building\n",
    "#         stat = chi2_contingency(crosstab)[0] # Keeping of the test statistic of the Chi2 test\n",
    "#         obs = np.sum(crosstab) # Number of observations\n",
    "#         mini = min(crosstab.shape)-1 # Take the minimum value between the columns and the rows of the cross table\n",
    "#         return np.sqrt(stat/(obs*mini))\n",
    "\n",
    "#     rows= []\n",
    "#     for var1 in data_pandas:\n",
    "#         col = []\n",
    "#         for var2 in data_pandas :\n",
    "#             cramers =cramers_V(data_pandas[var1], data_pandas[var2]) # Cramer's V test\n",
    "#             col.append(round(cramers,4)) # Keeping of the rounded value of the Cramer's V  \n",
    "#         rows.append(col)\n",
    "  \n",
    "#     cramers_results = np.array(rows)\n",
    "#     pd_cramers_results = pd.DataFrame(cramers_results, columns = data_pandas.columns, index =data_pandas.columns)\n",
    "\n",
    "#     return pd_cramers_results.drop(columns = target, index= target), pd_cramers_results.filter(regex = \"^\" + target).drop(index=target).sort_values(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fe226ba-5953-4ed1-bf83-485cd2b6b7de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# #Retorna uma lista de variaveis correlacionadas\n",
    "# def createCorrelatedFeaturesList(corrMatrix, threshold = 0.7):\n",
    "\n",
    "#     \"\"\"\n",
    "#     Retorna uma lista de variáveis correlacionadas com base em uma matriz de correlação fornecida e um limite de correlação.\n",
    "\n",
    "#     Args:\n",
    "#         corrMatrix (DataFrame): Matriz de correlação das variáveis.\n",
    "#         threshold (float, opcional): Limite de correlação para considerar variáveis como correlacionadas. O valor default é 0.7.\n",
    "\n",
    "#     Returns:\n",
    "#         list: Lista de variáveis correlacionadas.\n",
    "#     \"\"\"\n",
    "\n",
    "#     #Obtaining the correlation matrix of the dataframe (without the target)                        \n",
    "#     colCorr = []\n",
    "#     #Iterating through the columns of the correlation matrix dataframe\n",
    "#     for column in corrMatrix.columns:\n",
    "#         #Iterating through the values (row wise) of the correlation matrix dataframe\n",
    "#         for idx, row in corrMatrix.iterrows():                                            \n",
    "#             if(row[column] >= threshold) and (idx != column):\n",
    "#                 #Adding the features that are not already in the list of correlated features\n",
    "#                 if (idx not in colCorr):\n",
    "#                     colCorr.append(idx)\n",
    "#                 if (column not in colCorr):\n",
    "#                     colCorr.append(column)\n",
    "#     print(colCorr, '\\n')\n",
    "#     return colCorr\n",
    "\n",
    "# #função que deleta a feature mais recente \n",
    "# def deleteFeatures(data_pd, corrMatrix, corrWithTarget, colCorr, target):                                 \n",
    "#     for idx, row in corrWithTarget.iterrows():\n",
    "#         # print(idx, '\\n')\n",
    "#         if (idx in colCorr):\n",
    "#             print(f\"Coluna {idx} Deletada\")\n",
    "#             data_pd = data_pd.drop(idx, axis =1)\n",
    "#             corrWithTarget = corrWithTarget.drop(index = idx).sort_values(target)\n",
    "#             corrMatrix = corrMatrix.drop(columns = idx, index= idx)\n",
    "#             break\n",
    "#     return data_pd, corrMatrix, corrWithTarget, idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1e35e69-d10d-47db-95a9-7250ce3b0bf8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# #Method to run automatically eliminate multicollinearity\n",
    "# def autoEliminateMulticollinearity(data_spark, list_keys, list_features, target, threshold = 0.9, nsample = 100000):\n",
    "    \n",
    "#     \"\"\"\n",
    "#     Deleta a feature menos relavante com a variável resposta da lista de variáveis correlacionadas entre si no DataFrame.\n",
    "\n",
    "#     Args:\n",
    "#         data_pd (DataFrame): DataFrame contendo os dados.\n",
    "#         corrMatrix (DataFrame): Matriz de correlação das variáveis.\n",
    "#         corrWithTarget (DataFrame): Correlação das variáveis com o target.\n",
    "#         colCorr (list): Lista de variáveis correlacionadas.\n",
    "#         target (str): Nome da coluna target.\n",
    "\n",
    "#     Returns:\n",
    "#         tuple: DataFrame atualizado, matriz de correlação atualizada, correlação com o target atualizada e a variável deletada.\n",
    "\n",
    "#     Example:\n",
    "#         >>> data_spark_updated, features_removed = autoEliminateMulticollinearity(\n",
    "#         >>>     data_spark=df_spark,\n",
    "#         >>>     list_keys=['key1', 'key2'],\n",
    "#         >>>     list_features=['feature1', 'feature2', 'feature3'],\n",
    "#         >>>     target='target_column',\n",
    "#         >>>     threshold=0.9,\n",
    "#         >>>     nsample=100000\n",
    "#         >>> )\n",
    "        \n",
    "#     \"\"\"\n",
    "#     #######Validacoes#######\n",
    "#     #validando se a lista esta presente na tabela de input\n",
    "#     if list_features != None:\n",
    "#         list_not_in = [column for column in list_features if column not in data_spark.columns]\n",
    "#         if list_not_in != []:\n",
    "#             raise ValueError(f\"A lista de features {list_not_in} do parâmetro list_features para categorização não esta presente na tabela de input, especificado no parâmetro data_spark.\")\n",
    "\n",
    "#     if target not in data_spark.columns:\n",
    "#         raise ValueError(f\"A variavel {target} especificada no parâmetro target não esta presente no tabela de input, especificado no parâmetro data_spark.\")\n",
    "      \n",
    "#     #validando se o target é binario\n",
    "#     target_value  = data_spark.select(target).distinct().rdd.flatMap(lambda row: row).collect()\n",
    "#     result_bool = all(value in [1, 0] for value in target_value)\n",
    "\n",
    "#     if result_bool == False:\n",
    "#         raise ValueError(f\"A variavel {target} especificada no parâmetro target possui os seguintes valores {target_value}, logo o processo binning foi desenvolvido para problemas de classificação assumindo somente valores (0,1).\")\n",
    "\n",
    "#     if threshold < 0 or threshold > 1:\n",
    "#         raise ValueError(\"O valor do threshold tem que ser entre [0, 1].\")\n",
    "\n",
    "#     print(\"Fazendo Correlação de Crammer\")\n",
    "#     table_crammer, table_crammer_resp  = CrammerVCorrelation(data_spark = data_spark.selectExpr(*list_features, target), target = target, nsample = nsample)\n",
    "\n",
    "#     #listando features altamente correlacionadas\n",
    "#     ListColCorr = createCorrelatedFeaturesList(corrMatrix = table_crammer, threshold = threshold)\n",
    "\n",
    "\n",
    "#     table_crammer_input, table_crammer_resp_input  = table_crammer, table_crammer_resp\n",
    "\n",
    "\n",
    "#     print(f\"Features com correlação maior que {threshold}:{ListColCorr}\")\n",
    "\n",
    "#     data_pandas = data_spark.selectExpr(*list_features, target).toPandas()\n",
    "#     colCorrcand = ListColCorr\n",
    "\n",
    "#     feature_remove = []\n",
    "\n",
    "#     while colCorrcand != []:\n",
    "#         #seleciona um dataframe que remove da lista de features correlacionadas a com menor correlação com a variavel resposta\n",
    "#         data_pandas, table_crammer_input, table_crammer_resp_input, f_remove  = deleteFeatures(data_pd = data_pandas, corrMatrix = table_crammer_input, corrWithTarget = table_crammer_resp_input, colCorr = colCorrcand, target = target)\n",
    "\n",
    "#         feature_remove.append(f_remove)\n",
    "\n",
    "#         #Obtaining the list of correlated features\n",
    "#         colCorrcand = createCorrelatedFeaturesList(table_crammer_input, threshold= threshold)\n",
    "    \n",
    "#     feature_columns = data_pandas.drop(columns=[target]).columns \n",
    "#     return data_spark.selectExpr(*list_keys, *feature_columns), feature_columns, feature_remove, table_crammer, table_crammer_resp_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "08b8271f-f24d-4a1b-9b0c-088bcdbd8348",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "def cramers_V(var1, var2):\n",
    "    confusion_matrix = pd.crosstab(var1, var2)\n",
    "    chi2 = chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    phi2 = chi2 / n\n",
    "    r, k = confusion_matrix.shape\n",
    "    phi2corr = max(0, phi2 - ((k - 1)*(r - 1)) / (n - 1))    \n",
    "    rcorr = r - ((r - 1)**2) / (n - 1)\n",
    "    kcorr = k - ((k - 1)**2) / (n - 1)\n",
    "    return np.sqrt(phi2corr / min((kcorr - 1), (rcorr - 1)))\n",
    "\n",
    "def calc_iv(df, feature, target, bins=10):\n",
    "    \"\"\"\n",
    "    Calcula o Information Value para uma feature.\n",
    "    A feature pode estar já em WOE ou ser categórica.\n",
    "    \"\"\"\n",
    "    tmp = df[[feature, target]].copy()\n",
    "    tmp[feature] = tmp[feature].fillna(\"MISSING\")\n",
    "    if tmp[feature].dtype.kind in \"bifc\":  # Numérica\n",
    "        tmp['bin'] = pd.qcut(tmp[feature], q=bins, duplicates='drop')\n",
    "    else:\n",
    "        tmp['bin'] = tmp[feature]\n",
    "\n",
    "    grouped = tmp.groupby('bin')[target].agg(['count', 'sum'])\n",
    "    grouped['non_event'] = grouped['count'] - grouped['sum']\n",
    "    grouped['event_rate'] = grouped['sum'] / grouped['sum'].sum()\n",
    "    grouped['non_event_rate'] = grouped['non_event'] / grouped['non_event'].sum()\n",
    "    grouped['woe'] = np.log((grouped['event_rate'] + 1e-9) / (grouped['non_event_rate'] + 1e-9))\n",
    "    grouped['iv'] = (grouped['event_rate'] - grouped['non_event_rate']) * grouped['woe']\n",
    "    return grouped['iv'].sum()\n",
    "\n",
    "\n",
    "def buildHybridCorrelationMatrix(df_pd, list_features_num, list_features_cat, method_num='spearman'):\n",
    "    all_features = list_features_num + list_features_cat\n",
    "    matrix = pd.DataFrame(index=all_features, columns=all_features)\n",
    "\n",
    "    # Correlação entre numéricas\n",
    "    for i in list_features_num:\n",
    "        for j in list_features_num:\n",
    "            matrix.loc[i, j] = abs(df_pd[i].corr(df_pd[j], method=method_num))\n",
    "\n",
    "    # Correlação entre categóricas\n",
    "    for i in list_features_cat:\n",
    "        for j in list_features_cat:\n",
    "            matrix.loc[i, j] = cramers_V(df_pd[i], df_pd[j])\n",
    "\n",
    "    # Correlação entre tipos diferentes é indefinida\n",
    "    for i in list_features_cat:\n",
    "        for j in list_features_num:\n",
    "            matrix.loc[i, j] = np.nan\n",
    "            matrix.loc[j, i] = np.nan\n",
    "\n",
    "    return matrix.astype(float)\n",
    "\n",
    "def createCorrelatedFeaturesList(corrMatrix, threshold=0.7):\n",
    "    colCorr = []\n",
    "    for column in corrMatrix.columns:\n",
    "        for idx, row in corrMatrix.iterrows():\n",
    "            if pd.notnull(row[column]) and (row[column] >= threshold) and (idx != column):\n",
    "                if idx not in colCorr:\n",
    "                    colCorr.append(idx)\n",
    "                if column not in colCorr:\n",
    "                    colCorr.append(column)\n",
    "    return colCorr\n",
    "\n",
    "def deleteFeatures(data_pd, corrMatrix, corrWithTarget, colCorr, target):\n",
    "    for idx, row in corrWithTarget.iterrows():\n",
    "        if idx in colCorr:\n",
    "            data_pd = data_pd.drop(idx, axis=1)\n",
    "            corrWithTarget = corrWithTarget.drop(index=idx).sort_values(target)\n",
    "            corrMatrix = corrMatrix.drop(columns=idx, index=idx)\n",
    "            break\n",
    "    return data_pd, corrMatrix, corrWithTarget, idx\n",
    "\n",
    "def autoEliminateMulticollinearityHybrid(data_spark, list_keys, list_features_num, list_features_cat, target, threshold=0.9, nsample=100000, method_num='spearman', target_metric ='iv'):\n",
    "    # Validações\n",
    "    all_features = list_features_num + list_features_cat\n",
    "\n",
    "    if any(col not in data_spark.columns for col in all_features):\n",
    "        raise ValueError(\"Alguma coluna em list_features não está presente na tabela de input.\")\n",
    "\n",
    "    if target not in data_spark.columns:\n",
    "        raise ValueError(\"A variável target não está presente na tabela de input.\")\n",
    "\n",
    "    # Valida target binário\n",
    "    target_value = data_spark.select(target).distinct().rdd.flatMap(lambda row: row).collect()\n",
    "    if not all(value in [0, 1] for value in target_value):\n",
    "        raise ValueError(f\"Target deve ser binário. Valores encontrados: {target_value}\")\n",
    "\n",
    "    if threshold < 0 or threshold > 1:\n",
    "        raise ValueError(\"Threshold deve estar entre 0 e 1.\")\n",
    "\n",
    "    # Amostragem\n",
    "    df_pd = data_spark.select(*all_features, target).toPandas()\n",
    "    if len(df_pd) > nsample:\n",
    "        df_pd = df_pd.sample(n=nsample, random_state=42)\n",
    "\n",
    "    # Matriz híbrida\n",
    "    corrMatrix = buildHybridCorrelationMatrix(df_pd, list_features_num, list_features_cat, method_num=method_num)\n",
    "\n",
    "    # Correlação ou IV com o target\n",
    "    corr_target = {}\n",
    "    for col in all_features:\n",
    "        if target_metric == 'iv':\n",
    "            corr_target[col] = calc_iv(df_pd, col, target)\n",
    "        else:\n",
    "            if col in list_features_cat:\n",
    "                corr_target[col] = cramers_V(df_pd[col], df_pd[target])\n",
    "            else:\n",
    "                corr_target[col] = abs(df_pd[col].corr(df_pd[target], method=method_num))\n",
    "\n",
    "\n",
    "    df_target_corr = pd.DataFrame.from_dict(corr_target, orient='index', columns=[target]).sort_values(by=target, ascending=True)\n",
    "\n",
    "    df_target_corr_sup = df_target_corr\n",
    "    corrMatrix_sup = corrMatrix\n",
    "\n",
    "    colCorrcand = createCorrelatedFeaturesList(corrMatrix, threshold=threshold)\n",
    "    feature_remove = []\n",
    "\n",
    "    while colCorrcand != []:\n",
    "        df_pd, corrMatrix_sup, df_target_corr_sup, f_remove = deleteFeatures(df_pd, corrMatrix_sup, df_target_corr_sup, colCorrcand, target)\n",
    "        feature_remove.append(f_remove)\n",
    "        colCorrcand = createCorrelatedFeaturesList(corrMatrix_sup, threshold=threshold)\n",
    "\n",
    "    selected_features = df_pd.drop(columns=[target]).columns.tolist()\n",
    "    df_final = data_spark.select(*list_keys, *selected_features)\n",
    "\n",
    "    return df_final, selected_features, feature_remove, corrMatrix, df_target_corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f01fcc8-9b91-49c3-8e99-7ce5e854d779",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def fs_moda(df: DataFrame, colunas: list, threshold: float = 0.9):\n",
    "    \"\"\"\n",
    "    Calcula a moda e sua porcentagem para várias colunas de forma eficiente.\n",
    "\n",
    "    Parâmetros:\n",
    "        df (DataFrame): DataFrame de entrada\n",
    "        colunas (list): Lista de colunas categóricas ou discretas\n",
    "        threshold (float): Valor de corte da porcentagem da moda\n",
    "\n",
    "    Retorna:\n",
    "        Tuple:\n",
    "            - DataFrame com colunas ['variavel', 'moda', 'porcentagem']\n",
    "            - Lista de variáveis abaixo do threshold\n",
    "            - Lista de variáveis acima ou igual ao threshold\n",
    "    \"\"\"\n",
    "    if not colunas:\n",
    "        empty_df = df.sparkSession.createDataFrame([], schema=\"variavel string, moda string, porcentagem double\")\n",
    "        return empty_df, [], []\n",
    "\n",
    "    # Transforma em formato long\n",
    "    df_long = df.select([f.col(c).cast(\"string\").alias(c) for c in colunas]) \\\n",
    "                .select(f.explode(f.array([\n",
    "                    f.struct(f.lit(c).alias(\"variavel\"), f.col(c).alias(\"valor\"))\n",
    "                    for c in colunas\n",
    "                ])).alias(\"kv\")) \\\n",
    "                .select(\"kv.variavel\", \"kv.valor\")\n",
    "\n",
    "    total_por_coluna = df_long.groupBy(\"variavel\").agg(f.count(\"*\").alias(\"total\"))\n",
    "\n",
    "    moda_df = (\n",
    "        df_long.groupBy(\"variavel\", \"valor\")\n",
    "               .agg(f.count(\"*\").alias(\"frequencia\"))\n",
    "               .join(total_por_coluna, on=\"variavel\", how=\"left\")\n",
    "               .withColumn(\"porcentagem\", f.round(f.col(\"frequencia\") / f.col(\"total\"), 4))\n",
    "               .withColumn(\"rank\", f.row_number().over(Window.partitionBy(\"variavel\").orderBy(f.desc(\"frequencia\"))))\n",
    "               .filter(f.col(\"rank\") == 1)\n",
    "               .select(\n",
    "                   f.col(\"variavel\"),\n",
    "                   f.col(\"valor\").alias(\"moda\"),\n",
    "                   f.col(\"porcentagem\")\n",
    "               )\n",
    "    )\n",
    "\n",
    "    abaixo = (\n",
    "        moda_df.filter(f.col(\"porcentagem\") < threshold)\n",
    "               .select(\"variavel\")\n",
    "               .rdd.flatMap(lambda x: x)\n",
    "               .collect()\n",
    "    )\n",
    "\n",
    "    acima = (\n",
    "        moda_df.filter(f.col(\"porcentagem\") >= threshold)\n",
    "               .select(\"variavel\")\n",
    "               .rdd.flatMap(lambda x: x)\n",
    "               .collect()\n",
    "    )\n",
    "\n",
    "    return moda_df, abaixo, acima\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d8bb71a-f41b-4921-a102-bbd9288454a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def features_binning_process(data_spark, list_keys, target, list_features_num = None, list_features_cat = None, list_exception_code = None, dev = None, max_nsample = 100000, metric_bin = \"woe\", is_features_cat_default = False, n_bins = None):\n",
    "\n",
    "       \"\"\"\n",
    "       Realiza o binning em features numéricas e categóricas em um DataFrame Spark para problemas de classificação binária. Olhar exemplos para entender outputs.\n",
    "       \n",
    "       Args:\n",
    "           data_spark (DataFrame): O DataFrame Spark contendo os dados de entrada.\n",
    "           list_keys (list): Uma lista de colunas a serem usadas como chaves de identificação.\n",
    "           target (str): O nome da coluna target, que deve ser binária (0 e 1).\n",
    "           list_features_num (list, opcional): Uma lista de colunas de features numéricas a serem categorizadas. \n",
    "           Default é None.\n",
    "           list_features_cat (list, opcional): Uma lista de colunas de features categóricas a serem categorizadas.\n",
    "           Default é None.\n",
    "           list_exception_code (list, opcional): Uma lista de códigos de exceção a serem considerados durante o\n",
    "           binning. Default é None.\n",
    "           dev (str, opcional): O nome da coluna usada para filtrar o conjunto de desenvolvimento. Esta coluna deve ser\n",
    "           do tipo booleano (True/False). Default é None.\n",
    "           max_nsample (int, opcional): O número máximo de amostras a serem usadas no processo de binning. Default é\n",
    "           100000.\n",
    "           metric_bin (str, opcional): A métrica a ser usada para o binning. Valores possíveis são 'woe','event_rate',\n",
    "           'indices' e 'bins'. Default é \"woe\".\n",
    "           is_features_cat_default (bool, opcional): Uma flag indicando se as features categóricas devem ser tratadas\n",
    "           com configurações Default, ou seja não realizara agrupamentos. Default é False. caso selecionado True deverá ser inserido no output mas um objeto como no exemplo 2. Caso seja True, obrigatóriamente é necessário passar uma lista em list_features_cat\n",
    "       \n",
    "       Returns:\n",
    "           tuple: \n",
    "               - DataFrame Spark com as features categorizadas.\n",
    "               - Objeto do processo de binning para features numéricas (se aplicável).\n",
    "               - Objeto do processo de binning para features categóricas (se aplicável).\n",
    "       \n",
    "       Raises:\n",
    "           ValueError: Se nenhuma lista de features for fornecida.\n",
    "           ValueError: Se as features especificadas não estiverem presentes no DataFrame de entrada.\n",
    "           ValueError: Se a coluna target não for binária.\n",
    "           ValueError: Se as features numéricas não forem do tipo NumericType.\n",
    "           ValueError: Se as features categóricas não forem do tipo StringType.\n",
    "           ValueError: Se a métrica especificada não for válida.\n",
    "           ValueError: Se a coluna de desenvolvimento não for booleana.\n",
    "       \n",
    "       Example:\n",
    "           >>> data_spark_cat_bins, binning_process, binning_process_cat = features_binning_process(\n",
    "           >>>     data_spark=df_spark,\n",
    "           >>>     list_keys=['key1', 'key2'],\n",
    "           >>>     target='target_column',\n",
    "           >>>     list_features_num=['num_feature1', 'num_feature2'],\n",
    "           >>>     list_features_cat=['cat_feature1', 'cat_feature2'],\n",
    "           >>>     list_exception_code=[999, -1],\n",
    "           >>>     dev='dev_column',\n",
    "           >>>     max_nsample=100000,\n",
    "           >>>     metric_bin='woe',\n",
    "           >>>     is_features_cat_default=True)\n",
    "       \n",
    "\n",
    "           >>> data_spark_cat_bins, binning_process = features_binning_process(\n",
    "           >>>     data_spark=df_spark,\n",
    "           >>>     list_keys=['key1', 'key2'],\n",
    "           >>>     target='target_column',\n",
    "           >>>     list_features_num=['num_feature1', 'num_feature2'],\n",
    "           >>>     list_features_cat=['cat_feature1', 'cat_feature2'],\n",
    "           >>>     list_exception_code=[999, -1],\n",
    "           >>>     dev='dev_column',\n",
    "           >>>     max_nsample=100000,\n",
    "           >>>     metric_bin='woe',\n",
    "           >>>     is_features_cat_default=False)\n",
    "       \"\"\"\n",
    "\n",
    "       # Validação se existe uma lista de features:\n",
    "       if list_features_num == None and list_features_cat == None:\n",
    "              raise ValueError(\"É necessário passar uma lista de features no parâmetro list_features_num ou/e list_features_cat para categorização.\")\n",
    "\n",
    "       #validando se a lista esta presente na tabela de input\n",
    "       if list_features_num != None:\n",
    "              list_not_in = [column for column in list_features_num if column not in data_spark.columns]\n",
    "              if list_not_in != []:\n",
    "                     raise ValueError(f\"A lista de features {list_not_in} do parâmetro list_features_num para categorização não esta presente na tabela de input, especificado no parâmetro data_spark.\")\n",
    " \n",
    "       if list_features_cat != None:\n",
    "              list_not_in_cat = [column for column in list_features_cat if column not in data_spark.columns]\n",
    "              if list_not_in_cat != []:\n",
    "                     raise ValueError(f\"A lista de features {list_not_in_cat} do parâmetro list_features_cat para categorização não esta presente na tabela de input, especificado no parâmetro data_spark.\")\n",
    "\n",
    "       if target not in data_spark.columns:\n",
    "             raise ValueError(f\"A variavel {target} especificada no parâmetro target não esta presente no tabela de input, especificado no parâmetro data_spark.\")\n",
    "      \n",
    "\n",
    "       if dev != None:\n",
    "              if dev not in data_spark.columns:\n",
    "                     raise ValueError(f\"A variavel {dev} especificada no parâmetro dev não esta presente no tabela de input, especificado no parâmetro data_spark.\")      \n",
    "\n",
    "\n",
    "       if dev != None:\n",
    "              type_bool_columns = [col.name for col in data_spark.selectExpr(dev).schema.fields if isinstance(col.dataType, BooleanType)]\n",
    "\n",
    "              if type_bool_columns != [dev]:\n",
    "                     raise ValueError(f\"A feature {dev} definida no parâmetro dev precisa ser do tipo booleano (True e False)\")\n",
    "      \n",
    "       #validando se o target é binario\n",
    "\n",
    "       if dev != None:\n",
    "              target_value  = data_spark.filter(f.col(dev) == True).select(target).distinct().rdd.flatMap(lambda row: row).collect()\n",
    "              result_bool = all(value in [1, 0] for value in target_value)\n",
    "\n",
    "       if dev == None:\n",
    "              target_value  = data_spark.select(target).distinct().rdd.flatMap(lambda row: row).collect()\n",
    "              result_bool = all(value in [1, 0] for value in target_value)\n",
    "\n",
    "\n",
    "       if result_bool == False:\n",
    "              raise ValueError(f\"A variavel {target} especificada no parâmetro target possui os seguintes valores {target_value}, logo o processo binning foi desenvolvido para problemas de classificação assumindo somente valores (0,1).\")\n",
    "\n",
    "       # #Verificando se as colunas listadas como numericas são numericas no dataset\n",
    "       if list_features_num != None:\n",
    "              type_num_columns = [col.name for col in data_spark.selectExpr(*list_features_num).schema.fields  if isinstance(col.dataType, NumericType)]\n",
    "              #comparando lista numerica vs. lista dataset numerica\n",
    "              type_num_list_not_in = [column for column in list_features_num if column not in type_num_columns]\n",
    "\n",
    "              if type_num_list_not_in != []:\n",
    "                     raise ValueError(f\"A lista de features do parâmetro list_features_num precisam ser do tipo NumericType. As features {type_num_list_not_in} estão presentes na lista mas não são do tipo  NumericType na tabela de input, especificado no parâmetro data_spark.\")\n",
    "\n",
    "       #Verificando se as colunas listadas como string são strings no dataset\n",
    "       if list_features_cat != None:\n",
    "              type_string_columns = [col.name for col in data_spark.selectExpr(*list_features_cat).schema.fields  if isinstance(col.dataType, StringType)]\n",
    "              #comparando lista string vs. lista dataset string\n",
    "              type_string_list_not_in = [column for column in list_features_cat if column not in type_string_columns]\n",
    "              \n",
    "              if type_string_list_not_in != []:\n",
    "                     raise ValueError(f\"A lista de features do parâmetro list_features_cat precisam ser do tipo StringType. As features {type_string_list_not_in} estão presentes na lista mas não são do tipo  StringType na tabela de input, especificado no parâmetro data_spark.\")\n",
    "\n",
    "       #Validando se metrica indicada é valida\n",
    "\n",
    "       list_possible_metrics = ['woe', 'event_rate', 'indices', 'bins']\n",
    "       metric_result_valid = [column for column in list_possible_metrics if column in metric_bin.lower()]\n",
    "\n",
    "\n",
    "       if metric_result_valid == []:\n",
    "              raise ValueError(f\"A Métrica {metric_bin} especificada no parâmetro metric não esta presente nas possibilidades: {list_possible_metrics}. Escolha uma dessas informações para retorno da categorização.\")\n",
    "\n",
    "       metric_bin = metric_bin.lower()\n",
    "\n",
    "       #Processo Binning\n",
    "       #Verificando se o data set possui uma marcacao dev\n",
    "\n",
    "       #remover duplicatas\n",
    "       data_spark_temp = data_spark.dropDuplicates(list_keys)\n",
    "       data_pandas, data_pandas_temp = data_spark_temp.toPandas(), data_spark_temp.toPandas()\n",
    "\n",
    "       if data_spark_temp.count() < data_spark.count():\n",
    "              print(f\"O dataframe de input tem linhas duplicatas quando verificado as chaves {list_keys}, logo seu output final sera uma dataframe pyspark com {data_spark_temp.count()} linhas\")\n",
    "\n",
    "       data_pandas_temp['dev_opbinning'] = True\n",
    "\n",
    "       dev_opbinning = 'dev_opbinning'\n",
    "\n",
    "       if dev is None:\n",
    "              print(\"Não foi especificada uma coluna para treinar o processo de categorização, logo será utilizado `100%` da sua base para criar o modelo binning.\")\n",
    "              dev = 'dev_opbinning'\n",
    "       \n",
    "       data_pandas_temp = data_pandas_temp[data_pandas_temp[dev] == True]\n",
    "\n",
    "       #criando lista de flags de exceção\n",
    "       if list_exception_code != None:\n",
    "              list_exception = {f\"special_{i+1}\": value for i, value in enumerate(list_exception_code)}\n",
    "       else:\n",
    "              list_exception = None\n",
    "\n",
    "       # Avaliando tamanho da amostra\n",
    "       sizedata = len(data_pandas_temp)\n",
    "\n",
    "       print('Base Filtrando Dev:',len(data_pandas_temp))\n",
    "\n",
    "       # Validando o tamanho da amostra\n",
    "       if sizedata > max_nsample:\n",
    "              print(f\"O dataframe definido no parâmetro data_spark tem um tamanho de {sizedata}. Foi selecionada uma amostra com tamanho {max_nsample} para o processo de binning\")\n",
    "              data_pandas_temp = data_pandas_temp.sample(frac=max_nsample/sizedata, random_state=42)\n",
    "\n",
    "       print('Base Filtrando Final:', len(data_pandas_temp))\n",
    "\n",
    "\n",
    "       #Criando data set treino\n",
    "       # data_pandas_train_features, data_pandas_train_target = data_pandas_temp[(list_features_num or []) + (list_features_cat or [])], data_pandas_temp[target]\n",
    "\n",
    "       data_pandas_train_features = data_pandas_temp[(list_features_num or []) + (list_features_cat or [])].copy(); data_pandas_train_target = data_pandas_temp[target].copy()\n",
    "\n",
    "       #Criando processo binning\n",
    "       if is_features_cat_default is False:\n",
    "              binning_process = BinningProcess(variable_names = (list_features_num or []) + (list_features_cat or []), categorical_variables = (list_features_cat or []), special_codes = list_exception, max_n_bins = n_bins)\n",
    "\n",
    "              binning_process.fit(data_pandas_train_features.filter(items = (list_features_num or []) + (list_features_cat or [])), data_pandas_train_target)\n",
    "\n",
    "              pd_woe_binning_process = binning_process.transform(data_pandas.filter(items = (list_features_num or []) + (list_features_cat or [])), metric = metric_bin)\n",
    "\n",
    "              base_join_cat_bins = (\n",
    "                     data_pandas[list_keys]\n",
    "                    .merge(data_pandas_temp.filter(items = list_keys + [dev_opbinning]), \n",
    "                           how = 'left', on = list_keys) \n",
    "                    .merge(pd_woe_binning_process, \n",
    "                           left_index = True, \n",
    "                           right_index = True, \n",
    "                           how = 'left'))\n",
    "              \n",
    "\n",
    "       if is_features_cat_default is True:\n",
    "\n",
    "              if list_features_num != None:\n",
    "\n",
    "                     binning_process = BinningProcess(variable_names = list_features_num, special_codes = list_exception, max_n_bins = n_bins)\n",
    "\n",
    "                     binning_process.fit(data_pandas_train_features[list_features_num],    data_pandas_train_target)\n",
    "\n",
    "                     pd_woe_binning_process = binning_process.transform(data_pandas.filter(items =      list_features_num), metric = metric_bin)\n",
    "\n",
    "              binning_process_cat = BinningProcess(variable_names = list_features_cat, categorical_variables = list_features_cat, min_prebin_size = 0.000000001, special_codes = list_exception, max_n_bins = n_bins)\n",
    "\n",
    "              binning_process_cat.fit(data_pandas_train_features[list_features_cat], data_pandas_train_target)\n",
    "              \n",
    "              pd_woe_binning_process_cat = binning_process_cat.transform(data_pandas.filter(items = list_features_cat), metric = metric_bin)\n",
    "\n",
    "\n",
    "              if list_features_num != None:\n",
    "                     base_join_cat_bins = (\n",
    "                            data_pandas[list_keys]\n",
    "                            .merge(data_pandas_temp[list_keys + [dev_opbinning]],\n",
    "                                   how = 'left', on = list_keys)\n",
    "                            .merge(pd_woe_binning_process, \n",
    "                                   left_index = True, \n",
    "                                   right_index = True, \n",
    "                                   how = 'left')\n",
    "                            .merge(pd_woe_binning_process_cat, \n",
    "                                   left_index = True, \n",
    "                                   right_index = True, \n",
    "                                   how = 'left'))\n",
    "              else:\n",
    "                     base_join_cat_bins = (\n",
    "                            data_pandas[list_keys]\n",
    "                            .merge(data_pandas_temp[list_keys + [dev_opbinning]], \n",
    "                                  how = 'left', on = list_keys)\n",
    "                            .merge(pd_woe_binning_process_cat, \n",
    "                                  left_index = True, \n",
    "                                  right_index = True, \n",
    "                                  how = 'left'))\n",
    "              \n",
    "                     \n",
    "       data_spark_cat_bins = spark.createDataFrame(base_join_cat_bins).fillna(False, subset= [dev_opbinning])\n",
    "\n",
    "       try:\n",
    "              binning_process  # Tenta acessar o objeto\n",
    "       except NameError:\n",
    "              binning_process = None  # Se não existir, define como None\n",
    "\n",
    "       try:\n",
    "              binning_process_cat  # Tenta acessar o objeto\n",
    "       except NameError:\n",
    "              binning_process_cat = None  # Se não existir, define como None\n",
    "              \n",
    "       if binning_process is None:\n",
    "              return data_spark_cat_bins, binning_process_cat\n",
    "       if binning_process_cat is None:      \n",
    "              return data_spark_cat_bins, binning_process\n",
    "       else:\n",
    "              return data_spark_cat_bins, binning_process, binning_process_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf29c65a-b730-41ee-aaa2-4a4784ca20fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def apply_binning_process(data_spark, model_object, list_keys, list_features, metric_bin = \"woe\"):\n",
    "\n",
    "    \"\"\"\n",
    "    Aplica um processo de binning (categorização) em um DataFrame Spark com base em um objeto de modelo fornecido.\n",
    "\n",
    "    Args:\n",
    "        data_spark (DataFrame): DataFrame Spark contendo os dados de entrada que serão categorizados.\n",
    "        model_object (Model Object): Objeto de modelo que contém as informações de binning para as variáveis (saídas de\n",
    "        features_binning_process).\n",
    "        list_keys (list): Lista de chaves (colunas) que serão mantidas no DataFrame final.\n",
    "        list_features (list): Lista de variáveis (colunas) que serão categorizadas.\n",
    "        metric_bin (str, opcional): Métrica a ser usada para o processo de binning. As opções possíveis são 'woe',\n",
    "        'event_rate', 'indices', e 'bins'. O valor default é 'woe'.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame Spark com as variáveis categorizadas.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: Se qualquer coluna especificada em `list_features` não estiver presente no DataFrame de entrada\n",
    "                    (`data_spark`) ou no objeto de modelo (`model_object`).\n",
    "        ValueError: Se a métrica especificada em `metric_bin` não for uma das opções válidas.\n",
    "\n",
    "    Example:\n",
    "        >>> df_spark_cat_bins = apply_binning_process(data_spark=df_spark, model_object=model, list_keys=['key1', 'key2'], list_features=['feature1', 'feature2'])\n",
    "    \"\"\"\n",
    "\n",
    "    #features no arquivo objeto do modelo\n",
    "    features_cat = spark.createDataFrame(model_object.summary()).select(\"name\").distinct().rdd.flatMap(lambda row: row).collect()\n",
    "\n",
    "    #validando se a lista esta presente na tabela de input pu no objeto do modelo\n",
    "    list_not_in = [column for column in list_features if column not in data_spark.columns]\n",
    "    list_not_in_model = [column for column in list_features if column not in features_cat]\n",
    "\n",
    "    if list_not_in != []:\n",
    "        raise ValueError(f\"A lista de features {list_not_in} para categorização não esta presente na tabela de input, parametro data_spark.\")\n",
    "    \n",
    "    if list_not_in_model != []:\n",
    "        raise ValueError(f\"A lista de features {list_not_in_model} para categorização não esta presente no artefato do modelo, parametro model_object.\")\n",
    "\n",
    "    #Validando se metrica indicada é valida\n",
    "\n",
    "    list_possible_metrics = ['woe', 'event_rate', 'indices', 'bins']\n",
    "    metric_result_valid = [column for column in list_possible_metrics if column in metric_bin.lower()]\n",
    "    metric_bin = metric_bin.lower()\n",
    "\n",
    "    if metric_result_valid == []:\n",
    "        raise ValueError(f\"A Métrica {metric_bin} especificada no parâmetro metric não esta presente nas possibilidades: {list_possible_metrics}. Escolha uma dessas informações para retorno da categorização.\")\n",
    "\n",
    "    #transformando data set em pandas\n",
    "    data_pandas = data_spark.toPandas()\n",
    "\n",
    "    #Calculando os woe por feature listada\n",
    "    for i in list_features:\n",
    "        print(\"Categorizando Feature:\", i)\n",
    "        # Obter o binned variable específico\n",
    "        optb = model_object.get_binned_variable(i)\n",
    "\n",
    "        # Aplicar a transformação de binning para a coluna específica na nova base\n",
    "        data_pandas[i] = optb.transform(data_pandas[i], metric = metric_bin)\n",
    "\n",
    "    # Data set final escorado\n",
    "    data_spark_cat_bins = spark.createDataFrame(data_pandas.filter(items = list_keys + list_features))\n",
    "\n",
    "    return(data_spark_cat_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c0efbfe-41d9-4f81-b68c-59c5728c3404",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def fs_iv(model_object, threshold = 0.01):\n",
    "    \"\"\"\n",
    "    Filtra e seleciona features com base no Information Value (IV) de um modelo feito pelo process binning.\n",
    "\n",
    "    Args:\n",
    "        model_object : Objeto do modelo treinado que suporta o método. Geralmente, é um modelo de binning (Saida de\n",
    "        features_binning_process).\n",
    "\n",
    "        threshold (float, optional): Limite mínimo de IV para considerar uma feature como relevante. Features com\n",
    "        abaixo desse valor serão removidas. Default é 0.01.\n",
    "\n",
    "    Returns:\n",
    "        tuple[DataFrame, list[str], list[str]]:\n",
    "            - DataFrame: Tabela contendo o resumo das features, número de bins e IV arredondado.\n",
    "            - list[str]: Lista de features selecionadas (IV >= threshold).\n",
    "            - list[str]: Lista de features removidas (IV < threshold).\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: Se o `threshold` for negativo ou inválido.\n",
    "    \n",
    "    Example:\n",
    "        >>> table_summary, selected_features, removed_features = fs_iv(model, threshold=0.05)\n",
    "        >>> print(\"Features selecionadas:\", selected_features)\n",
    "        >>> print(\"Features removidas:\", removed_features)\n",
    "    \"\"\"\n",
    "\n",
    "    #Selecinonando Tabela\n",
    "    table_describe_num = spark.createDataFrame(model_object.summary())\n",
    "    table_describe_num = (table_describe_num\n",
    "                          .selectExpr(\"name as Features\", \"n_bins as qtd_bins\", \"iv as information_value\")\n",
    "                          .withColumn(\"information_value\", f.round(f.col(\"information_value\"), 4)))\n",
    "    \n",
    "    list_features_selection = (table_describe_num\n",
    "                               .filter(f.col(\"information_value\") >= threshold)\n",
    "                               .select(\"Features\")\n",
    "                               .distinct()\n",
    "                               .rdd.flatMap(lambda row: row)\n",
    "                               .collect())\n",
    "\n",
    "    not_list_features_selection = (table_describe_num\n",
    "                                   .filter(f.col(\"information_value\") < threshold)\n",
    "                                   .select(\"Features\")\n",
    "                                   .distinct()\n",
    "                                   .rdd.flatMap(lambda row: row)\n",
    "                                   .collect())\n",
    "    \n",
    "    print(f'Features Removidas: {len(not_list_features_selection)}')\n",
    "\n",
    "    return table_describe_num, list_features_selection, not_list_features_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1cb957f2-0838-43ac-bb0d-d63548da3399",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def describe_binning(model_object, list_features):\n",
    "\n",
    "    \"\"\"\n",
    "    Gera um descritivo de binning para cada uma das variáveis especificadas.\n",
    "\n",
    "    Args:\n",
    "        model_object: Objeto do modelo treinado que suporta o método binning. Deve ser um modelo que contenha as variáveis binned e suporte `get_binned_variable()`.\n",
    "        list_features (list[str]): Lista de nomes das features para as quais o descritivo de binning será gerado.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, DataFrame]: Uma lista em que cada posição dessa lista é uma tabela resumo de cada feature listada\n",
    "        contendo as tabelas de binning associadas.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: Se qualquer feature em `list_features` não estiver presente no artefato do modelo (`model_object`).\n",
    "\n",
    "    Example:\n",
    "        >>> model_object = treinado_modelo_com_binning  # Objeto com método summary e binning\n",
    "        >>> list_features = [\"feature_1\", \"feature_2\"]\n",
    "        >>> binning_results = describe_binning(model_object, list_features)\n",
    "        >>> for feature, table in binning_results.items():\n",
    "        >>>     print(f\"Binning para {feature}:\")\n",
    "        >>>     table.show()\n",
    "    \n",
    "    Workflow:\n",
    "        1. Identifica as variáveis disponíveis no artefato do modelo (model_object.summary()).\n",
    "        2. Valida se todas as features na lista `list_features` estão presentes no modelo.\n",
    "        3. Para cada feature válida:\n",
    "           - Obtém o objeto de binning usando `model_object.get_binned_variable(feature)`.\n",
    "           - Gera a tabela de binning com o método `binning_table.build()`.\n",
    "        4. Retorna um dicionário com as tabelas de binning por feature.\n",
    "\n",
    "    Notes:\n",
    "        - O método `model_object.summary()` deve retornar uma estrutura que inclua o nome das variáveis.\n",
    "        - A função `get_binned_variable()` deve estar disponível no `model_object` e retornar uma estrutura de binning.\n",
    "    \"\"\"\n",
    "\n",
    "    #features no arquivo objeto do modelo\n",
    "    features_cat = spark.createDataFrame(model_object.summary()).select(\"name\").distinct().rdd.flatMap(lambda row: row).collect()\n",
    "\n",
    "    #validando se a lista esta presente na tabela de input pu no objeto do modelo\n",
    "    list_not_in_model = [column for column in list_features if column not in features_cat]\n",
    "    \n",
    "    if list_not_in_model != []:\n",
    "        raise ValueError(f\"A lista de features {list_not_in_model} para categorização não esta presente no artefato do modelo, parametro model_object.\")\n",
    "\n",
    "    #Descritivo Binning\n",
    "    table_final =  {}\n",
    "    for i in list_features:\n",
    "        optb = model_object.get_binned_variable(i)\n",
    "        print(\"Variavel:\", i)\n",
    "        binning_table_result = optb.binning_table.build()\n",
    "        table_final[i] = binning_table_result\n",
    "    return(table_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "765172e8-c05d-42ed-a210-cd394e6f1c64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Tratamentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1862fa56-73f9-485a-9b5e-1bab71630c75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def process_categoric_cuts(data_spark, feature, reference = None, cuts = 10):\n",
    "\n",
    "    \"\"\"\n",
    "    Processa uma variável categórica contínua em faixas (buckets) com base em cortes definidos por quantis.\n",
    "\n",
    "    Args:\n",
    "        data_spark (DataFrame): DataFrame PySpark contendo os dados de entrada.\n",
    "        feature (str): Nome da coluna no DataFrame que será categorizada em faixas.\n",
    "        reference (str, optional): Nome de uma coluna boolean no DataFrame usada como referência para calcular os \n",
    "        quantis.\n",
    "            Se None, considera toda a base. Default é None.\n",
    "        cuts (int, optional): Número de faixas (buckets) desejadas. Deve ser maior que 2. Default é 10.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Um DataFrame com a coluna original categorizada em uma nova coluna de faixas.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: Caso:\n",
    "            - A coluna `feature` não esteja presente no DataFrame.\n",
    "            - A coluna `reference` (se especificada) não esteja presente no DataFrame.\n",
    "            - A coluna `reference` (se especificada) não seja do tipo booleano.\n",
    "            - O valor de `cuts` seja menor ou igual a 2.\n",
    "        ValueError: Caso não haja quantis suficientes para formar buckets.\n",
    "\n",
    "    Example:\n",
    "        >>> df_result = process_categoric_cuts(df, feature=\"value\", reference=\"is_valid\", cuts=3)\n",
    "        >>> df_result.show()\n",
    "    \n",
    "    Workflow:\n",
    "        1. Valida se `feature` e, se especificado, `reference` estão no DataFrame.\n",
    "        2. Garante que `reference` é do tipo booleano, se presente.\n",
    "        3. Filtra valores nulos e negativos na coluna `feature`.\n",
    "        4. Calcula os quantis da coluna `feature` com base no número de cortes especificado.\n",
    "        5. Ajusta os quantis para garantir o suporte a valores extremos.\n",
    "        6. Aplica o `Bucketizer` para categorizar a coluna em faixas.\n",
    "        7. Trata valores nulos ou negativos na coluna categorizada.\n",
    "\n",
    "    Notes:\n",
    "        - A coluna categorizada será adicionada ao DataFrame com o nome `faixa_<feature>`.\n",
    "        - Valores nulos ou negativos serão tratados separadamente, e negativos são convertidos para string temporariamente.\n",
    "        - A precisão dos quantis é ajustada com um erro absoluto máximo de 0.001.\n",
    "\n",
    "    Columns:\n",
    "        - Entrada: `data_spark` deve conter as colunas especificadas em `feature` e (opcional) `reference`.\n",
    "        - Saída: Uma nova coluna `faixa_<feature>` será adicionada ao DataFrame, representando os buckets.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    if feature not in data_spark.columns:\n",
    "            raise ValueError(f\"A feature {feature} definido no parâmetro feature não esta presente na tabela de input, parâmetro data_spark.\")\n",
    "\n",
    "    if reference != None and reference not in data_spark.columns:\n",
    "            raise ValueError(f\"A feature {reference} definido no parâmetro feature não esta presente na tabela de input, parâmetro data_spark.\")\n",
    "    \n",
    "    if reference != None:\n",
    "        type_bool_columns = [col.name for col in data_spark.selectExpr(reference).schema.fields if isinstance(col.dataType, BooleanType)]\n",
    "        \n",
    "        if type_bool_columns != [reference]:\n",
    "            raise ValueError(f\"A feature {reference} definida no parâmetro feature precisa ser do tipo booleano (True e False)\")\n",
    "\n",
    "    if cuts <= 2:\n",
    "        raise ValueError(\"O valor do cuts tem que ser maior que 2.\")\n",
    "    \n",
    "    df_table = data_spark.filter(f.col(feature) > 0).filter(f.col(feature).isNotNull())\n",
    "\n",
    "    df_table_ref = df_table\n",
    "\n",
    "    if reference != None:\n",
    "        df_table_ref = df_table_ref.filter(f.col(reference) == True)\n",
    "\n",
    "\n",
    "    #Criando as probabilidades baseado na quantidade de quebras\n",
    "    probabilities = [i/cuts for i in range(cuts+1)]  # Probabilidades de 0 a 1 em incrementos de 0.1\n",
    "    \n",
    "    #Ajustando a feature para o tipo inteiro\n",
    "    df_table_ref = df_table_ref.withColumn(feature, f.col(feature).cast(\"integer\"))\n",
    "\n",
    "    # Obtendo os quantis\n",
    "    quantiles = df_table_ref.approxQuantile(feature, probabilities, 0.001)\n",
    "    \n",
    "    #ajustando os máximio e minimos para aplicar em toda a base se gerar missings\n",
    "    quantiles = sorted(set(quantiles))\n",
    "    quantiles[-1] = float('inf')\n",
    "    quantiles[0] = float('-inf')\n",
    "    \n",
    "    # verificando se a quantidade de quebras é mínima para categorizar\n",
    "    if len(quantiles)==2:\n",
    "        return df_table\n",
    "    \n",
    "    feature_low = f'faixa_{feature.lower()}'\n",
    "\n",
    "    #gerando o modelo buccketizer para aplicar\n",
    "    bucketizer = Bucketizer(splits=quantiles, inputCol=feature, outputCol= feature_low)\n",
    "    df_table_with_bins = bucketizer.transform(data_spark)\n",
    "\n",
    "    n_cuts  = len(df_table_with_bins.select(feature_low).distinct().rdd.flatMap(lambda row: row).collect())\n",
    "\n",
    "    df_table_with_bins = df_table_with_bins.withColumn(feature_low, (n_cuts-1)-f.col(feature_low))\n",
    "\n",
    "    #ajustando valores como missing ou negativos\n",
    "\n",
    "    # Trate valores nulos e negativos antes de aplicar o Bucketizer\n",
    "    df_table_with_bins = (df_table_with_bins\n",
    "                          .withColumn(feature_low,\n",
    "                                      f.when(f.col(feature).isNull(), None)\n",
    "                                      .when(f.col(feature) < 0, f.col(feature).cast(\"string\"))\n",
    "                                      .otherwise(f.col(feature_low)) ) # Temporariamente colocar None para valores que passarão pelo Bucketizer\n",
    "                          )\n",
    "    return(df_table_with_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9273c049-5b32-4ff3-8212-dce4e0989f3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def process_categoric_percentiles(data_spark, feature, reference = None, percentiles_acm = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]):\n",
    "    \n",
    "    \"\"\"\n",
    "    Processa percentis categóricos para uma feature contínua em um DataFrame Spark.\n",
    "    \n",
    "    Esta função aplica um modelo de bucketização (via `Bucketizer`) para transformar uma variável contínua em faixas    categóricas com base nos percentis definidos. Ela também suporta filtragem condicional com base em uma feature de  referência booleana.\n",
    "    \n",
    "    Parameters:\n",
    "        data_spark (DataFrame): \n",
    "            DataFrame Spark de entrada contendo as colunas para processamento.\n",
    "        feature (str): \n",
    "            Nome da feature contínua que será categorizada com base nos percentis.\n",
    "        reference (str, optional): \n",
    "            Nome de uma coluna booleana usada como referência para determinar os percentis.\n",
    "            Apenas valores `True` nesta coluna serão considerados para calcular os percentis.\n",
    "            Default: None.\n",
    "        percentiles_acm (list of float, optional): \n",
    "            Lista de valores de percentis cumulativos para determinar os cortes.\n",
    "            Valores devem estar no intervalo [0, 1] e ordenados de forma crescente.\n",
    "            Default: [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0].\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame:\n",
    "            DataFrame Spark contendo a coluna categorizada adicional, chamada `faixa_<nome_da_feature>`, \n",
    "            representando os intervalos definidos pelos percentis.\n",
    "            - Valores nulos ou negativos na coluna original são tratados separadamente.\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: \n",
    "            Caso a coluna especificada em `feature` não exista em `data_spark`.\n",
    "        ValueError: \n",
    "            Caso a coluna especificada em `reference` (se fornecida) não exista em `data_spark`.\n",
    "        ValueError: \n",
    "            Caso `reference` seja fornecida, mas não seja uma coluna booleana.\n",
    "        ValueError: \n",
    "            Caso o número de percentis em `percentiles_acm` seja menor ou igual a 2.\n",
    "    \n",
    "    Example:\n",
    "        >>> # Chamando a função\n",
    "        >>> df_result = process_categoric_percentiles(\n",
    "        ...     data_spark=df,\n",
    "        ...     feature=\"feature\",\n",
    "        ...     reference=\"reference\",\n",
    "        ...     percentiles_acm=[0.0, 0.5, 1.0]\n",
    "        ... )\n",
    "    \"\"\"\n",
    "\n",
    "    if feature not in data_spark.columns:\n",
    "            raise ValueError(f\"A feature {feature} definido no parâmetro feature não esta presente na tabela de input, parâmetro data_spark.\")\n",
    "\n",
    "    if reference != None and reference not in data_spark.columns:\n",
    "            raise ValueError(f\"A feature {reference} definido no parâmetro feature não esta presente na tabela de input, parâmetro data_spark.\")\n",
    "    \n",
    "    if reference != None:\n",
    "        type_bool_columns = [col.name for col in data_spark.selectExpr(reference).schema.fields if isinstance(col.dataType, BooleanType)]\n",
    "        \n",
    "        if type_bool_columns != [reference]:\n",
    "            raise ValueError(f\"A feature {reference} definida no parâmetro feature precisa ser do tipo booleano (True e False)\")\n",
    "\n",
    "    if len(percentiles_acm) <= 2:\n",
    "        raise ValueError(\"O valores do percentis tem que ser maior que 2\")\n",
    "    \n",
    "    df_table = data_spark.filter(f.col(feature) > 0).filter(f.col(feature).isNotNull())\n",
    "\n",
    "    df_table_ref = df_table\n",
    "\n",
    "    if reference != None:\n",
    "        df_table_ref = df_table_ref.filter(f.col(reference) == True)\n",
    "\n",
    "    \n",
    "    #Ajustando a feature para o tipo inteiro\n",
    "    df_table_ref = df_table_ref.withColumn(feature, f.col(feature).cast(\"integer\"))\n",
    "\n",
    "    # Obtendo os quantis\n",
    "    quantiles = df_table_ref.approxQuantile(feature, percentiles_acm, 0.001)\n",
    "    \n",
    "    #ajustando os máximio e minimos para aplicar em toda a base se gerar missings\n",
    "    quantiles = sorted(set(quantiles))\n",
    "    quantiles[-1] = float('inf')\n",
    "    quantiles[0] = float('-inf')\n",
    "    \n",
    "    # verificando se a quantidade de quebras é mínima para categorizar\n",
    "    if len(quantiles)==2:\n",
    "        return df_table\n",
    "    \n",
    "    feature_low = f'faixa_{feature.lower()}'\n",
    "\n",
    "    #gerando o modelo buccketizer para aplicar\n",
    "    bucketizer = Bucketizer(splits=quantiles, inputCol=feature, outputCol= feature_low)\n",
    "    df_table_with_bins = bucketizer.transform(data_spark)\n",
    "\n",
    "    n_cuts  = len(df_table_with_bins.select(feature_low).distinct().rdd.flatMap(lambda row: row).collect())\n",
    "    df_table_with_bins = df_table_with_bins.withColumn(feature_low, (n_cuts-1)-f.col(feature_low))\n",
    "\n",
    "    #ajustando valores como missing ou negativos\n",
    "\n",
    "    # Trate valores nulos e negativos antes de aplicar o Bucketizer\n",
    "    df_table_with_bins = (df_table_with_bins\n",
    "                          .withColumn(feature_low,\n",
    "                                      f.when(f.col(feature).isNull(), None)\n",
    "                                      .when(f.col(feature) < 0, f.col(feature).cast(\"string\"))\n",
    "                                      .otherwise(f.col(feature_low)) ) # Temporariamente colocar None para valores que passarão pelo Bucketizer\n",
    "                          )\n",
    "    return(df_table_with_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75bcfa28-2aaa-49cb-851f-dc9575a9f2a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def process_categoric_cuts_multiple_features(data_spark, list_features, cuts = 10, reference = None):\n",
    "\n",
    "    \"\"\"\n",
    "    Processa cortes categóricos em múltiplas features de um DataFrame Spark.\n",
    "\n",
    "    Args:\n",
    "        data_spark (DataFrame): DataFrame Spark contendo os dados de entrada.\n",
    "        list_features (list): Lista de colunas que contêm as features a serem processadas.\n",
    "        cuts (int, opcional): Número de cortes categóricos a serem aplicados. O valor default é 10.\n",
    "        reference (str, opcional): Nome da coluna de referência para os cortes.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame Spark com as features categorizadas.\n",
    "\n",
    "    Example:\n",
    "        >>> df_processed = process_categoric_cuts_multiple_features(data_spark=df_spark, list_features=['feature1', 'feature2'], cuts=10, reference='reference_column')\n",
    "    \"\"\"\n",
    "    \n",
    "    data_spark_temp = data_spark\n",
    "\n",
    "    for i in list_features:\n",
    "        data_spark_temp = process_categoric_cuts(data_spark = data_spark_temp, feature = i, reference = reference, cuts = cuts)\n",
    "\n",
    "    return(data_spark_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fbb031f-2b14-41f9-812b-7c465cdd3f97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def process_categoric_percentiles_multiple_features(data_spark, list_features, cuts = 10, reference = None):\n",
    "\n",
    "    \"\"\"\n",
    "    Processa percentis categóricos em múltiplas features de um DataFrame Spark.\n",
    "\n",
    "    Args:\n",
    "        data_spark (DataFrame): DataFrame Spark contendo os dados de entrada.\n",
    "        list_features (list): Lista de colunas que contêm as features a serem processadas.\n",
    "        cuts (int, opcional): Número de cortes categóricos a serem aplicados. O valor default é 10.\n",
    "        reference (str, opcional): Nome da coluna de referência para os cortes.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame Spark com as features categorizadas.\n",
    "\n",
    "    Example:\n",
    "        >>> df_processed = process_categoric_percentiles_multiple_features(data_spark=df_spark, list_features=['feature1', 'feature2'], cuts=10, reference='reference_column')\n",
    "    \"\"\"\n",
    "    \n",
    "    data_spark_temp = data_spark\n",
    "\n",
    "    for i in list_features:\n",
    "        data_spark_temp = process_categoric_percentiles(data_spark = data_spark_temp, feature = i, reference = reference, percentiles_acm=[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "\n",
    "    return(data_spark_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91cfc349-37cf-4fe1-96a0-bf1db2e9ebfd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Modelagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9f42626-149c-4ff7-b21f-dacd54628c93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def model_glm_multiples_combination(data_spark, list_scores, target, dev = None):\n",
    "\n",
    "    \"\"\"\n",
    "    Treina múltiplos modelos GLM com diferentes combinações de features em um DataFrame Spark.\n",
    "\n",
    "    Args:\n",
    "        data_spark (DataFrame): DataFrame Spark contendo os dados de entrada.\n",
    "        list_scores (list): Lista de listas, onde cada sublista contém os nomes das features a serem utilizadas em um\n",
    "        modelo.\n",
    "        target (str): Nome da coluna que contém o target.\n",
    "        dev (str, opcional): Nome da coluna boolean para filtrar a base de desenvolvimento. O valor default é None.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dicionário contendo os modelos treinados, com os nomes das features concatenadas como chaves.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: Se alguma feature especificada em `list_scores` não estiver presente no DataFrame de entrada\n",
    "        `data_spark`.\n",
    "        ValueError: Se a coluna `dev` não for do tipo booleano (True e False).\n",
    "\n",
    "    Example:\n",
    "        >>> models = model_glm_multiples_combination(data_spark=df_spark, list_scores=[['feature1', 'feature2'], ['feature3', 'feature4']], target='target_column', dev='dev_column')\n",
    "    \"\"\"\n",
    "\n",
    "    #validando \n",
    "    #verificando nomes unicos da lista\n",
    "    list_features_blend = set(item for sublist in list_scores for item in sublist)\n",
    "\n",
    "    #validando se a lista esta presente na tabela de input pu no objeto do modelo\n",
    "    list_not_in = [column for column in list_features_blend if column not in data_spark.columns]\n",
    "\n",
    "    if list_not_in != []:\n",
    "        raise ValueError(f\"As features {list_not_in} para aplicação não esta presente na tabela de input, parâmetro data_spark.\")\n",
    "\n",
    "    # if dev != None:\n",
    "    #     type_bool_columns = [col.name for col in data_spark.selectExpr(dev).schema.fields if isinstance(col.dataType, BooleanType)]\n",
    "        \n",
    "    #     if type_bool_columns != [dev]:\n",
    "    #         raise ValueError(f\"A feature {dev} definida no parâmetro dev precisa ser do tipo booleano (True e False)\")\n",
    "\n",
    "    #Transformando em data pandas\n",
    "    df_pandas = data_spark.toPandas()\n",
    "\n",
    "    #Verificando se existe a base esta em desenvolvimento e validação\n",
    "    if dev != None:\n",
    "         df_pandas = df_pandas[df_pandas[dev] == True]\n",
    "\n",
    "    # Treinando o modelo em treino e validação\n",
    "    df_dev, df_val = train_test_split(df_pandas, test_size=0.2, random_state=1234)\n",
    "\n",
    "    lista_model = {}\n",
    "\n",
    "    y_train = df_dev[target]\n",
    "    \n",
    "    for i in list_scores:\n",
    "        modelo_glm = LogisticRegression(random_state=7)\n",
    "        modelo_glm.fit(df_dev.filter(items = i), y_train)\n",
    "        features = list(modelo_glm.feature_names_in_)\n",
    "        model_feature_X = 'model_glm_' + '_'.join(features)\n",
    "        print(\"nome do modelo utilizando as features\", i,\":\", model_feature_X)\n",
    "        lista_model[model_feature_X] = modelo_glm\n",
    "    return lista_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b499734-907d-419e-acdb-1ec50c9672b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def predict_model_glm_multiples_combination(data_spark, list_models):\n",
    "\n",
    "    \"\"\"\n",
    "    Gera previsões para múltiplos modelos GLM com diferentes combinações de features em um DataFrame Spark.\n",
    "\n",
    "    Args:\n",
    "        data_spark (DataFrame): DataFrame Spark contendo os dados de entrada.\n",
    "        list_models (dict): Dicionário contendo os modelos treinados, com os nomes das features concatenadas como chaves.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame Spark contendo as previsões de probabilidade para cada modelo.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: Se alguma feature especificada em `list_models` não estiver presente no DataFrame de entrada `data_spark`.\n",
    "        \n",
    "    Example:\n",
    "        >>> df_predictions = predict_model_glm_multiples_combination(data_spark=df_spark, list_models=models)\n",
    "    \"\"\"\n",
    "\n",
    "    names_models = list(list_models.keys())\n",
    "    #validando\n",
    "    lists_features_models = list()\n",
    "    # for i in np.arange(0, (len(list_models)), 1):\n",
    "    for i in names_models:\n",
    "            lists_features_models.append(list(list_models[i].feature_names_in_))\n",
    "\n",
    "    #verificando nomes unicos da lista\n",
    "    list_features_blend = set(item for sublist in lists_features_models for item in sublist)\n",
    "\n",
    "    #validando se a lista esta presente na tabela de input pu no objeto do modelo\n",
    "    list_not_in = [column for column in list_features_blend if column not in data_spark.columns]\n",
    "\n",
    "    if list_not_in != []:\n",
    "        raise ValueError(f\"As features {list_not_in} para aplicação não esta presente na tabela de input, parâmetro data_spark.\")\n",
    "\n",
    "\n",
    "    #tranformando em data panas\n",
    "    data_pandas = data_spark.toPandas()\n",
    "\n",
    "    #Criando um looping de aplicação \n",
    "    # for i in np.arange(0, (len(list_models)), 1):\n",
    "    for i in names_models:\n",
    "        features = list(list_models[i].feature_names_in_)\n",
    "        model_feature_X = 'prob_model_glm_' + '_'.join(features)\n",
    "        data_pandas[f'{model_feature_X}'] = list_models[i].predict_proba(data_pandas[list(list_models[i].feature_names_in_)])[:, 1]\n",
    "        \n",
    "    return(spark.createDataFrame(data_pandas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae555b5a-391f-4f81-9fca-30ad8636e012",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Função para calcular KS e Gini\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calcula as métricas KS, Gini e AUC com base nas previsões e valores reais.\n",
    "\n",
    "    Args:\n",
    "        y_true (array-like): Valores reais do target (0 ou 1).\n",
    "        y_pred (array-like): Probabilidades previstas pelo modelo.\n",
    "\n",
    "    Returns:\n",
    "        dict: Um dicionário contendo as métricas calculadas:\n",
    "            - 'ks': Valor do KS.\n",
    "            - 'gini': Valor do Gini.\n",
    "            - 'auc': Área sob a curva ROC.\n",
    "            - 'bad_decil10': Taxa de default no primeiro decil.\n",
    "\n",
    "\n",
    "    Raises:\n",
    "        ValueError: Se os arrays `y_true` e `y_pred` tiverem tamanhos diferentes.\n",
    "        ValueError: Se `y_true` contiver valores diferentes de 0 e 1.\n",
    "\n",
    "    Example:\n",
    "        >>> metrics = calculate_metrics(y_true=[0, 1, 1, 0], y_pred=[0.1, 0.9, 0.8, 0.2])\n",
    "        >>> print(metrics)\n",
    "        {'ks': 0.75, 'gini': 0.8, 'auc': 0.9}\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Gini: 2 * AUC - 1\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    # Corrigindo o AUC se for menor que 0.5\n",
    "    if auc < 0.5:\n",
    "        auc = 1 - auc\n",
    "\n",
    "    gini = 2 * auc - 1\n",
    "    \n",
    "    # KS\n",
    "    sorted_indices = np.argsort(y_pred)\n",
    "    cum_good = (y_true[sorted_indices] == 1).cumsum()\n",
    "    cum_bad = (y_true[sorted_indices] == 0).cumsum()\n",
    "    # ks = max(abs(cum_good / cum_good[-1] - cum_bad / cum_bad[-1])) original\n",
    "    ks = np.max(np.abs(cum_good / cum_good[-1] - cum_bad / cum_bad[-1])) #ajuste matheus\n",
    "\n",
    "\n",
    "    # # Taxa de default no primeiro decil\n",
    "    # decil_size = len(y_true) // 10\n",
    "    # decil_size_30 = len(y_true) // 30\n",
    "    # decil_size_40 = len(y_true) // 40\n",
    "    # Tamanhos dos percentis desejados\n",
    "    size_10 = int(len(y_true) * 0.10)\n",
    "    size_30 = int(len(y_true) * 0.30)\n",
    "    size_40 = int(len(y_true) * 0.40)\n",
    "\n",
    "    # Seleciona os índices dos menores scores preditos (menor risco, se score for default probability)\n",
    "    sorted_indices = np.argsort(y_pred)\n",
    "\n",
    "    indices_10 = sorted_indices[:size_10]\n",
    "    indices_30 = sorted_indices[:size_30]\n",
    "    indices_40 = sorted_indices[:size_40]\n",
    "\n",
    "    # top_decil_indices = np.argsort(y_pred)[:decil_size]  # Pegamos os 10% com menor probabilidade default\n",
    "    # top_decil_indices_30 = np.argsort(y_pred)[:decil_size_30]  # Pegamos os 10% com menor probabilidade default\n",
    "    # top_decil_indices_40 = np.argsort(y_pred)[:decil_size_40]  # Pegamos os 10% com menor probabilidade default\n",
    "\n",
    "    # Taxa de default nos grupos\n",
    "    # bad_rate_10 = round(np.mean(y_true[indices_10]), 4) ORIGINAL\n",
    "    # bad_rate_30 = round(np.mean(y_true[indices_30]), 4)\n",
    "    # bad_rate_40 = round(np.mean(y_true[indices_40]), 4)\n",
    "\n",
    "    bad_rate_10 = np.round(np.mean(y_true[indices_10]), 4) #AJUSTE MATHEUS\n",
    "    bad_rate_30 = np.round(np.mean(y_true[indices_30]), 4)\n",
    "    bad_rate_40 = np.round(np.mean(y_true[indices_40]), 4)\n",
    "\n",
    "    # bad_decil10 = round(np.mean(y_true[top_decil_indices]), 4)  # Média dos valores reais (proporção de defaults)\n",
    "    # bad_decil30 = round(np.mean(y_true[top_decil_indices_30]), 4)  # Média dos valores reais (proporção de defaults)\n",
    "    # bad_decil40 = round(np.mean(y_true[top_decil_indices_40]), 4)  # Média dos valores reais (proporção de defaults)\n",
    "\n",
    "    return ks, gini, auc, bad_rate_10, bad_rate_30, bad_rate_40\n",
    "\n",
    "\n",
    "\n",
    "# # Função para realizar a busca de hiperparâmetros via Optuna\n",
    "# def objective_express(trial, X_train, X_valid, y_train, y_valid, iteration, results):\n",
    "\n",
    "#     \"\"\"\n",
    "#     Define o objetivo para a otimização do Optuna usando LightGBM.\n",
    "\n",
    "#     Args:\n",
    "#         trial (optuna.trial.Trial): Objeto que controla as iterações do Optuna.\n",
    "#         X_train (pandas.DataFrame): Dados de treinamento.\n",
    "#         X_valid (pandas.DataFrame): Dados de validação.\n",
    "#         y_train (pandas.Series): Target para os dados de treinamento.\n",
    "#         y_valid (pandas.Series): Target para os dados de validação.\n",
    "#         iteration (int): Número atual da iteração de treinamento.\n",
    "#         results (dict): Dicionário para armazenar os resultados das métricas.\n",
    "\n",
    "#     Returns:\n",
    "#         float: Valor da métrica de avaliação escolhida (ex.: KS ou AUC).\n",
    "\n",
    "#     Raises:\n",
    "#         ValueError: Se `X_train` e `X_valid` tiverem colunas inconsistentes.\n",
    "#         ValueError: Se o tamanho de `X_train` não coincidir com `y_train`.\n",
    "\n",
    "#     Example:\n",
    "#         >>> study.optimize(lambda trial: objective_express(trial, X_train, X_valid, y_train, y_valid, iteration=1, results={}), n_trials=10)\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Lista para armazenar os resultados\n",
    "#     params = {\n",
    "#         \"objective\": \"binary\",\n",
    "#         \"metric\": \"auc\",\n",
    "#         \"boosting_type\": \"gbdt\",\n",
    "#         \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.000001, 0.1, log = True),\n",
    "#         \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 150),\n",
    "#         \"max_depth\": trial.suggest_int(\"max_depth\", 3, 15),\n",
    "#         \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "#         \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 1e-3, 1e-1, log = True),\n",
    "#         \"subsample\": trial.suggest_float(\"subsample\", 0.4, 1.0),\n",
    "#         \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.4, 1.0),\n",
    "#         \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-3, 10.0, log = True),\n",
    "#         \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-3, 10.0, log = True),\n",
    "#         \"verbose\": -1,\n",
    "#         \"seed\": 42,\n",
    "#     }\n",
    "\n",
    "\n",
    "#     # Criação dos datasets de treino e validação\n",
    "#     train_data = lgb.Dataset(X_train, label=y_train)\n",
    "#     valid_data = lgb.Dataset(X_valid, label=y_valid, reference=train_data)\n",
    "\n",
    "#     # Treinamento com early stopping\n",
    "#     model = lgb.train(\n",
    "#         params,\n",
    "#         train_data,\n",
    "#         num_boost_round=1000,\n",
    "#         valid_sets=[valid_data],\n",
    "#         callbacks=[lgb.early_stopping(stopping_rounds=10)],\n",
    "#     )\n",
    "\n",
    "#     #Avaliando quantidade de features dentro de um range de acm pelo menos de 98%\n",
    "#     # Calcular a importância das features\n",
    "#     feature_importance = model.feature_importance(importance_type='gain')\n",
    "#     features = model.feature_name()\n",
    "        \n",
    "#     importance_df = pd.DataFrame({\n",
    "#         'feature': features,\n",
    "#         'importance': feature_importance\n",
    "#     })\n",
    "    \n",
    "#     importance_df = importance_df.sort_values(by='importance', ascending=False)\n",
    "    \n",
    "#     total_gain = importance_df['importance'].sum()\n",
    "#     importance_df['cumulative_gain'] = importance_df['importance'].cumsum() / total_gain\n",
    "\n",
    "#     # Selecionar as features com ganho acumulado até 95%\n",
    "#     selected_features_max = importance_df[importance_df['cumulative_gain'] <= 0.98]['feature'].tolist()\n",
    "#     qtd_feautures = len(selected_features_max)\n",
    "\n",
    "#     # Previsões para treino e validação/teste\n",
    "#     y_pred_train = model.predict(X_train, num_iteration=model.best_iteration)\n",
    "#     y_pred_valid = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "\n",
    "#     # Calcular métricas para treino\n",
    "#     ks_train, gini_train, auc_train, bad_decil10_train, bad_decil30_train, bad_decil40_train = calculate_metrics(y_train.values, y_pred_train)\n",
    "\n",
    "#     # Calcular métricas para validação/teste\n",
    "#     ks_valid, gini_valid, auc_valid, bad_decil10_valid, bad_decil30_valid, bad_decil40_valid = calculate_metrics(y_valid.values, y_pred_valid)\n",
    "\n",
    "#     # Armazenar os resultados\n",
    "#     results.append({\n",
    "#         \"iteration\": iteration,\n",
    "#         \"params\": params,\n",
    "#         \"features_relevance\": qtd_feautures,\n",
    "#         \"ks2_train\": ks_train,\n",
    "#         \"gini_train\": gini_train,\n",
    "#         \"auc_train\": auc_train,\n",
    "#         \"bad_decil10_train\": bad_decil10_train,\n",
    "#         \"ks2_valid\": ks_valid,\n",
    "#         \"gini_valid\": gini_valid,\n",
    "#         \"auc_valid\": auc_valid,\n",
    "#         \"bad_decil10_valid\": bad_decil10_valid,\n",
    "#     })\n",
    "\n",
    "#     return auc_valid  # Maximizar o AUC na validação/teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "da08a347-3b7a-41dd-ae17-cddd7a2dcd04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# # Função para realizar a busca de hiperparâmetros via Optuna\n",
    "# def objective_express_V2(trial, X_train, X_valid, X_oot, y_train, y_valid, y_oot, iteration, results):\n",
    "\n",
    "#     \"\"\"\n",
    "#     Define o objetivo para a otimização do Optuna usando LightGBM.\n",
    "\n",
    "#     Args:\n",
    "#         trial (optuna.trial.Trial): Objeto que controla as iterações do Optuna.\n",
    "#         X_train (pandas.DataFrame): Dados de treinamento.\n",
    "#         X_valid (pandas.DataFrame): Dados de validação.\n",
    "#         y_train (pandas.Series): Target para os dados de treinamento.\n",
    "#         y_valid (pandas.Series): Target para os dados de validação.\n",
    "#         iteration (int): Número atual da iteração de treinamento.\n",
    "#         results (dict): Dicionário para armazenar os resultados das métricas.\n",
    "\n",
    "#     Returns:\n",
    "#         float: Valor da métrica de avaliação escolhida (ex.: KS ou AUC).\n",
    "\n",
    "#     Raises:\n",
    "#         ValueError: Se `X_train` e `X_valid` tiverem colunas inconsistentes.\n",
    "#         ValueError: Se o tamanho de `X_train` não coincidir com `y_train`.\n",
    "\n",
    "#     Example:\n",
    "#         >>> study.optimize(lambda trial: objective_express(trial, X_train, X_valid, y_train, y_valid, iteration=1, results={}), n_trials=10)\n",
    "#     \"\"\"\n",
    "\n",
    "#     is_unbalance_list = trial.suggest_categorical('is_unbalance', [True, False])\n",
    "\n",
    "    \n",
    "#     # Lista para armazenar os resultados\n",
    "#     params = {\n",
    "#         \"objective\": \"binary\",\n",
    "#         \"metric\": \"auc\",\n",
    "#         \"boosting_type\": trial.suggest_categorical('boosting_type', ['gbdt', 'dart']),\n",
    "#         'is_unbalance': is_unbalance_list,\n",
    "#         \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.0001, 0.3, log = True),\n",
    "#         \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 20),\n",
    "#         \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n",
    "#         \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "#         # \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 1e-3, 1e-1, log = True),\n",
    "#         \"subsample\": trial.suggest_float(\"subsample\", 0.3, 1.0),\n",
    "#         \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.3, 1.0),\n",
    "#         \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-3, 10.0, log = True),\n",
    "#         \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-3, 10.0, log = True),\n",
    "#         \"verbose\": -1,\n",
    "#         \"seed\": 42,\n",
    "#     }\n",
    "\n",
    "\n",
    "#     # Criação dos datasets de treino e validação\n",
    "#     train_data = lgb.Dataset(X_train, label=y_train)\n",
    "#     valid_data = lgb.Dataset(X_valid, label=y_valid, reference=train_data)\n",
    "#     oot_data = lgb.Dataset(X_oot, label=y_oot, reference=train_data)\n",
    "\n",
    "#     # Treinamento com early stopping\n",
    "#     model = lgb.train(\n",
    "#         params,\n",
    "#         train_data,\n",
    "#         num_boost_round=1000,\n",
    "#         valid_sets=[valid_data],\n",
    "#         callbacks=[lgb.early_stopping(stopping_rounds=20)],\n",
    "#     )\n",
    "\n",
    "#     #Avaliando quantidade de features dentro de um range de acm pelo menos de 98%\n",
    "#     # Calcular a importância das features\n",
    "#     feature_importance = model.feature_importance(importance_type='gain')\n",
    "#     features = model.feature_name()\n",
    "        \n",
    "#     importance_df = pd.DataFrame({\n",
    "#         'feature': features,\n",
    "#         'importance': feature_importance\n",
    "#     })\n",
    "    \n",
    "#     importance_df = importance_df.sort_values(by='importance', ascending=False)\n",
    "    \n",
    "#     total_gain = importance_df['importance'].sum()\n",
    "#     importance_df['cumulative_gain'] = importance_df['importance'].cumsum() / total_gain\n",
    "\n",
    "#     # Selecionar as features com ganho acumulado até 95%\n",
    "#     selected_features_max = importance_df[importance_df['cumulative_gain'] <= 0.98]['feature'].tolist()\n",
    "#     qtd_feautures = len(selected_features_max)\n",
    "\n",
    "#     # Previsões para treino e validação/teste\n",
    "#     y_pred_train = model.predict(X_train, num_iteration=model.best_iteration)\n",
    "#     y_pred_valid = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "#     y_pred_oot = model.predict(X_oot, num_iteration=model.best_iteration)\n",
    "\n",
    "#     # Calcular métricas para treino\n",
    "#     ks_train, gini_train, auc_train, bad_decil10_train, bad_decil30_train, bad_decil40_train = calculate_metrics(y_train.values, y_pred_train)\n",
    "\n",
    "#     # Calcular métricas para validação/teste\n",
    "#     ks_valid, gini_valid, auc_valid, bad_decil10_valid, bad_decil30_valid, bad_decil40_valid = calculate_metrics(y_valid.values, y_pred_valid)\n",
    "\n",
    "#     # Calcular métricas para OOT\n",
    "#     ks_oot, gini_oot, auc_oot, bad_decil10_oot, bad_decil30_oot, bad_decil40_oot = calculate_metrics(y_oot.values, y_pred_oot)\n",
    "\n",
    "\n",
    "#     shift_oot  = ((gini_oot-gini_train)/gini_train)*100\n",
    "\n",
    "#     # Armazenar os resultados\n",
    "#     results.append({\n",
    "#         \"iteration\": iteration,\n",
    "#         \"params\": params,\n",
    "#         \"features_relevance\": qtd_feautures,\n",
    "#         \"ks2_train\": ks_train,\n",
    "#         \"gini_train\": gini_train,\n",
    "#         \"auc_train\": auc_train,\n",
    "#         \"bad_decil10_train\": bad_decil10_train,\n",
    "#         \"bad_decil30_train\": bad_decil30_train,\n",
    "#         \"bad_decil40_train\": bad_decil40_train,        \n",
    "#         \"ks2_valid\": ks_valid,\n",
    "#         \"gini_valid\": gini_valid,\n",
    "#         \"auc_valid\": auc_valid,\n",
    "#         \"bad_decil10_valid\": bad_decil10_valid,\n",
    "#         \"bad_decil30_valid\": bad_decil30_valid,\n",
    "#         \"bad_decil40_valid\": bad_decil40_valid,\n",
    "#         \"ks2_oot\": ks_oot,\n",
    "#         \"gini_oot\": gini_oot,\n",
    "#         \"auc_oot\": auc_oot,\n",
    "#         \"bad_decil10_oot\": bad_decil10_oot,\n",
    "#         \"bad_decil30_oot\": bad_decil30_oot,\n",
    "#         \"bad_decil40_oot\": bad_decil40_oot,\n",
    "#         'shift_oot': shift_oot,\n",
    "#     })\n",
    "\n",
    "#     # return auc_valid  # Maximizar o AUC na validação/teste\n",
    "#     return np.abs(shift_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba7d8d82-5be5-48f3-a5f7-70b0c227ac7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Função para realizar a busca de hiperparâmetros via Optuna - Antigo V3\n",
    "def objective_express(trial, X_train, X_valid, X_oot, y_train, y_valid, y_oot, iteration, results):\n",
    "\n",
    "    \"\"\"\n",
    "    Define o objetivo para a otimização do Optuna usando LightGBM.\n",
    "\n",
    "    Args:\n",
    "        trial (optuna.trial.Trial): Objeto que controla as iterações do Optuna.\n",
    "        X_train (pandas.DataFrame): Dados de treinamento.\n",
    "        X_valid (pandas.DataFrame): Dados de validação.\n",
    "        y_train (pandas.Series): Target para os dados de treinamento.\n",
    "        y_valid (pandas.Series): Target para os dados de validação.\n",
    "        iteration (int): Número atual da iteração de treinamento.\n",
    "        results (dict): Dicionário para armazenar os resultados das métricas.\n",
    "\n",
    "    Returns:\n",
    "        float: Valor da métrica de avaliação escolhida (ex.: KS ou AUC).\n",
    "\n",
    "    Raises:\n",
    "        ValueError: Se `X_train` e `X_valid` tiverem colunas inconsistentes.\n",
    "        ValueError: Se o tamanho de `X_train` não coincidir com `y_train`.\n",
    "\n",
    "    Example:\n",
    "        >>> study.optimize(lambda trial: objective_express(trial, X_train, X_valid, y_train, y_valid, iteration=1, results={}), n_trials=10)\n",
    "    \"\"\"\n",
    "\n",
    "    is_unbalance_list = trial.suggest_categorical('is_unbalance', [True, False])\n",
    "\n",
    "    \n",
    "    # Lista para armazenar os resultados\n",
    "    params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"boosting_type\": trial.suggest_categorical('boosting_type', ['gbdt', 'dart']),\n",
    "        'is_unbalance': is_unbalance_list,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.0001, 0.3, log = True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 20),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "        # \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 1e-3, 1e-1, log = True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.3, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.3, 1.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-3, 10.0, log = True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-3, 10.0, log = True),\n",
    "        \"verbose\": -1,\n",
    "        \"seed\": 42,\n",
    "    }\n",
    "\n",
    "\n",
    "    # Criação dos datasets de treino e validação\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid, reference=train_data)\n",
    "    oot_data = lgb.Dataset(X_oot, label=y_oot, reference=train_data)\n",
    "\n",
    "    # Treinamento com early stopping\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[valid_data],\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=20)],\n",
    "    )\n",
    "\n",
    "    #Avaliando quantidade de features dentro de um range de acm pelo menos de 98%\n",
    "    # Calcular a importância das features\n",
    "    feature_importance = model.feature_importance(importance_type='gain')\n",
    "    features = model.feature_name()\n",
    "        \n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': features,\n",
    "        'importance': feature_importance\n",
    "    })\n",
    "    \n",
    "    importance_df = importance_df.sort_values(by='importance', ascending=False)\n",
    "    \n",
    "    total_gain = importance_df['importance'].sum()\n",
    "    importance_df['cumulative_gain'] = importance_df['importance'].cumsum() / total_gain\n",
    "\n",
    "    # Selecionar as features com ganho acumulado até 95%\n",
    "    selected_features_max = importance_df[importance_df['cumulative_gain'] <= 0.98]['feature'].tolist()\n",
    "    qtd_feautures = len(selected_features_max)\n",
    "\n",
    "    # Previsões para treino e validação/teste\n",
    "    y_pred_train = model.predict(X_train, num_iteration=model.best_iteration)\n",
    "    y_pred_valid = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "    y_pred_oot = model.predict(X_oot, num_iteration=model.best_iteration)\n",
    "\n",
    "    # Calcular métricas para treino\n",
    "    ks_train, gini_train, auc_train, bad_decil10_train, bad_decil30_train, bad_decil40_train = calculate_metrics(y_train.values, y_pred_train)\n",
    "\n",
    "    # Calcular métricas para validação/teste\n",
    "    ks_valid, gini_valid, auc_valid, bad_decil10_valid, bad_decil30_valid, bad_decil40_valid = calculate_metrics(y_valid.values, y_pred_valid)\n",
    "\n",
    "    # Calcular métricas para OOT\n",
    "    ks_oot, gini_oot, auc_oot, bad_decil10_oot, bad_decil30_oot, bad_decil40_oot = calculate_metrics(y_oot.values, y_pred_oot)\n",
    "\n",
    "\n",
    "    shift_oot  = ((gini_oot-gini_train)/gini_train)*100\n",
    "\n",
    "    # Armazenar os resultados\n",
    "    results.append({\n",
    "        \"iteration\": iteration,\n",
    "        \"params\": params,\n",
    "        'num_boost_round': model.best_iteration,\n",
    "        \"features_relevance\": qtd_feautures,\n",
    "        \"ks2_train\": ks_train,\n",
    "        \"gini_train\": gini_train,\n",
    "        \"auc_train\": auc_train,\n",
    "        \"bad_decil10_train\": bad_decil10_train,\n",
    "        \"bad_decil30_train\": bad_decil30_train,\n",
    "        \"bad_decil40_train\": bad_decil40_train,        \n",
    "        \"ks2_valid\": ks_valid,\n",
    "        \"gini_valid\": gini_valid,\n",
    "        \"auc_valid\": auc_valid,\n",
    "        \"bad_decil10_valid\": bad_decil10_valid,\n",
    "        \"bad_decil30_valid\": bad_decil30_valid,\n",
    "        \"bad_decil40_valid\": bad_decil40_valid,\n",
    "        \"ks2_oot\": ks_oot,\n",
    "        \"gini_oot\": gini_oot,\n",
    "        \"auc_oot\": auc_oot,\n",
    "        \"bad_decil10_oot\": bad_decil10_oot,\n",
    "        \"bad_decil30_oot\": bad_decil30_oot,\n",
    "        \"bad_decil40_oot\": bad_decil40_oot,\n",
    "        'shift_oot': shift_oot,\n",
    "    })\n",
    "\n",
    "    return auc_valid  # Maximizar o AUC na validação/teste\n",
    "    # return np.abs(shift_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "89f3e40b-c010-4811-9957-121751439714",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# # Função para realizar a busca de hiperparâmetros via Optuna\n",
    "# def objective_express_V3(trial, X_train, X_valid, X_oot, y_train, y_valid, y_oot, iteration, results):\n",
    "\n",
    "#     \"\"\"\n",
    "#     Define o objetivo para a otimização do Optuna usando LightGBM.\n",
    "\n",
    "#     Args:\n",
    "#         trial (optuna.trial.Trial): Objeto que controla as iterações do Optuna.\n",
    "#         X_train (pandas.DataFrame): Dados de treinamento.\n",
    "#         X_valid (pandas.DataFrame): Dados de validação.\n",
    "#         y_train (pandas.Series): Target para os dados de treinamento.\n",
    "#         y_valid (pandas.Series): Target para os dados de validação.\n",
    "#         iteration (int): Número atual da iteração de treinamento.\n",
    "#         results (dict): Dicionário para armazenar os resultados das métricas.\n",
    "\n",
    "#     Returns:\n",
    "#         float: Valor da métrica de avaliação escolhida (ex.: KS ou AUC).\n",
    "\n",
    "#     Raises:\n",
    "#         ValueError: Se `X_train` e `X_valid` tiverem colunas inconsistentes.\n",
    "#         ValueError: Se o tamanho de `X_train` não coincidir com `y_train`.\n",
    "\n",
    "#     Example:\n",
    "#         >>> study.optimize(lambda trial: objective_express(trial, X_train, X_valid, y_train, y_valid, iteration=1, results={}), n_trials=10)\n",
    "#     \"\"\"\n",
    "\n",
    "#     is_unbalance_list = trial.suggest_categorical('is_unbalance', [True, False])\n",
    "\n",
    "    \n",
    "#     # Lista para armazenar os resultados\n",
    "#     params = {\n",
    "#         \"objective\": \"binary\",\n",
    "#         \"metric\": \"binary_logloss\",\n",
    "#         \"boosting_type\": trial.suggest_categorical('boosting_type', ['gbdt', 'dart']),\n",
    "#         'is_unbalance': is_unbalance_list,\n",
    "#         \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.0001, 0.3, log = True),\n",
    "#         \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 20),\n",
    "#         \"max_depth\": trial.suggest_int(\"max_depth\", 2, 5),\n",
    "#         \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "#         # \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 1e-3, 1e-1, log = True),\n",
    "#         \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "#         \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "#         \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-3, 10.0, log = True),\n",
    "#         \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-3, 10.0, log = True),\n",
    "#         \"verbose\": -1,\n",
    "#         \"seed\": 42,\n",
    "#     }\n",
    "\n",
    "\n",
    "#     # Criação dos datasets de treino e validação\n",
    "#     train_data = lgb.Dataset(X_train, label=y_train)\n",
    "#     valid_data = lgb.Dataset(X_valid, label=y_valid, reference=train_data)\n",
    "#     oot_data = lgb.Dataset(X_oot, label=y_oot, reference=train_data)\n",
    "\n",
    "#     # Treinamento com early stopping\n",
    "#     model = lgb.train(\n",
    "#         params,\n",
    "#         train_data,\n",
    "#         num_boost_round=1000,\n",
    "#         valid_sets=[valid_data],\n",
    "#         callbacks=[lgb.early_stopping(stopping_rounds=10)],\n",
    "#     )\n",
    "\n",
    "#     #Avaliando quantidade de features dentro de um range de acm pelo menos de 98%\n",
    "#     # Calcular a importância das features\n",
    "#     feature_importance = model.feature_importance(importance_type='gain')\n",
    "#     features = model.feature_name()\n",
    "        \n",
    "#     importance_df = pd.DataFrame({\n",
    "#         'feature': features,\n",
    "#         'importance': feature_importance\n",
    "#     })\n",
    "    \n",
    "#     importance_df = importance_df.sort_values(by='importance', ascending=False)\n",
    "    \n",
    "#     total_gain = importance_df['importance'].sum()\n",
    "#     importance_df['cumulative_gain'] = importance_df['importance'].cumsum() / total_gain\n",
    "\n",
    "#     # Selecionar as features com ganho acumulado até 95%\n",
    "#     selected_features_max = importance_df[importance_df['cumulative_gain'] <= 0.98]['feature'].tolist()\n",
    "#     qtd_feautures = len(selected_features_max)\n",
    "\n",
    "#     # Previsões para treino e validação/teste\n",
    "#     y_pred_train = model.predict(X_train, num_iteration=model.best_iteration)\n",
    "#     y_pred_valid = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "#     y_pred_oot = model.predict(X_oot, num_iteration=model.best_iteration)\n",
    "\n",
    "#     # Calcular métricas para treino\n",
    "#     ks_train, gini_train, auc_train, bad_decil10_train = calculate_metrics(y_train.values, y_pred_train)\n",
    "\n",
    "#     # Calcular métricas para validação/teste\n",
    "#     ks_valid, gini_valid, auc_valid, bad_decil10_valid = calculate_metrics(y_valid.values, y_pred_valid)\n",
    "\n",
    "#     # Calcular métricas para OOT\n",
    "#     ks_oot, gini_oot, auc_oot, bad_decil10_oot = calculate_metrics(y_oot.values, y_pred_oot)\n",
    "\n",
    "#     # Armazenar os resultados\n",
    "#     results.append({\n",
    "#         \"iteration\": iteration,\n",
    "#         \"params\": params,\n",
    "#         \"features_relevance\": qtd_feautures,\n",
    "#         \"ks2_train\": ks_train,\n",
    "#         \"gini_train\": gini_train,\n",
    "#         \"auc_train\": auc_train,\n",
    "#         \"bad_decil10_train\": bad_decil10_train,\n",
    "#         \"ks2_valid\": ks_valid,\n",
    "#         \"gini_valid\": gini_valid,\n",
    "#         \"auc_valid\": auc_valid,\n",
    "#         \"bad_decil10_valid\": bad_decil10_valid,\n",
    "#         \"ks2_oot\": ks_oot,\n",
    "#         \"gini_oot\": gini_oot,\n",
    "#         \"auc_oot\": auc_oot,\n",
    "#         \"bad_decil10_oot\": bad_decil10_oot,\n",
    "#     })\n",
    "\n",
    "#     return auc_valid  # Maximizar o AUC na validação/teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ca2f30b-5325-4b58-9715-d946de75d450",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def objective_express_xgb(trial, X_train, X_valid, X_oot, y_train, y_valid, y_oot, iteration, results):\n",
    "    # Sugestão de hiperparâmetros pelo Optuna\n",
    "    params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"auc\",\n",
    "        \"booster\": trial.suggest_categorical('booster', ['gbtree', 'dart']),\n",
    "        \"eta\": trial.suggest_float(\"learning_rate\", 0.0001, 0.3, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 0.1, 10.0, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.3, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.3, 1.0),\n",
    "        \"lambda\": trial.suggest_float(\"reg_lambda\", 1e-3, 10.0, log=True),\n",
    "        \"alpha\": trial.suggest_float(\"reg_alpha\", 1e-3, 10.0, log=True),\n",
    "        \"scale_pos_weight\": trial.suggest_categorical('is_unbalance', [1.0, (len(y_train)-sum(y_train))/sum(y_train)]),\n",
    "        \"verbosity\": 0,\n",
    "        \"seed\": 42\n",
    "    }\n",
    "\n",
    "    # Criação dos DMatrix\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "    doot = xgb.DMatrix(X_oot, label=y_oot)\n",
    "\n",
    "    # Treinamento com early stopping\n",
    "    evals = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=1000,\n",
    "        evals=evals,\n",
    "        early_stopping_rounds=20\n",
    "    )\n",
    "\n",
    "    # Importância das features (gain)\n",
    "    importance_dict = model.get_score(importance_type='gain')\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': list(importance_dict.keys()),\n",
    "        'importance': list(importance_dict.values())\n",
    "    }).sort_values(by='importance', ascending=False)\n",
    "\n",
    "    total_gain = importance_df['importance'].sum()\n",
    "    importance_df['cumulative_gain'] = importance_df['importance'].cumsum() / total_gain\n",
    "    selected_features_max = importance_df[importance_df['cumulative_gain'] <= 0.98]['feature'].tolist()\n",
    "    qtd_features = len(selected_features_max)\n",
    "\n",
    "    # Previsões\n",
    "    y_pred_train = model.predict(dtrain)\n",
    "    y_pred_valid = model.predict(dvalid)\n",
    "    y_pred_oot = model.predict(doot)\n",
    "\n",
    "    # Função já existente\n",
    "    ks_train, gini_train, auc_train, bad_decil10_train, bad_decil30_train, bad_decil40_train = calculate_metrics(y_train.values, y_pred_train)\n",
    "    ks_valid, gini_valid, auc_valid, bad_decil10_valid, bad_decil30_valid, bad_decil40_valid = calculate_metrics(y_valid.values, y_pred_valid)\n",
    "    ks_oot, gini_oot, auc_oot, bad_decil10_oot, bad_decil30_oot, bad_decil40_oot = calculate_metrics(y_oot.values, y_pred_oot)\n",
    "\n",
    "    shift_oot = ((gini_oot - gini_train) / gini_train) * 100\n",
    "\n",
    "    # Registro dos resultados\n",
    "    results.append({\n",
    "        \"iteration\": iteration,\n",
    "        \"params\": params,\n",
    "        'best_iteration': model.num_boosted_rounds(),\n",
    "        \"features_relevance\": qtd_features,\n",
    "        \"ks2_train\": ks_train,\n",
    "        \"gini_train\": gini_train,\n",
    "        \"auc_train\": auc_train,\n",
    "        \"bad_decil10_train\": bad_decil10_train,\n",
    "        \"bad_decil30_train\": bad_decil30_train,\n",
    "        \"bad_decil40_train\": bad_decil40_train,\n",
    "        \"ks2_valid\": ks_valid,\n",
    "        \"gini_valid\": gini_valid,\n",
    "        \"auc_valid\": auc_valid,\n",
    "        \"bad_decil10_valid\": bad_decil10_valid,\n",
    "        \"bad_decil30_valid\": bad_decil30_valid,\n",
    "        \"bad_decil40_valid\": bad_decil40_valid,\n",
    "        \"ks2_oot\": ks_oot,\n",
    "        \"gini_oot\": gini_oot,\n",
    "        \"auc_oot\": auc_oot,\n",
    "        \"bad_decil10_oot\": bad_decil10_oot,\n",
    "        \"bad_decil30_oot\": bad_decil30_oot,\n",
    "        \"bad_decil40_oot\": bad_decil40_oot,\n",
    "        'shift_oot': shift_oot,\n",
    "    })\n",
    "\n",
    "    return auc_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "152cda9b-0399-4dd0-90a5-cb0b54690c26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def objective_express_rdf(trial, X_train, X_valid, X_oot, y_train, y_valid, y_oot, iteration, results):\n",
    "    \"\"\"\n",
    "    Função objetivo do Optuna para otimização de hiperparâmetros usando RandomForestClassifier (scikit-learn).\n",
    "    Mantém regras de negócio originais.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sugestão de hiperparâmetros via Optuna\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 20),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 20),\n",
    "        \"max_features\": trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", None]),\n",
    "        \"bootstrap\": trial.suggest_categorical(\"bootstrap\", [True, False]),\n",
    "        \"class_weight\": trial.suggest_categorical(\"is_unbalance\", [None, \"balanced\"]),\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1\n",
    "    }\n",
    "\n",
    "    # Treinamento\n",
    "    model = RandomForestClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Importância das features\n",
    "    importance_df = pd.DataFrame({\n",
    "        \"feature\": X_train.columns,\n",
    "        \"importance\": model.feature_importances_\n",
    "    }).sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "    total_gain = importance_df['importance'].sum()\n",
    "    importance_df['cumulative_gain'] = importance_df['importance'].cumsum() / total_gain\n",
    "    selected_features_max = importance_df[importance_df['cumulative_gain'] <= 0.98]['feature'].tolist()\n",
    "    qtd_features = len(selected_features_max)\n",
    "\n",
    "    # Previsões (probabilidade de classe positiva)\n",
    "    y_pred_train = model.predict_proba(X_train)[:, 1]\n",
    "    y_pred_valid = model.predict_proba(X_valid)[:, 1]\n",
    "    y_pred_oot = model.predict_proba(X_oot)[:, 1]\n",
    "\n",
    "    # Métricas de negócio\n",
    "    ks_train, gini_train, auc_train, bad_decil10_train, bad_decil30_train, bad_decil40_train = calculate_metrics(y_train.values, y_pred_train)\n",
    "    ks_valid, gini_valid, auc_valid, bad_decil10_valid, bad_decil30_valid, bad_decil40_valid = calculate_metrics(y_valid.values, y_pred_valid)\n",
    "    ks_oot, gini_oot, auc_oot, bad_decil10_oot, bad_decil30_oot, bad_decil40_oot = calculate_metrics(y_oot.values, y_pred_oot)\n",
    "\n",
    "    shift_oot = ((gini_oot - gini_train) / gini_train) * 100\n",
    "\n",
    "    # Registro dos resultados\n",
    "    results.append({\n",
    "        \"iteration\": iteration,\n",
    "        \"params\": params,\n",
    "        \"features_relevance\": qtd_features,\n",
    "        \"ks2_train\": ks_train,\n",
    "        \"gini_train\": gini_train,\n",
    "        \"auc_train\": auc_train,\n",
    "        \"bad_decil10_train\": bad_decil10_train,\n",
    "        \"bad_decil30_train\": bad_decil30_train,\n",
    "        \"bad_decil40_train\": bad_decil40_train,\n",
    "        \"ks2_valid\": ks_valid,\n",
    "        \"gini_valid\": gini_valid,\n",
    "        \"auc_valid\": auc_valid,\n",
    "        \"bad_decil10_valid\": bad_decil10_valid,\n",
    "        \"bad_decil30_valid\": bad_decil30_valid,\n",
    "        \"bad_decil40_valid\": bad_decil40_valid,\n",
    "        \"ks2_oot\": ks_oot,\n",
    "        \"gini_oot\": gini_oot,\n",
    "        \"auc_oot\": auc_oot,\n",
    "        \"bad_decil10_oot\": bad_decil10_oot,\n",
    "        \"bad_decil30_oot\": bad_decil30_oot,\n",
    "        \"bad_decil40_oot\": bad_decil40_oot,\n",
    "        'shift_oot': shift_oot,\n",
    "    })\n",
    "\n",
    "    return auc_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e22ad58-3126-4a4f-bf1a-6b1d7f1b2ec0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def objective_express_catb(trial, X_train, X_valid, X_oot, y_train, y_valid, y_oot, iteration, results):\n",
    "    \"\"\"\n",
    "    Função objetivo do Optuna para otimização de hiperparâmetros usando CatBoostClassifier.\n",
    "    Mantém regras de negócio originais.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sugestão de hiperparâmetros pelo Optuna\n",
    "    params = {\n",
    "        # \"iterations\": trial.suggest_int(\"iterations\", 200, 2000),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.0001, 0.3, log=True),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 2, 10),\n",
    "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1e-3, 10.0, log=True),\n",
    "        \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0.0, 10.0),\n",
    "        \"border_count\": trial.suggest_int(\"border_count\", 32, 255),\n",
    "        \"scale_pos_weight\": trial.suggest_categorical('is_unbalance', [1.0, (len(y_train)-sum(y_train))/sum(y_train)]),\n",
    "        \"eval_metric\": \"AUC\",\n",
    "        \"loss_function\": \"Logloss\",\n",
    "        \"verbose\": False,\n",
    "        \"random_seed\": 42\n",
    "    }\n",
    "\n",
    "    # Criação do modelo\n",
    "    model = CatBoostClassifier(**params, iterations=1000)\n",
    "\n",
    "\n",
    "    # Treinamento com conjuntos de validação para early stopping\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=(X_valid, y_valid),\n",
    "        early_stopping_rounds=50,\n",
    "        use_best_model=True\n",
    "    )\n",
    "\n",
    "    # Importância das features\n",
    "    importance_df = pd.DataFrame({\n",
    "        \"feature\": X_train.columns,\n",
    "        \"importance\": model.get_feature_importance(type='PredictionValuesChange')\n",
    "    }).sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "    total_gain = importance_df['importance'].sum()\n",
    "    importance_df['cumulative_gain'] = importance_df['importance'].cumsum() / total_gain\n",
    "    selected_features_max = importance_df[importance_df['cumulative_gain'] <= 0.98]['feature'].tolist()\n",
    "    qtd_features = len(selected_features_max)\n",
    "\n",
    "    # Previsões (probabilidade classe positiva)\n",
    "    y_pred_train = model.predict_proba(X_train)[:, 1]\n",
    "    y_pred_valid = model.predict_proba(X_valid)[:, 1]\n",
    "    y_pred_oot = model.predict_proba(X_oot)[:, 1]\n",
    "    # [:, 1]\n",
    "\n",
    "    # Métricas de negócio (mantém função existente)\n",
    "    ks_train, gini_train, auc_train, bad_decil10_train, bad_decil30_train, bad_decil40_train = calculate_metrics(y_train.values, y_pred_train)\n",
    "    ks_valid, gini_valid, auc_valid, bad_decil10_valid, bad_decil30_valid, bad_decil40_valid = calculate_metrics(y_valid.values, y_pred_valid)\n",
    "    ks_oot, gini_oot, auc_oot, bad_decil10_oot, bad_decil30_oot, bad_decil40_oot = calculate_metrics(y_oot.values, y_pred_oot)\n",
    "\n",
    "    shift_oot = ((gini_oot - gini_train) / gini_train) * 100\n",
    "\n",
    "    # Registro dos resultados\n",
    "    results.append({\n",
    "        \"iteration\": iteration,\n",
    "        \"params\": params,\n",
    "        'best_iteration': model.get_best_iteration(),\n",
    "        \"features_relevance\": qtd_features,\n",
    "        \"ks2_train\": ks_train,\n",
    "        \"gini_train\": gini_train,\n",
    "        \"auc_train\": auc_train,\n",
    "        \"bad_decil10_train\": bad_decil10_train,\n",
    "        \"bad_decil30_train\": bad_decil30_train,\n",
    "        \"bad_decil40_train\": bad_decil40_train,\n",
    "        \"ks2_valid\": ks_valid,\n",
    "        \"gini_valid\": gini_valid,\n",
    "        \"auc_valid\": auc_valid,\n",
    "        \"bad_decil10_valid\": bad_decil10_valid,\n",
    "        \"bad_decil30_valid\": bad_decil30_valid,\n",
    "        \"bad_decil40_valid\": bad_decil40_valid,\n",
    "        \"ks2_oot\": ks_oot,\n",
    "        \"gini_oot\": gini_oot,\n",
    "        \"auc_oot\": auc_oot,\n",
    "        \"bad_decil10_oot\": bad_decil10_oot,\n",
    "        \"bad_decil30_oot\": bad_decil30_oot,\n",
    "        \"bad_decil40_oot\": bad_decil40_oot,\n",
    "        'shift_oot': shift_oot,\n",
    "    })\n",
    "\n",
    "    return auc_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e9d4cb4f-e37e-4505-8730-e68e00416787",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def objective_express_mlp(trial, X_train, X_valid, X_oot, y_train, y_valid, y_oot, iteration, results):\n",
    "    \"\"\"\n",
    "    Função objetivo do Optuna para otimização de hiperparâmetros usando MLPClassifier (rede neural).\n",
    "    Mantém métricas e regras originais.\n",
    "    \"\"\"\n",
    "\n",
    "    # Espaço de busca de hiperparâmetros\n",
    "    params = {\n",
    "        \"hidden_layer_sizes\": tuple([\n",
    "            trial.suggest_int(f\"layer_{i}_neurons\", 10, 200) \n",
    "            for i in range(trial.suggest_int(\"n_layers\", 1, 3))\n",
    "        ]),\n",
    "        \"activation\": trial.suggest_categorical(\"activation\", [\"relu\", \"tanh\", \"logistic\"]),\n",
    "        \"solver\": trial.suggest_categorical(\"solver\", [\"adam\", \"sgd\"]),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1e-5, 1e-1, log=True),\n",
    "        \"learning_rate_init\": trial.suggest_float(\"learning_rate_init\", 1e-4, 1e-1, log=True),\n",
    "        \"max_iter\": 500,\n",
    "        \"random_state\": 42\n",
    "    }\n",
    "\n",
    "    # Treinamento\n",
    "    model = MLPClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Importância das features (usando coeficientes absolutos da primeira camada como proxy)\n",
    "    if hasattr(model, \"coefs_\"):\n",
    "        importances = pd.Series(abs(model.coefs_[0]).sum(axis=1), index=X_train.columns)\n",
    "    else:\n",
    "        importances = pd.Series([0]*X_train.shape[1], index=X_train.columns)\n",
    "    \n",
    "    importance_df = pd.DataFrame({\n",
    "        \"feature\": importances.index,\n",
    "        \"importance\": importances.values\n",
    "    }).sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "    total_gain = importance_df['importance'].sum()\n",
    "    importance_df['cumulative_gain'] = importance_df['importance'].cumsum() / total_gain\n",
    "    selected_features_max = importance_df[importance_df['cumulative_gain'] <= 0.98]['feature'].tolist()\n",
    "    qtd_features = len(selected_features_max)\n",
    "\n",
    "    # Predições\n",
    "    y_pred_train = model.predict_proba(X_train)[:, 1]\n",
    "    y_pred_valid = model.predict_proba(X_valid)[:, 1]\n",
    "    y_pred_oot = model.predict_proba(X_oot)[:, 1]\n",
    "\n",
    "    # Métricas\n",
    "    ks_train, gini_train, auc_train, bad_decil10_train, bad_decil30_train, bad_decil40_train = calculate_metrics(y_train.values, y_pred_train)\n",
    "    ks_valid, gini_valid, auc_valid, bad_decil10_valid, bad_decil30_valid, bad_decil40_valid = calculate_metrics(y_valid.values, y_pred_valid)\n",
    "    ks_oot, gini_oot, auc_oot, bad_decil10_oot, bad_decil30_oot, bad_decil40_oot = calculate_metrics(y_oot.values, y_pred_oot)\n",
    "\n",
    "    shift_oot = ((gini_oot - gini_train) / gini_train) * 100\n",
    "\n",
    "    # Registro\n",
    "    results.append({\n",
    "        \"iteration\": iteration,\n",
    "        \"params\": params,\n",
    "        \"features_relevance\": qtd_features,\n",
    "        \"ks2_train\": ks_train,\n",
    "        \"gini_train\": gini_train,\n",
    "        \"auc_train\": auc_train,\n",
    "        \"bad_decil10_train\": bad_decil10_train,\n",
    "        \"bad_decil30_train\": bad_decil30_train,\n",
    "        \"bad_decil40_train\": bad_decil40_train,\n",
    "        \"ks2_valid\": ks_valid,\n",
    "        \"gini_valid\": gini_valid,\n",
    "        \"auc_valid\": auc_valid,\n",
    "        \"bad_decil10_valid\": bad_decil10_valid,\n",
    "        \"bad_decil30_valid\": bad_decil30_valid,\n",
    "        \"bad_decil40_valid\": bad_decil40_valid,\n",
    "        \"ks2_oot\": ks_oot,\n",
    "        \"gini_oot\": gini_oot,\n",
    "        \"auc_oot\": auc_oot,\n",
    "        \"bad_decil10_oot\": bad_decil10_oot,\n",
    "        \"bad_decil30_oot\": bad_decil30_oot,\n",
    "        \"bad_decil40_oot\": bad_decil40_oot,\n",
    "        'shift_oot': shift_oot,\n",
    "    })\n",
    "\n",
    "    return auc_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf37d73a-0816-4097-a5c4-cee3c6443868",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def main(data_spark, data_spark_oot, list_features, target, dev, metric, n_trials):\n",
    "\n",
    "    \"\"\"\n",
    "    Orquestra a preparação de dados, a seleção do modelo e a otimização\n",
    "    de hiperparâmetros usando Optuna para um modelo de classificação.\n",
    "\n",
    "    Args:\n",
    "        data_spark (pyspark.sql.DataFrame): Dados de desenvolvimento (Treino/Validação).\n",
    "        data_spark_oot (pyspark.sql.DataFrame): Dados Out-of-Time (OOT) para avaliação.\n",
    "        list_features (list): Lista de colunas (features) a serem utilizadas no modelo.\n",
    "        target (str): Nome da coluna target (binária).\n",
    "        dev (str, optional): Nome da coluna booleana que indica o conjunto de desenvolvimento.\n",
    "        metric (str): Métrica de avaliação a ser maximizada ('ks2', 'gini', 'auc').\n",
    "        n_trials (int): Número de tentativas de otimização a serem executadas pelo Optuna.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Um DataFrame contendo os resultados de cada trial de otimização,\n",
    "                          incluindo os parâmetros testados e as métricas de desempenho.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: Em caso de inconsistências nos dados, features, target ou métricas inválidas.\n",
    "\n",
    "    Example:\n",
    "        >>> results_df = main(\n",
    "    #     data_spark=data_spark_cat_dev_blend,\n",
    "    #     data_spark_oot=data_spark_cat_oot_blend,\n",
    "    #     list_features=features_model,\n",
    "    #     target=\"ever30reneg_mob3\",\n",
    "    #     dev=\"dev\",\n",
    "    #     metric=\"ks2\",\n",
    "    #     n_trials=50)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def menu():\n",
    "        print(\"Escolha uma opção:\")\n",
    "        print(\"1. Modelo LightGBM\")\n",
    "        print(\"2. Modelo XGBoost\")\n",
    "        print(\"3. Modelo Random Forest\")\n",
    "        print(\"4. Modelo CatBoost\")\n",
    "        print(\"5. Modelo MLPclassifier\")\n",
    "\n",
    "    menu()\n",
    "    modelo = int(input(\"Escolha uma opção: \"))\n",
    "\n",
    "    # Função para limpar labels e features (Pandas)\n",
    "    def clean_labels_and_features(X_df, y_series):\n",
    "        mask_labels = y_series.isin([0, 1]) & ~y_series.isna()\n",
    "        X_clean = X_df[mask_labels].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "        y_clean = y_series[mask_labels].loc[X_clean.index]\n",
    "        return X_clean, y_clean\n",
    "\n",
    "    # -----------------------------\n",
    "    # Validações com Spark DataFrame\n",
    "    # -----------------------------\n",
    "    list_not_in = [column for column in list_features if column not in data_spark.columns]\n",
    "    list_not_in_oot = [column for column in list_features if column not in data_spark_oot.columns]\n",
    "    if list_not_in:\n",
    "        raise ValueError(f\"Features {list_not_in} não estão no data_spark.\")\n",
    "    if list_not_in_oot:\n",
    "        raise ValueError(f\"Features {list_not_in_oot} não estão no data_spark_oot.\")\n",
    "    if target not in data_spark.columns:\n",
    "        raise ValueError(f\"Target {target} não está no data_spark.\")\n",
    "    if target not in data_spark_oot.columns:\n",
    "        raise ValueError(f\"Target {target} não está no data_spark_oot.\")\n",
    "    if dev is not None and dev not in data_spark.columns:\n",
    "        raise ValueError(f\"Dev {dev} não está no data_spark.\")\n",
    "\n",
    "    # target binário — ignorando nulos\n",
    "    target_value = [row[target] for row in data_spark.select(target).distinct().collect()]\n",
    "    target_value = [v for v in target_value if v is not None]\n",
    "    if not all(value in [0, 1] for value in target_value):\n",
    "        raise ValueError(f\"Target {target} possui valores {target_value} — esperado só 0 e 1.\")\n",
    "\n",
    "    target_value_oot = [row[target] for row in data_spark_oot.select(target).distinct().collect()]\n",
    "    target_value_oot = [v for v in target_value_oot if v is not None]\n",
    "    if not all(value in [0, 1] for value in target_value_oot):\n",
    "        raise ValueError(f\"Target {target} possui valores {target_value_oot} — esperado só 0 e 1.\")\n",
    "\n",
    "    # validar tipo numérico das features\n",
    "    type_num_columns = [f.name for f in data_spark.selectExpr(*list_features).schema.fields if isinstance(f.dataType, NumericType)]\n",
    "    type_num_columns_oot = [f.name for f in data_spark_oot.selectExpr(*list_features).schema.fields if isinstance(f.dataType, NumericType)]\n",
    "    type_num_list_not_in = [column for column in list_features if column not in type_num_columns]\n",
    "    type_num_list_not_in_oot = [column for column in list_features if column not in type_num_columns_oot]\n",
    "    if type_num_list_not_in:\n",
    "        raise ValueError(f\"Features {type_num_list_not_in} não são NumericType no data_spark.\")\n",
    "    if type_num_list_not_in_oot:\n",
    "        raise ValueError(f\"Features {type_num_list_not_in_oot} não são NumericType no data_spark_oot.\")\n",
    "\n",
    "    # métricas válidas\n",
    "    list_possible_metrics = ['ks2', 'gini', 'auc']\n",
    "    if metric.lower() not in list_possible_metrics:\n",
    "        raise ValueError(f\"Métrica {metric} inválida. Escolha {list_possible_metrics}.\")\n",
    "    metric = metric.lower()\n",
    "\n",
    "    if n_trials <= 0:\n",
    "        raise ValueError(\"n_trials deve ser > 0.\")\n",
    "\n",
    "    if dev is not None:\n",
    "        type_bool_columns = [f.name for f in data_spark.selectExpr(dev).schema.fields if isinstance(f.dataType, BooleanType)]\n",
    "        if type_bool_columns != [dev]:\n",
    "            raise ValueError(f\"A coluna {dev} precisa ser booleana.\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Conversão para Pandas — removendo linhas com target nulo\n",
    "    # -----------------------------\n",
    "    data_pandas = data_spark.filter(f\"{target} IS NOT NULL\").toPandas()\n",
    "    data_pandas_oot = data_spark_oot.filter(f\"{target} IS NOT NULL\").toPandas()\n",
    "\n",
    "    X = data_pandas[list_features]\n",
    "    y = data_pandas[target]\n",
    "    X_oot = data_pandas_oot[list_features]\n",
    "    y_oot = data_pandas_oot[target]\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    X_train, y_train = clean_labels_and_features(X_train, y_train)\n",
    "    X_valid, y_valid = clean_labels_and_features(X_valid, y_valid)\n",
    "    X_oot, y_oot = clean_labels_and_features(X_oot, y_oot)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Otimização com Optuna\n",
    "    # -----------------------------\n",
    "    results = []\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "    if modelo == 1:\n",
    "        nome_modelo = 'LightGBMClassifier'\n",
    "        for i in range(1, n_trials + 1):\n",
    "            study.optimize(\n",
    "                lambda trial: objective_express(trial, X_train, X_valid, X_oot, y_train, y_valid, y_oot, iteration=i, results=results),\n",
    "                n_trials=1,\n",
    "                show_progress_bar=False\n",
    "            )\n",
    "    elif modelo == 2:\n",
    "        nome_modelo = 'XGBoostClassifier'\n",
    "        for i in range(1, n_trials + 1):\n",
    "            study.optimize(\n",
    "                lambda trial: objective_express_xgb(trial, X_train, X_valid, X_oot, y_train, y_valid, y_oot, iteration=i, results=results),\n",
    "                n_trials=1,\n",
    "                show_progress_bar=False\n",
    "            )\n",
    "    elif modelo == 3:\n",
    "        nome_modelo = 'RandomForestClassifier'\n",
    "        for i in range(1, n_trials + 1):\n",
    "            study.optimize(\n",
    "                lambda trial: objective_express_RdF(trial, X_train, X_valid, X_oot, y_train, y_valid, y_oot, iteration=i, results=results),\n",
    "                n_trials=1,\n",
    "                show_progress_bar=False\n",
    "            )\n",
    "    elif modelo == 4:\n",
    "        nome_modelo = 'CatBoostClassifier'\n",
    "        for i in range(1, n_trials + 1):\n",
    "            study.optimize(\n",
    "                lambda trial: objective_express_catb(trial, X_train, X_valid, X_oot, y_train, y_valid, y_oot, iteration=i, results=results),\n",
    "                n_trials=1,\n",
    "                show_progress_bar=False\n",
    "            )\n",
    "    elif modelo == 5:\n",
    "        nome_modelo = 'MLPclassifier'\n",
    "        for i in range(1, n_trials + 1):\n",
    "            study.optimize(\n",
    "                lambda trial: objective_express_mlp(trial, X_train, X_valid, X_oot, y_train, y_valid, y_oot, iteration=i, results=results),\n",
    "                n_trials=1,\n",
    "                show_progress_bar=False\n",
    "            )\n",
    "\n",
    "    best_params = study.best_params\n",
    "    print(\"Melhores parâmetros:\", best_params)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df[\"model_champion\"] = nome_modelo\n",
    "    return results_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f80e942-2f15-4e14-823e-941ff18821bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# def plot_best_model_exp(metrics_result, metric=\"ks2\"):\n",
    "#     fig = px.scatter(\n",
    "#         metrics_result,\n",
    "#         x=f\"{metric}_train\",\n",
    "#         y=f\"{metric}_valid\",\n",
    "#         color=\"features_relevance\",  # Cor de cada ponto de acordo com a iteração\n",
    "#         hover_data=[\"iteration\", \"bad_decil10_train\", \"bad_decil10_valid\"],  # Exibe o número da iteração ao passar o mouse\n",
    "#         labels={f\"{metric}_train\": f\"{metric.upper()} Train\",\n",
    "#                 f\"{metric}_valid\": f\"{metric.upper()} Valid/Test\",\n",
    "#                 \"features_relevance\": \"Feature Relevance\",\n",
    "#                 \"bad_decil10_train\": \"BadRate Top10% Train\",\n",
    "#                 \"bad_decil10_valid\": \"BadRate Top10% Valid/Test\"},\n",
    "\n",
    "#         title=f\"{metric.upper()} Train vs. {metric.upper()} Valid\"\n",
    "#     )\n",
    "\n",
    "#     # Ajustando o layout do gráfico\n",
    "#     fig.update_traces(marker=dict(size=12, line=dict(width=2, color='DarkSlateGrey')))\n",
    "#     fig.update_layout(title=f\"{metric.upper()} Train vs. {metric.upper()} Valid\", title_x=0.5)\n",
    "\n",
    "#     fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8cde1d8d-8b30-4054-ab71-3e81193450e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def plot_best_model_express(metrics_result, metric=\"ks2\",  label_x = 'train', label_y = 'valid'):\n",
    "    fig = px.scatter(\n",
    "        metrics_result,\n",
    "        x=f\"{metric}_{label_x}\",\n",
    "        y=f\"{metric}_{label_y}\",\n",
    "        color=\"features_relevance\",  # Cor de cada ponto de acordo com a iteração\n",
    "        hover_data=[f\"{metric}_oot\", \"iteration\", \"bad_decil10_train\", \"bad_decil10_valid\", 'bad_decil10_oot', \"bad_decil30_train\", \"bad_decil30_valid\", 'bad_decil30_oot'],  # Exibe o número da iteração ao passar o mouse\n",
    "        labels={f\"{metric}_{label_x}\": f\"{metric.upper()} {label_x}\",\n",
    "                f\"{metric}_{label_y}\": f\"{metric.upper()} {label_y}/Test\",\n",
    "                f\"{metric}_oot\": f\"{metric.upper()} OOT\",\n",
    "                \"features_relevance\": \"Feature Relevance\",\n",
    "                f\"bad_decil10_{label_x}\": f\"BadRate Top10% {label_x}\",\n",
    "                f\"bad_decil10_{label_y}\": f\"BadRate Top10% {label_y}/Test\",\n",
    "                f\"bad_decil10_oot\": f\"BadRate Top10% OOT\",\n",
    "                f\"bad_decil30_{label_x}\": f\"BadRate Top30% {label_x}\",\n",
    "                f\"bad_decil30_{label_y}\": f\"BadRate Top30% {label_y}/Test\",\n",
    "                f\"bad_decil30_oot\": f\"BadRate Top30% OOT\",\n",
    "                },\n",
    "\n",
    "        title=f\"{metric.upper()} {label_x} vs. {metric.upper()} {label_y}\"\n",
    "    )\n",
    "\n",
    "    # Ajustando o layout do gráfico\n",
    "    fig.update_traces(marker=dict(size=12, line=dict(width=2, color='DarkSlateGrey')))\n",
    "    fig.update_layout(title=f\"{metric.upper()} {label_x} vs. {metric.upper()} {label_y}\", title_x=0.5)\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d55d7957-b283-4bd9-bdae-5051b06530f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# def model_lgbm_express_v2(data_spark, data_spark_oot, list_features, target, dev = None, n_trials = 20, metric = \"ks2\", max_nsample = 100000):\n",
    "    \n",
    "#     \"\"\"\n",
    "#     Treina e otimiza um modelo LightGBM utilizando Optuna para busca de hiperparâmetros, com suporte a métricas de avaliação como KS2, Gini e AUC.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     data_spark : pyspark.sql.DataFrame\n",
    "#         DataFrame Spark contendo os dados de entrada para o treinamento do modelo.\n",
    "    \n",
    "#     list_features : list of str\n",
    "#         Lista com os nomes das colunas que serão utilizadas como features no modelo.\n",
    "    \n",
    "#     target : str\n",
    "#         Nome da coluna alvo (variável dependente). Deve ser binária com valores 0 e 1.\n",
    "    \n",
    "#     dev : str, optional\n",
    "#         Nome da coluna de desenvolvimento (booleano), indicando as linhas que serão utilizadas no treinamento. \n",
    "#         Se não for especificada, toda a base será usada. Por padrão, `None`.\n",
    "    \n",
    "#     n_trials : int, optional\n",
    "#         Número de iterações para a otimização dos hiperparâmetros. Deve ser maior que 0. Por padrão, 20.\n",
    "    \n",
    "#     metric : str, optional\n",
    "#         Métrica utilizada para avaliar o modelo. As opções disponíveis são:\n",
    "#         - `'ks2'` (Kolmogorov-Smirnov)\n",
    "#         - `'gini'`\n",
    "#         - `'auc'` (Área sob a curva ROC)\n",
    "#         Por padrão, `'ks2'`.\n",
    "    \n",
    "#     max_nsample : int, optional\n",
    "#         Número máximo de amostras utilizadas para o treinamento. Caso o dataset tenha mais registros, será feita uma amostragem aleatória.\n",
    "#         Por padrão, 100000.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     tuple\n",
    "#         - **best_params**: dict\n",
    "#             Dicionário com os melhores hiperparâmetros encontrados pela otimização.\n",
    "#         - **results_df**: pandas.DataFrame\n",
    "#             DataFrame contendo os resultados detalhados de cada iteração da busca por hiperparâmetros.\n",
    "\n",
    "#     Raises\n",
    "#     ------\n",
    "#     ValueError\n",
    "#         - Se `list_features` contiver colunas que não estão presentes no `data_spark`.\n",
    "#         - Se o `target` não for encontrado no `data_spark`.\n",
    "#         - Se `target` não for binário com valores 0 e 1.\n",
    "#         - Se `list_features` contiver colunas que não sejam numéricas.\n",
    "#         - Se a métrica especificada em `metric` não estiver entre as opções permitidas.\n",
    "#         - Se `n_trials` for menor ou igual a 0.\n",
    "#         - Se a coluna `dev` (caso especificada) não for do tipo booleano.\n",
    "\n",
    "#     Notes\n",
    "#     -----\n",
    "#     - O processo realiza uma validação dos dados e assegura que os tipos das colunas estejam corretos antes de iniciar o treinamento.\n",
    "#     - Os resultados são apresentados por meio de um gráfico da métrica de avaliação especificada.\n",
    "#     - A otimização usa uma amostragem do dataset se o número de registros exceder o valor de `max_nsample`.\n",
    "\n",
    "#     Examples\n",
    "#     --------\n",
    "#     >>> best_params, results_df = model_lgbm_express(\n",
    "#     ...     data_spark=data_spark,\n",
    "#     ...     list_features=[\"feature1\", \"feature2\", \"feature3\"],\n",
    "#     ...     target=\"target\",\n",
    "#     ...     dev=\"is_dev\",\n",
    "#     ...     n_trials=10,\n",
    "#     ...     metric=\"gini\",\n",
    "#     ...     max_nsample=50000\n",
    "#     ... )\n",
    "#     >>> print(best_params)\n",
    "#     >>> print(results_df.head())\n",
    "#     \"\"\"\n",
    "    \n",
    "\n",
    "#     #######Validacoes#######\n",
    "#     #validando se a lista esta presente na tabela de input\n",
    "#     list_not_in = [column for column in list_features if column not in data_spark.columns]\n",
    "\n",
    "#     list_not_in_oot = [column for column in list_features if column not in data_spark_oot.columns]\n",
    "\n",
    "#     if list_not_in != []:\n",
    "#         raise ValueError(f\"A lista de features {list_not_in} do parâmetro list_features para o processo de modelagem não esta presente na tabela de input, especificado no parâmetro data_spark.\")\n",
    "\n",
    "#     if list_not_in_oot != []:\n",
    "#         raise ValueError(f\"A lista de features {list_not_in_oot} do parâmetro list_features para o processo de modelagem não esta presente na tabela de input, especificado no parâmetro data_spark.\")\n",
    "\n",
    "#     if target not in data_spark.columns:\n",
    "#         raise ValueError(f\"A variavel {target} especificada no parâmetro target não esta presente no tabela de input, especificado no parâmetro data_spark.\")\n",
    "\n",
    "#     if target not in data_spark_oot.columns:\n",
    "#         raise ValueError(f\"A variavel {target} especificada no parâmetro target não esta presente no tabela de input, especificado no parâmetro data_spark.\")\n",
    "\n",
    "\n",
    "#     if dev != None:\n",
    "#         if dev not in data_spark.columns:\n",
    "#             raise ValueError(f\"A variavel {dev} especificada no parâmetro dev não esta presente no tabela de input, especificado no parâmetro data_spark.\")\n",
    "\n",
    "\n",
    "#     #validando se o target é binario\n",
    "#     target_value  = data_spark.select(target).distinct().rdd.flatMap(lambda row: row).collect()\n",
    "#     result_bool = all(value in [1, 0] for value in target_value)\n",
    "\n",
    "#     #validando se o target é binario\n",
    "#     target_value_oot  = data_spark_oot.select(target).distinct().rdd.flatMap(lambda row: row).collect()\n",
    "#     result_bool_oot = all(value in [1, 0] for value in target_value_oot)\n",
    "\n",
    "#     if result_bool == False:\n",
    "#         raise ValueError(f\"A variavel {target} especificada no parâmetro target possui os seguintes valores {target_value}, logo o processo binning foi desenvolvido para problemas de classificação assumindo somente valores (0,1).\")\n",
    "\n",
    "#     if result_bool_oot == False:\n",
    "#         raise ValueError(f\"A variavel {target} especificada no parâmetro target possui os seguintes valores {target_value_oot}, logo o processo binning foi desenvolvido para problemas de classificação assumindo somente valores (0,1).\")\n",
    "\n",
    "\n",
    "#     #Verificando se as colunas listadas como numericas são numericas no dataset\n",
    "#     type_num_columns = [col.name for col in data_spark.selectExpr(*list_features).schema.fields  if isinstance(col.dataType, NumericType)]\n",
    "\n",
    "#     type_num_columns_oot = [col.name for col in data_spark_oot.selectExpr(*list_features).schema.fields  if isinstance(col.dataType, NumericType)]\n",
    "\n",
    "\n",
    "#     #comparando lista numerica vs. lista dataset numerica\n",
    "#     type_num_list_not_in = [column for column in list_features if column not in type_num_columns]\n",
    "\n",
    "#     type_num_list_not_in_oot = [column for column in list_features if column not in type_num_columns_oot]\n",
    "\n",
    "#     if type_num_list_not_in != []:\n",
    "#         raise ValueError(f\"A lista de features do parâmetro list_features precisam ser do tipo NumericType. As features {type_num_list_not_in} estão presentes na lista mas não são do tipo  NumericType na tabela de input, especificado no parâmetro data_spark.\")\n",
    "\n",
    "#     if type_num_list_not_in_oot != []:\n",
    "#         raise ValueError(f\"A lista de features do parâmetro list_features precisam ser do tipo NumericType. As features {type_num_list_not_in_oot} estão presentes na lista mas não são do tipo  NumericType na tabela de input, especificado no parâmetro data_spark.\")\n",
    "\n",
    "#     list_possible_metrics = ['ks2', 'gini', 'auc']\n",
    "#     # Verifica se a métrica é válida, ignorando case sensitivity\n",
    "#     metric_result_valid = [m for m in list_possible_metrics if m == metric.lower()]\n",
    "\n",
    "#     # Levanta um erro se nenhuma correspondência for encontrada\n",
    "#     if not metric_result_valid: \n",
    "#         raise ValueError(f\"A métrica '{metric}' especificada no parâmetro 'metric' não está presente nas possibilidades: {list_possible_metrics}. \"f\"Escolha uma das opções disponíveis.\")\n",
    "\n",
    "#     metric = metric.lower()\n",
    "\n",
    "#     if n_trials <= 0:\n",
    "#         raise ValueError(\"O valor do n_trials tem que ser maior do que 0.\")\n",
    "\n",
    "#     if dev != None:\n",
    "#         type_bool_columns = [col.name for col in data_spark.selectExpr(dev).schema.fields if isinstance(col.dataType, BooleanType)]\n",
    "\n",
    "#         if type_bool_columns != [dev]:\n",
    "#             raise ValueError(f\"A feature {dev} definida no parâmetro dev precisa ser do tipo booleano (True e False)\")\n",
    "\n",
    "\n",
    "#     #marcacao dos resultados\n",
    "#     results = []\n",
    "\n",
    "#     #transformando data set em pandas\n",
    "#     data_pandas = data_spark.toPandas()\n",
    "#     data_pandas_oot = data_spark_oot.toPandas()\n",
    "\n",
    "#     # dev_lgbm_exp = 'dev_lgbm_exp'\n",
    "#     data_pandas['dev_lgbm_exp'] = True\n",
    "\n",
    "\n",
    "#     if dev is None:\n",
    "#         print(\"Não foi especificada uma coluna para treinar o processo de categorização, logo será utilizado `100%` da sua base para criar o modelo modelagem.\")\n",
    " \n",
    "    \n",
    "#     data_pandas = data_pandas[data_pandas[dev] == True]\n",
    "\n",
    "#     # Avaliando tamanho da amostra\n",
    "#     sizedata = len(data_pandas)\n",
    "#     # Validando o tamanho da amostra\n",
    "#     if sizedata > max_nsample:\n",
    "#         print(f\"O dataframe definido no parâmetro data_spark tem um tamanho de {sizedata}. Foi selecionada uma amostra com tamanho {max_nsample} para o processo de modelagem\")\n",
    "        \n",
    "#         data_pandas = data_pandas.sample(frac=max_nsample/sizedata, random_state=42)\n",
    "\n",
    "\n",
    "#     X_train, X_valid, y_train, y_valid = train_test_split(data_pandas[list_features], data_pandas[target], test_size=0.2, random_state=42)\n",
    "\n",
    "#     X_oot = data_pandas_oot[list_features]\n",
    "#     y_oot = data_pandas_oot[target]\n",
    "\n",
    "#     # Otimização via Optuna com índice da iteração\n",
    "#     study = optuna.create_study(direction=\"minimize\")\n",
    "\n",
    "#     for i in range(1, (n_trials + 1)):\n",
    "#         study.optimize(lambda trial, iteration=i: objective_express_V2(trial, X_train, X_valid, X_oot, y_train, y_valid, y_oot, iteration, results), n_trials=1, show_progress_bar=False)\n",
    "#         pass\n",
    "\n",
    "#     # Melhores parâmetros\n",
    "#     best_params = study.best_params\n",
    "#     # print(\"Melhores parâmetros:\", best_params)\n",
    "\n",
    "#     # Converter os resultados em um DataFrame para análise\n",
    "#     results_df = pd.DataFrame(results)\n",
    "#     # print(results_df)\n",
    "\n",
    "#     plot_best_model_exp(metrics_result = results_df, metric = metric)\n",
    "\n",
    "#     return best_params, results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cdd3440b-66ad-4961-a26b-69d5b8f8b6d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#antigo v3\n",
    "def model_lgbm_express(data_spark, data_spark_oot, list_features, target, dev = None, n_trials = 20, metric = \"ks2\", max_nsample = 100000):\n",
    "    \n",
    "    \"\"\"\n",
    "    Treina e otimiza um modelo LightGBM utilizando Optuna para busca de hiperparâmetros, com suporte a métricas de avaliação como KS2, Gini e AUC.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_spark : pyspark.sql.DataFrame\n",
    "        DataFrame Spark contendo os dados de entrada para o treinamento do modelo.\n",
    "    \n",
    "    list_features : list of str\n",
    "        Lista com os nomes das colunas que serão utilizadas como features no modelo.\n",
    "    \n",
    "    target : str\n",
    "        Nome da coluna alvo (variável dependente). Deve ser binária com valores 0 e 1.\n",
    "    \n",
    "    dev : str, optional\n",
    "        Nome da coluna de desenvolvimento (booleano), indicando as linhas que serão utilizadas no treinamento. \n",
    "        Se não for especificada, toda a base será usada. Por padrão, `None`.\n",
    "    \n",
    "    n_trials : int, optional\n",
    "        Número de iterações para a otimização dos hiperparâmetros. Deve ser maior que 0. Por padrão, 20.\n",
    "    \n",
    "    metric : str, optional\n",
    "        Métrica utilizada para avaliar o modelo. As opções disponíveis são:\n",
    "        - `'ks2'` (Kolmogorov-Smirnov)\n",
    "        - `'gini'`\n",
    "        - `'auc'` (Área sob a curva ROC)\n",
    "        Por padrão, `'ks2'`.\n",
    "    \n",
    "    max_nsample : int, optional\n",
    "        Número máximo de amostras utilizadas para o treinamento. Caso o dataset tenha mais registros, será feita uma amostragem aleatória.\n",
    "        Por padrão, 100000.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        - **best_params**: dict\n",
    "            Dicionário com os melhores hiperparâmetros encontrados pela otimização.\n",
    "        - **results_df**: pandas.DataFrame\n",
    "            DataFrame contendo os resultados detalhados de cada iteração da busca por hiperparâmetros.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        - Se `list_features` contiver colunas que não estão presentes no `data_spark`.\n",
    "        - Se o `target` não for encontrado no `data_spark`.\n",
    "        - Se `target` não for binário com valores 0 e 1.\n",
    "        - Se `list_features` contiver colunas que não sejam numéricas.\n",
    "        - Se a métrica especificada em `metric` não estiver entre as opções permitidas.\n",
    "        - Se `n_trials` for menor ou igual a 0.\n",
    "        - Se a coluna `dev` (caso especificada) não for do tipo booleano.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - O processo realiza uma validação dos dados e assegura que os tipos das colunas estejam corretos antes de iniciar o treinamento.\n",
    "    - Os resultados são apresentados por meio de um gráfico da métrica de avaliação especificada.\n",
    "    - A otimização usa uma amostragem do dataset se o número de registros exceder o valor de `max_nsample`.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> best_params, results_df = model_lgbm_express(\n",
    "    ...     data_spark=data_spark,\n",
    "    ...     list_features=[\"feature1\", \"feature2\", \"feature3\"],\n",
    "    ...     target=\"target\",\n",
    "    ...     dev=\"is_dev\",\n",
    "    ...     n_trials=10,\n",
    "    ...     metric=\"gini\",\n",
    "    ...     max_nsample=50000\n",
    "    ... )\n",
    "    >>> print(best_params)\n",
    "    >>> print(results_df.head())\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    #######Validacoes#######\n",
    "    #validando se a lista esta presente na tabela de input\n",
    "    list_not_in = [column for column in list_features if column not in data_spark.columns]\n",
    "\n",
    "    list_not_in_oot = [column for column in list_features if column not in data_spark_oot.columns]\n",
    "\n",
    "    if list_not_in != []:\n",
    "        raise ValueError(f\"A lista de features {list_not_in} do parâmetro list_features para o processo de modelagem não esta presente na tabela de input, especificado no parâmetro data_spark.\")\n",
    "\n",
    "    if list_not_in_oot != []:\n",
    "        raise ValueError(f\"A lista de features {list_not_in_oot} do parâmetro list_features para o processo de modelagem não esta presente na tabela de input, especificado no parâmetro data_spark.\")\n",
    "\n",
    "    if target not in data_spark.columns:\n",
    "        raise ValueError(f\"A variavel {target} especificada no parâmetro target não esta presente no tabela de input, especificado no parâmetro data_spark.\")\n",
    "\n",
    "    if target not in data_spark_oot.columns:\n",
    "        raise ValueError(f\"A variavel {target} especificada no parâmetro target não esta presente no tabela de input, especificado no parâmetro data_spark.\")\n",
    "\n",
    "\n",
    "    if dev != None:\n",
    "        if dev not in data_spark.columns:\n",
    "            raise ValueError(f\"A variavel {dev} especificada no parâmetro dev não esta presente no tabela de input, especificado no parâmetro data_spark.\")\n",
    "\n",
    "\n",
    "    #validando se o target é binario\n",
    "    target_value  = data_spark.select(target).distinct().rdd.flatMap(lambda row: row).collect()\n",
    "    result_bool = all(value in [1, 0] for value in target_value)\n",
    "\n",
    "    #validando se o target é binario\n",
    "    target_value_oot  = data_spark_oot.select(target).distinct().rdd.flatMap(lambda row: row).collect()\n",
    "    result_bool_oot = all(value in [1, 0] for value in target_value_oot)\n",
    "\n",
    "    if result_bool == False:\n",
    "        raise ValueError(f\"A variavel {target} especificada no parâmetro target possui os seguintes valores {target_value}, logo o processo binning foi desenvolvido para problemas de classificação assumindo somente valores (0,1).\")\n",
    "\n",
    "    if result_bool_oot == False:\n",
    "        raise ValueError(f\"A variavel {target} especificada no parâmetro target possui os seguintes valores {target_value_oot}, logo o processo binning foi desenvolvido para problemas de classificação assumindo somente valores (0,1).\")\n",
    "\n",
    "\n",
    "    #Verificando se as colunas listadas como numericas são numericas no dataset\n",
    "    type_num_columns = [col.name for col in data_spark.selectExpr(*list_features).schema.fields  if isinstance(col.dataType, NumericType)]\n",
    "\n",
    "    type_num_columns_oot = [col.name for col in data_spark_oot.selectExpr(*list_features).schema.fields  if isinstance(col.dataType, NumericType)]\n",
    "\n",
    "\n",
    "    #comparando lista numerica vs. lista dataset numerica\n",
    "    type_num_list_not_in = [column for column in list_features if column not in type_num_columns]\n",
    "\n",
    "    type_num_list_not_in_oot = [column for column in list_features if column not in type_num_columns_oot]\n",
    "\n",
    "    if type_num_list_not_in != []:\n",
    "        raise ValueError(f\"A lista de features do parâmetro list_features precisam ser do tipo NumericType. As features {type_num_list_not_in} estão presentes na lista mas não são do tipo  NumericType na tabela de input, especificado no parâmetro data_spark.\")\n",
    "\n",
    "    if type_num_list_not_in_oot != []:\n",
    "        raise ValueError(f\"A lista de features do parâmetro list_features precisam ser do tipo NumericType. As features {type_num_list_not_in_oot} estão presentes na lista mas não são do tipo  NumericType na tabela de input, especificado no parâmetro data_spark.\")\n",
    "\n",
    "    list_possible_metrics = ['ks2', 'gini', 'auc']\n",
    "    # Verifica se a métrica é válida, ignorando case sensitivity\n",
    "    metric_result_valid = [m for m in list_possible_metrics if m == metric.lower()]\n",
    "\n",
    "    # Levanta um erro se nenhuma correspondência for encontrada\n",
    "    if not metric_result_valid: \n",
    "        raise ValueError(f\"A métrica '{metric}' especificada no parâmetro 'metric' não está presente nas possibilidades: {list_possible_metrics}. \"f\"Escolha uma das opções disponíveis.\")\n",
    "\n",
    "    metric = metric.lower()\n",
    "\n",
    "    if n_trials <= 0:\n",
    "        raise ValueError(\"O valor do n_trials tem que ser maior do que 0.\")\n",
    "\n",
    "    if dev != None:\n",
    "        type_bool_columns = [col.name for col in data_spark.selectExpr(dev).schema.fields if isinstance(col.dataType, BooleanType)]\n",
    "\n",
    "        if type_bool_columns != [dev]:\n",
    "            raise ValueError(f\"A feature {dev} definida no parâmetro dev precisa ser do tipo booleano (True e False)\")\n",
    "\n",
    "\n",
    "    #marcacao dos resultados\n",
    "    results = []\n",
    "\n",
    "    #transformando data set em pandas\n",
    "    data_pandas = data_spark.toPandas()\n",
    "    data_pandas_oot = data_spark_oot.toPandas()\n",
    "\n",
    "    # dev_lgbm_exp = 'dev_lgbm_exp'\n",
    "    data_pandas['dev_lgbm_exp'] = True\n",
    "\n",
    "\n",
    "    if dev is None:\n",
    "        print(\"Não foi especificada uma coluna para treinar o processo de categorização, logo será utilizado `100%` da sua base para criar o modelo modelagem.\")\n",
    " \n",
    "    \n",
    "    data_pandas = data_pandas[data_pandas[dev] == True]\n",
    "\n",
    "    # Avaliando tamanho da amostra\n",
    "    sizedata = len(data_pandas)\n",
    "    # Validando o tamanho da amostra\n",
    "    if sizedata > max_nsample:\n",
    "        print(f\"O dataframe definido no parâmetro data_spark tem um tamanho de {sizedata}. Foi selecionada uma amostra com tamanho {max_nsample} para o processo de modelagem\")\n",
    "        \n",
    "        data_pandas = data_pandas.sample(frac=max_nsample/sizedata, random_state=42)\n",
    "\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(data_pandas[list_features], data_pandas[target], test_size=0.2, random_state=42)\n",
    "\n",
    "    X_oot = data_pandas_oot[list_features]\n",
    "    y_oot = data_pandas_oot[target]\n",
    "\n",
    "    # Otimização via Optuna com índice da iteração\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "    for i in range(1, (n_trials + 1)):\n",
    "        study.optimize(lambda trial, iteration=i: objective_express(trial, X_train, X_valid, X_oot, y_train, y_valid, y_oot, iteration, results), n_trials=1, show_progress_bar=False)\n",
    "        pass\n",
    "\n",
    "    # Melhores parâmetros\n",
    "    best_params = study.best_params\n",
    "    # print(\"Melhores parâmetros:\", best_params)\n",
    "\n",
    "    # Converter os resultados em um DataFrame para análise\n",
    "    results_df = pd.DataFrame(results)\n",
    "    # print(results_df)\n",
    "\n",
    "    plot_best_model_express(metrics_result = results_df, metric = metric)\n",
    "\n",
    "    return best_params, results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7a75ce32-b70d-4b5a-8488-343f6a089ca2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# def model_lgbm_express(data_spark, list_features, target, dev = None, n_trials = 20, metric = \"ks2\", max_nsample = 100000):\n",
    "    \n",
    "#     \"\"\"\n",
    "#     Treina e otimiza um modelo LightGBM utilizando Optuna para busca de hiperparâmetros, com suporte a métricas de avaliação como KS2, Gini e AUC.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     data_spark : pyspark.sql.DataFrame\n",
    "#         DataFrame Spark contendo os dados de entrada para o treinamento do modelo.\n",
    "    \n",
    "#     list_features : list of str\n",
    "#         Lista com os nomes das colunas que serão utilizadas como features no modelo.\n",
    "    \n",
    "#     target : str\n",
    "#         Nome da coluna alvo (variável dependente). Deve ser binária com valores 0 e 1.\n",
    "    \n",
    "#     dev : str, optional\n",
    "#         Nome da coluna de desenvolvimento (booleano), indicando as linhas que serão utilizadas no treinamento. \n",
    "#         Se não for especificada, toda a base será usada. Por padrão, `None`.\n",
    "    \n",
    "#     n_trials : int, optional\n",
    "#         Número de iterações para a otimização dos hiperparâmetros. Deve ser maior que 0. Por padrão, 20.\n",
    "    \n",
    "#     metric : str, optional\n",
    "#         Métrica utilizada para avaliar o modelo. As opções disponíveis são:\n",
    "#         - `'ks2'` (Kolmogorov-Smirnov)\n",
    "#         - `'gini'`\n",
    "#         - `'auc'` (Área sob a curva ROC)\n",
    "#         Por padrão, `'ks2'`.\n",
    "    \n",
    "#     max_nsample : int, optional\n",
    "#         Número máximo de amostras utilizadas para o treinamento. Caso o dataset tenha mais registros, será feita uma amostragem aleatória.\n",
    "#         Por padrão, 100000.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     tuple\n",
    "#         - **best_params**: dict\n",
    "#             Dicionário com os melhores hiperparâmetros encontrados pela otimização.\n",
    "#         - **results_df**: pandas.DataFrame\n",
    "#             DataFrame contendo os resultados detalhados de cada iteração da busca por hiperparâmetros.\n",
    "\n",
    "#     Raises\n",
    "#     ------\n",
    "#     ValueError\n",
    "#         - Se `list_features` contiver colunas que não estão presentes no `data_spark`.\n",
    "#         - Se o `target` não for encontrado no `data_spark`.\n",
    "#         - Se `target` não for binário com valores 0 e 1.\n",
    "#         - Se `list_features` contiver colunas que não sejam numéricas.\n",
    "#         - Se a métrica especificada em `metric` não estiver entre as opções permitidas.\n",
    "#         - Se `n_trials` for menor ou igual a 0.\n",
    "#         - Se a coluna `dev` (caso especificada) não for do tipo booleano.\n",
    "\n",
    "#     Notes\n",
    "#     -----\n",
    "#     - O processo realiza uma validação dos dados e assegura que os tipos das colunas estejam corretos antes de iniciar o treinamento.\n",
    "#     - Os resultados são apresentados por meio de um gráfico da métrica de avaliação especificada.\n",
    "#     - A otimização usa uma amostragem do dataset se o número de registros exceder o valor de `max_nsample`.\n",
    "\n",
    "#     Examples\n",
    "#     --------\n",
    "#     >>> best_params, results_df = model_lgbm_express(\n",
    "#     ...     data_spark=data_spark,\n",
    "#     ...     list_features=[\"feature1\", \"feature2\", \"feature3\"],\n",
    "#     ...     target=\"target\",\n",
    "#     ...     dev=\"is_dev\",\n",
    "#     ...     n_trials=10,\n",
    "#     ...     metric=\"gini\",\n",
    "#     ...     max_nsample=50000\n",
    "#     ... )\n",
    "#     >>> print(best_params)\n",
    "#     >>> print(results_df.head())\n",
    "#     \"\"\"\n",
    "    \n",
    "\n",
    "#     #######Validacoes#######\n",
    "#     #validando se a lista esta presente na tabela de input\n",
    "#     list_not_in = [column for column in list_features if column not in data_spark.columns]\n",
    "\n",
    "#     if list_not_in != []:\n",
    "#         raise ValueError(f\"A lista de features {list_not_in} do parâmetro list_features para o processo de modelagem não esta presente na tabela de input, especificado no parâmetro data_spark.\")\n",
    "\n",
    "#     if target not in data_spark.columns:\n",
    "#         raise ValueError(f\"A variavel {target} especificada no parâmetro target não esta presente no tabela de input, especificado no parâmetro data_spark.\")\n",
    "\n",
    "#     if dev != None:\n",
    "#         if dev not in data_spark.columns:\n",
    "#             raise ValueError(f\"A variavel {dev} especificada no parâmetro dev não esta presente no tabela de input, especificado no parâmetro data_spark.\")\n",
    "\n",
    "\n",
    "#     #validando se o target é binario\n",
    "#     target_value  = data_spark.select(target).distinct().rdd.flatMap(lambda row: row).collect()\n",
    "#     result_bool = all(value in [1, 0] for value in target_value)\n",
    "\n",
    "#     if result_bool == False:\n",
    "#         raise ValueError(f\"A variavel {target} especificada no parâmetro target possui os seguintes valores {target_value}, logo o processo binning foi desenvolvido para problemas de classificação assumindo somente valores (0,1).\")\n",
    "\n",
    "\n",
    "#     #Verificando se as colunas listadas como numericas são numericas no dataset\n",
    "#     type_num_columns = [col.name for col in data_spark.selectExpr(*list_features).schema.fields  if isinstance(col.dataType, NumericType)]\n",
    "#     #comparando lista numerica vs. lista dataset numerica\n",
    "#     type_num_list_not_in = [column for column in list_features if column not in type_num_columns]\n",
    "\n",
    "#     if type_num_list_not_in != []:\n",
    "#         raise ValueError(f\"A lista de features do parâmetro list_features precisam ser do tipo NumericType. As features {type_num_list_not_in} estão presentes na lista mas não são do tipo  NumericType na tabela de input, especificado no parâmetro data_spark.\")\n",
    "\n",
    "#     list_possible_metrics = ['ks2', 'gini', 'auc']\n",
    "#     # Verifica se a métrica é válida, ignorando case sensitivity\n",
    "#     metric_result_valid = [m for m in list_possible_metrics if m == metric.lower()]\n",
    "\n",
    "#     # Levanta um erro se nenhuma correspondência for encontrada\n",
    "#     if not metric_result_valid: \n",
    "#         raise ValueError(f\"A métrica '{metric}' especificada no parâmetro 'metric' não está presente nas possibilidades: {list_possible_metrics}. \"f\"Escolha uma das opções disponíveis.\")\n",
    "\n",
    "#     metric = metric.lower()\n",
    "\n",
    "#     if n_trials <= 0:\n",
    "#         raise ValueError(\"O valor do n_trials tem que ser maior do que 0.\")\n",
    "\n",
    "#     if dev != None:\n",
    "#         type_bool_columns = [col.name for col in data_spark.selectExpr(dev).schema.fields if isinstance(col.dataType, BooleanType)]\n",
    "\n",
    "#         if type_bool_columns != [dev]:\n",
    "#             raise ValueError(f\"A feature {dev} definida no parâmetro dev precisa ser do tipo booleano (True e False)\")\n",
    "\n",
    "\n",
    "#     #marcacao dos resultados\n",
    "#     results = []\n",
    "\n",
    "#     #transformando data set em pandas\n",
    "#     data_pandas = data_spark.toPandas()\n",
    "\n",
    "#     # dev_lgbm_exp = 'dev_lgbm_exp'\n",
    "#     data_pandas['dev_lgbm_exp'] = True\n",
    "\n",
    "\n",
    "#     if dev is None:\n",
    "#         print(\"Não foi especificada uma coluna para treinar o processo de categorização, logo será utilizado `100%` da sua base para criar o modelo modelagem.\")\n",
    " \n",
    "    \n",
    "#     data_pandas = data_pandas[data_pandas[dev] == True]\n",
    "\n",
    "#     # Avaliando tamanho da amostra\n",
    "#     sizedata = len(data_pandas)\n",
    "#     # Validando o tamanho da amostra\n",
    "#     if sizedata > max_nsample:\n",
    "#         print(f\"O dataframe definido no parâmetro data_spark tem um tamanho de {sizedata}. Foi selecionada uma amostra com tamanho {max_nsample} para o processo de modelagem\")\n",
    "        \n",
    "#         data_pandas = data_pandas.sample(frac=max_nsample/sizedata, random_state=42)\n",
    "\n",
    "\n",
    "#     X_train, X_valid, y_train, y_valid = train_test_split(data_pandas[list_features], data_pandas[target], test_size=0.2, random_state=42)\n",
    "\n",
    "#     # Otimização via Optuna com índice da iteração\n",
    "#     study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "#     for i in range(1, (n_trials + 1)):\n",
    "#         study.optimize(lambda trial, iteration=i: objective_express(trial, X_train, X_valid, y_train, y_valid, iteration, results), n_trials=1, show_progress_bar=False)\n",
    "#         pass\n",
    "\n",
    "#     # Melhores parâmetros\n",
    "#     best_params = study.best_params\n",
    "#     # print(\"Melhores parâmetros:\", best_params)\n",
    "\n",
    "#     # Converter os resultados em um DataFrame para análise\n",
    "#     results_df = pd.DataFrame(results)\n",
    "#     # print(results_df)\n",
    "\n",
    "#     plot_best_model_exp(metrics_result = results_df, metric = metric)\n",
    "\n",
    "#     return best_params, results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "968377b4-4e80-4baf-8112-9a176073a4a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ETAPA RFE\n",
    "\n",
    "# Função para realizar a seleção de features\n",
    "def feature_selection_lgb(params, data_pandas, data_pandas_oot, list_features, target, threshold = 0.95, min_diff=3):\n",
    "    \"\"\"\n",
    "    Realiza a seleção iterativa de features utilizando o LightGBM com base na importância acumulada e métricas de performance.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params : dict\n",
    "        Dicionário com os hiperparâmetros para o modelo LightGBM.\n",
    "    \n",
    "    data_pandas : pandas.DataFrame\n",
    "        DataFrame contendo os dados de entrada. Todas as colunas, exceto a coluna alvo, serão consideradas como features.\n",
    "    \n",
    "    target : str\n",
    "        Nome da coluna alvo (variável dependente). Deve ser binária com valores 0 e 1.\n",
    "    \n",
    "    threshold : float, optional\n",
    "        Limite de ganho acumulado para a seleção de features. Features com ganho acumulado abaixo deste limite serão mantidas.\n",
    "        Por padrão, 0.95 (95% do ganho acumulado).\n",
    "    \n",
    "    min_diff : int, optional\n",
    "        Número mínimo de features a serem removidas em cada iteração para continuar o processo. \n",
    "        Caso a diferença seja menor que este valor, a seleção é interrompida. Por padrão, 3.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of dict\n",
    "        Histórico das iterações, onde cada elemento é um dicionário contendo:\n",
    "        - 'iteration': número da iteração.\n",
    "        - 'lengh_features_model': quantidade de features no modelo na iteração.\n",
    "        - 'ks2_train': valor do KS (Kolmogorov-Smirnov) para o conjunto de treino.\n",
    "        - 'gini_train': valor do Gini para o conjunto de treino.\n",
    "        - 'auc_train': valor da AUC para o conjunto de treino.\n",
    "        - 'bad_decil10_train': valor da badrate dos 10% melhores scores para o conjunto de treino.\n",
    "        - 'ks2_valid': valor do KS para o conjunto de validação.\n",
    "        - 'gini_valid': valor do Gini para o conjunto de validação.\n",
    "        - 'auc_valid': valor da AUC para o conjunto de validação.\n",
    "        - 'bad_decil10_val': valor da badrate dos 10% melhores scores para o conjunto de validação.\n",
    "        - 'selected_features': lista de features selecionadas para a próxima iteração.\n",
    "        - 'removed_features': lista de features removidas na iteração.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        - Se `target` não estiver presente no `data_pandas`.\n",
    "        - Se a coluna alvo não for binária com valores 0 e 1.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - O processo utiliza o LightGBM para calcular a importância das features com base no ganho acumulado (importance_type='gain').\n",
    "    - A seleção continua até que a diferença no número de features entre iterações seja menor que `min_diff`.\n",
    "    - A validação do modelo é realizada em cada iteração com um split de 80% treino e 20% validação.\n",
    "    - As métricas KS, Gini e AUC são calculadas para os conjuntos de treino e validação.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> params = {\n",
    "    ...     'objective': 'binary',\n",
    "    ...     'metric': 'auc',\n",
    "    ...     'boosting_type': 'gbdt',\n",
    "    ...     'learning_rate': 0.01,\n",
    "    ...     'num_leaves': 31,\n",
    "    ...     'seed': 42\n",
    "    ... }\n",
    "    >>> history = feature_selection_lgb(\n",
    "    ...     params=params,\n",
    "    ...     data_pandas=data_pandas,\n",
    "    ...     target=\"target_column\",\n",
    "    ...     threshold=0.95,\n",
    "    ...     min_diff=5\n",
    "    ... )\n",
    "    >>> print(history[-1]['selected_features'])\n",
    "    \"\"\"\n",
    "\n",
    "    selected_features = data_pandas[list_features].columns.tolist()  # Começar com todas as features\n",
    "    feature_history = []\n",
    "    \n",
    "    while True:\n",
    "        X = data_pandas[selected_features]\n",
    "        y = data_pandas[target]\n",
    "\n",
    "        X_oot = data_pandas_oot[selected_features]\n",
    "        y_oot = data_pandas_oot[target]\n",
    "        \n",
    "        \n",
    "        # Dividir os dados em treino e validação\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        train_data = lgb.Dataset(X_train, label=y_train)\n",
    "        valid_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "        oot_data = lgb.Dataset(X_oot, label=y_oot)\n",
    "\n",
    "        \n",
    "        model = lgb.train(params, train_data, num_boost_round=1000, valid_sets=[valid_data],\n",
    "                          callbacks=[lgb.early_stopping(stopping_rounds=10)])\n",
    "        \n",
    "        # Calcular a importância das features\n",
    "        feature_importance = model.feature_importance(importance_type='gain')\n",
    "        # features = model.feature_name()\n",
    "\n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': selected_features,\n",
    "            'importance': feature_importance\n",
    "        })\n",
    "        \n",
    "        importance_df = importance_df.sort_values(by='importance', ascending=False)\n",
    "        \n",
    "        total_gain = importance_df['importance'].sum()\n",
    "        importance_df['cumulative_gain'] = importance_df['importance'].cumsum() / total_gain\n",
    "\n",
    "        # display(importance_df)\n",
    "        \n",
    "        # Selecionar as features com ganho acumulado até 95%\n",
    "        selected_features_next = importance_df[importance_df['cumulative_gain'] <= threshold]['feature'].tolist()\n",
    "        \n",
    "        # Identificar as features removidas\n",
    "        removed_features = list(set(selected_features) - set(selected_features_next))\n",
    "        \n",
    "        # Previsões do modelo\n",
    "        y_pred_train = model.predict(X_train, num_iteration=model.best_iteration)\n",
    "        y_pred_valid = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "        y_pred_oot = model.predict(X_oot, num_iteration=model.best_iteration)\n",
    "\n",
    "        \n",
    "        # Calcular métricas para treino\n",
    "        ks_train, gini_train, auc_train, bad_decil10_train, bad_decil30_train, bad_decil40_train = calculate_metrics(y_train.values, y_pred_train)\n",
    "\n",
    "        # Calcular métricas para validação/teste\n",
    "        ks_valid, gini_valid, auc_valid, bad_decil10_val, bad_decil30_val, bad_decil40_val = calculate_metrics(y_valid.values, y_pred_valid)\n",
    "\n",
    "        # Calcular métricas para validação/teste\n",
    "        ks_oot, gini_oot, auc_oot, bad_decil10_oot, bad_decil30_oot, bad_decil40_oot = calculate_metrics(y_oot.values, y_pred_oot)\n",
    "        \n",
    "        # Armazenar os resultados da interação\n",
    "        feature_history.append({\n",
    "            'iteration': len(feature_history) + 1,\n",
    "            'num_boost_round': model.best_iteration,\n",
    "            'lengh_features_model': len(selected_features),\n",
    "            'ks2_train': ks_train,\n",
    "            'gini_train': gini_train,\n",
    "            'auc_train': auc_train,\n",
    "            'bad_decil10_train': bad_decil10_train,\n",
    "            'bad_decil30_train': bad_decil30_train,\n",
    "            'bad_decil40_train': bad_decil40_train,\n",
    "            'ks2_valid': ks_valid,\n",
    "            'gini_valid': gini_valid,\n",
    "            'auc_valid': auc_valid,\n",
    "            'bad_decil10_val': bad_decil10_val,\n",
    "            'bad_decil30_val': bad_decil30_val,\n",
    "            'bad_decil40_val': bad_decil40_val,\n",
    "            'ks2_oot': ks_oot,\n",
    "            'gini_oot': gini_oot,\n",
    "            'auc_oot': auc_oot,\n",
    "            'bad_decil10_oot': bad_decil10_oot,\n",
    "            'bad_decil30_oot': bad_decil30_oot,\n",
    "            'bad_decil40_oot': bad_decil40_oot,\n",
    "            'selected_features': selected_features_next,\n",
    "            'removed_features': removed_features\n",
    "        })\n",
    "        \n",
    "        # Verificar se a diferença de features entre iterações é menor que 3\n",
    "        if len(selected_features) - len(selected_features_next) < min_diff:\n",
    "            break\n",
    "        \n",
    "        selected_features = selected_features_next\n",
    "\n",
    "    for result in feature_history:\n",
    "        print(f\"Iteração {result['iteration']}:\")\n",
    "        print(f\"  Quantidade de Features do Modelo nessa iteração : {result['lengh_features_model']} features\")\n",
    "        print(f\"  KS (Treino): {result['ks2_train']:.4f}\")\n",
    "        print(f\"  Gini (Treino): {result['gini_train']:.4f}\")\n",
    "        print(f\"  AUC (Treino): {result['auc_train']:.4f}\")\n",
    "        print(f\"  BadRate10Decil (Treino): {result['bad_decil10_train']:.4f}\")\n",
    "        print(f\"  BadRate30Decil (Treino): {result['bad_decil30_train']:.4f}\")\n",
    "        print(f\"  BadRate40Decil (Treino): {result['bad_decil40_train']:.4f}\")\n",
    "        print(f\"  KS (Validação): {result['ks2_valid']:.4f}\")\n",
    "        print(f\"  Gini (Validação): {result['gini_valid']:.4f}\")\n",
    "        print(f\"  AUC (Validação): {result['auc_valid']:.4f}\")\n",
    "        print(f\"  BadRate10Decil (Validação): {result['bad_decil10_val']:.4f}\")\n",
    "        print(f\"  BadRate30Decil (Validação): {result['bad_decil30_val']:.4f}\")\n",
    "        print(f\"  BadRate40Decil (Validação): {result['bad_decil40_val']:.4f}\")\n",
    "        print(f\"  KS (OOT): {result['ks2_oot']:.4f}\")\n",
    "        print(f\"  Gini (OOT): {result['gini_oot']:.4f}\")\n",
    "        print(f\"  AUC (OOT): {result['auc_oot']:.4f}\")\n",
    "        print(f\"  BadRate10Decil (OOT): {result['bad_decil10_oot']:.4f}\")\n",
    "        print(f\"  BadRate30Decil (OOT): {result['bad_decil30_oot']:.4f}\")\n",
    "        print(f\"  BadRate40Decil (OOT): {result['bad_decil40_oot']:.4f}\")\n",
    "        print(f\"  Selecionadas Prox. Iteração: {len(result['selected_features'])} features\")\n",
    "        print(f\"  Removidas Prox. Iteração: {len(result['removed_features'])} features\")\n",
    "        print(f\"  Nome das Features Selecionadas Prox. Iteração: {result['selected_features']}\")\n",
    "        print(f\"  Nome das Features Removidas Prox. Iteração: {result['removed_features']}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    \n",
    "    return feature_history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c081678f-5528-4f5e-adaf-bfd5f78211c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_interactive_metric(feature_history, metric = \"ks2\"):\n",
    "    \"\"\"\n",
    "    Plota um gráfico interativo de KS por iteração usando Plotly,\n",
    "    exibindo a quantidade de features ao posicionar o mouse nos pontos.\n",
    "\n",
    "    Args:\n",
    "        feature_history (list): Lista de dicionários contendo os resultados de cada iteração.\n",
    "    \"\"\"\n",
    "    # Extrair dados\n",
    "    iterations = [result['iteration'] for result in feature_history]\n",
    "    ks_train = [result[f'{metric}_train'] * 100 for result in feature_history]  # Converter para porcentagem\n",
    "    ks_valid = [result[f'{metric}_valid'] * 100 for result in feature_history]  # Converter para porcentagem\n",
    "    ks_oot = [result[f'{metric}_oot'] * 100 for result in feature_history]  # Converter para porcentagem\n",
    "\n",
    "\n",
    "    num_features = [(result['lengh_features_model']) for result in feature_history]\n",
    "\n",
    "    bad_decil10_train = [result['bad_decil10_train'] * 100 for result in feature_history]  # Converter para porcentagem\n",
    "    bad_decil30_train = [result['bad_decil30_train'] * 100 for result in feature_history]  # Converter para porcentagem\n",
    "    bad_decil40_train = [result['bad_decil40_train'] * 100 for result in feature_history]  # Converter para porcentagem\n",
    "\n",
    "\n",
    "    bad_decil10_val = [result['bad_decil10_val'] * 100 for result in feature_history]  # Converter para porcentagem\n",
    "    bad_decil30_val = [result['bad_decil30_val'] * 100 for result in feature_history]  # Converter para porcentagem\n",
    "    bad_decil40_val = [result['bad_decil40_val'] * 100 for result in feature_history]  # Converter para porcentagem\n",
    "\n",
    "\n",
    "    bad_decil10_oot = [result['bad_decil10_oot'] * 100 for result in feature_history]  # Converter para porcentagem\n",
    "    bad_decil30_oot = [result['bad_decil30_oot'] * 100 for result in feature_history]  # Converter para porcentagem\n",
    "    bad_decil40_oot = [result['bad_decil40_oot'] * 100 for result in feature_history]  # Converter para porcentagem\n",
    "\n",
    "\n",
    "    # Criar o gráfico\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Adicionar linha KS Treino\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=iterations,\n",
    "        y=ks_train,\n",
    "        mode='lines+markers',\n",
    "        name=f'{metric.upper()} Treino',\n",
    "        marker=dict(size=10, color='blue'),\n",
    "        line=dict(width=2, color='blue'),\n",
    "        hoverinfo='text',\n",
    "        text=[f'Iteração: {i}<br>{metric} Treino: {ks:.0f}%<br>Features: {n}<br>BadTopTrain10%: {top10:.2f}%<br>BadTopTrain30%: {top30:.2f}%<br>BadTopTrain40%: {top40:.2f}%' for i, ks, n, top10, top30, top40 in zip(iterations, ks_train, num_features, bad_decil10_train, bad_decil30_train, bad_decil40_train)]\n",
    "    ))\n",
    "\n",
    "    # Adicionar linha KS Validação\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=iterations,\n",
    "        y=ks_valid,\n",
    "        mode='lines+markers',\n",
    "        name=f'{metric.upper()} Validação',\n",
    "        marker=dict(size=10, color='green'),\n",
    "        line=dict(width=2, color='green'),\n",
    "        hoverinfo='text',\n",
    "        text=[f'Iteração: {i}<br>{metric} Validação: {ks:.0f}%<br>Features: {n}<br>BadTopVal10%: {top10:.2f}%<br>BadTopVal30%: {top30:.2f}%<br>BadTopVal40%: {top40:.2f}%' for i, ks, n, top10, top30, top40 in zip(iterations, ks_train, num_features, bad_decil10_val, bad_decil30_val, bad_decil40_val)]\n",
    "    ))\n",
    "\n",
    "    # Adicionar linha KS OOT\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=iterations,\n",
    "        y=ks_oot,\n",
    "        mode='lines+markers',\n",
    "        name=f'{metric.upper()} OOT',\n",
    "        marker=dict(size=10, color='red'),\n",
    "        line=dict(width=2, color='red'),\n",
    "        hoverinfo='text',\n",
    "        text=[f'Iteração: {i}<br>{metric} OOT: {ks:.0f}%<br>Features: {n}<br>BadTopOOT10%: {top10:.2f}%<br>BadTopOOT30%: {top30:.2f}%<br>BadTopOOT40%: {top40:.2f}%' for i, ks, n, top10, top30, top40 in zip(iterations, ks_train, num_features, bad_decil10_oot, bad_decil30_oot, bad_decil40_oot)]\n",
    "        # text=[f'Iteração: {i}<br>{metric} OOT: {ks:.0f}%<br>Features: {n}<br>BadTopVal10%: {top10:.2f}%' for i, ks, n, top10 in zip(iterations, ks_oot, num_features, bad_decil10_oot)]\n",
    "    ))\n",
    "\n",
    "\n",
    "    # Configurar layout do gráfico\n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text=f'Evolução do {metric.upper()} por Iteração',\n",
    "            x=0.5,  # Centraliza o título no eixo X\n",
    "            xanchor='center',\n",
    "            font=dict(size=20, color='black')\n",
    "        ),\n",
    "        xaxis=dict(\n",
    "            title='Interações',\n",
    "            tickmode='linear',\n",
    "            showgrid=False,  # Remove a grade no eixo X\n",
    "            zeroline=False   # Remove a linha zero\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=f'{metric.upper()} (%)',\n",
    "            tickformat=',.0f',  # Formata os valores do eixo Y como números inteiros\n",
    "            showgrid=False,  # Remove a grade no eixo Y\n",
    "            zeroline=False   # Remove a linha zero\n",
    "        ),\n",
    "        template='plotly_white',\n",
    "        plot_bgcolor='rgba(0,0,0,0)',  # Fundo transparente\n",
    "        paper_bgcolor='white',  # Fundo do papel branco\n",
    "        legend=dict(\n",
    "            orientation=\"h\",  # Legenda na horizontal\n",
    "            yanchor=\"bottom\",\n",
    "            y=1.02,  # Posiciona a legenda acima do gráfico\n",
    "            xanchor=\"center\",\n",
    "            x=0.5,  # Centraliza a legenda\n",
    "            font=dict(size=12)\n",
    "        ),\n",
    "        hovermode='x unified',\n",
    "        font=dict(size=14)\n",
    "    )\n",
    "\n",
    "    # Exibir gráfico\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e3459f2c-bb3b-4c98-bf70-cb8bf167fe28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def fs_rfe_lgbm(data_spark, data_spark_oot, list_features, target, params, dev = None, threshold = 0.98, min_diff = 3, metric = \"ks2\", max_nsample = 100000):\n",
    "    \n",
    "    \"\"\"\n",
    "    Realiza a seleção iterativa de features utilizando o LightGBM em um conjunto de dados Spark,\n",
    "    com base em métricas de importância acumulada e desempenho do modelo.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_spark : pyspark.sql.DataFrame\n",
    "        DataFrame do Spark contendo os dados de entrada.\n",
    "    \n",
    "    list_features : list of str\n",
    "        Lista das colunas que serão utilizadas como features para o modelo.\n",
    "    \n",
    "    target : str\n",
    "        Nome da coluna alvo (variável dependente). Deve ser binária, contendo apenas os valores 0 e 1.\n",
    "    \n",
    "    params : dict\n",
    "        Dicionário contendo os hiperparâmetros para o modelo LightGBM.\n",
    "    \n",
    "    dev : str, optional\n",
    "        Nome da coluna utilizada para indicar os dados de treino/validação. Deve ser do tipo booleano. \n",
    "        Se não especificado, todo o conjunto será usado. Por padrão, None.\n",
    "    \n",
    "    threshold : float, optional\n",
    "        Limite do ganho acumulado para a seleção de features. Features com ganho acumulado abaixo deste valor serão mantidas.\n",
    "        Valor padrão é 0.98 (98% do ganho acumulado).\n",
    "    \n",
    "    min_diff : int, optional\n",
    "        Número mínimo de features a serem removidas em cada iteração. \n",
    "        O processo para quando a diferença é menor que este valor. Por padrão, 3.\n",
    "    \n",
    "    metric : str, optional\n",
    "        Métrica de avaliação utilizada para o processo interativo. Opções disponíveis: 'ks2', 'gini', 'auc'. \n",
    "        Valor padrão é 'ks2'.\n",
    "\n",
    "    max_nsample : int, optional\n",
    "        Número máximo de amostras a serem utilizadas para o processo de modelagem. \n",
    "        Se o conjunto de dados exceder este limite, será realizada uma amostragem. Por padrão, 100000.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of dict\n",
    "        Histórico das iterações de seleção de features, contendo para cada iteração:\n",
    "        - 'iteration': número da iteração.\n",
    "        - 'lengh_features_model': quantidade de features no modelo na iteração.\n",
    "        - 'ks2_train': KS (Kolmogorov-Smirnov) no conjunto de treino.\n",
    "        - 'gini_train': Gini no conjunto de treino.\n",
    "        - 'auc_train': AUC no conjunto de treino.\n",
    "        - 'ks2_valid': KS no conjunto de validação.\n",
    "        - 'gini_valid': Gini no conjunto de validação.\n",
    "        - 'auc_valid': AUC no conjunto de validação.\n",
    "        - 'selected_features': lista de features selecionadas para a próxima iteração.\n",
    "        - 'removed_features': lista de features removidas na iteração.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        - Se `list_features` ou `target` não estiverem presentes em `data_spark`.\n",
    "        - Se `target` não for binária com valores 0 e 1.\n",
    "        - Se alguma feature em `list_features` não for numérica.\n",
    "        - Se `metric` não for uma das opções válidas ('ks2', 'gini', 'auc').\n",
    "        - Se `threshold` estiver fora do intervalo (0, 1].\n",
    "        - Se `min_diff` for menor que 2.\n",
    "        - Se `dev` for especificada e não for do tipo booleano.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - O conjunto de dados Spark é convertido para Pandas antes do processamento.\n",
    "    - Caso o número de amostras no conjunto de dados exceda `max_nsample`, é realizada uma amostragem com uma fração proporcional.\n",
    "    - O processo utiliza a função `feature_selection_lgb` para realizar a seleção iterativa de features e o LightGBM para calcular a importância das features.\n",
    "    - A métrica selecionada é utilizada para avaliar as iterações de seleção de features.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> params = {\n",
    "    ...     'objective': 'binary',\n",
    "    ...     'metric': 'auc',\n",
    "    ...     'boosting_type': 'gbdt',\n",
    "    ...     'learning_rate': 0.01,\n",
    "    ...     'num_leaves': 31,\n",
    "    ...     'seed': 42\n",
    "    ... }\n",
    "    >>> history = fs_rfe_lgbm(\n",
    "    ...     data_spark=data_spark,\n",
    "    ...     list_features=['feature1', 'feature2', 'feature3'],\n",
    "    ...     target='target_column',\n",
    "    ...     params=params,\n",
    "    ...     dev='dev_column',\n",
    "    ...     threshold=0.95,\n",
    "    ...     min_diff=3,\n",
    "    ...     metric='gini',\n",
    "    ...     max_nsample=50000\n",
    "    ... )\n",
    "    >>> print(history[-1]['selected_features'])\n",
    "    \"\"\"\n",
    "\n",
    "    #######Validacoes#######\n",
    "    #validando se a lista esta presente na tabela de input\n",
    "    list_not_in = [column for column in list_features if column not in data_spark.columns]\n",
    "    \n",
    "    list_not_in_oot = [column for column in list_features if column not in data_spark_oot.columns]\n",
    "\n",
    "\n",
    "    if list_not_in != []:\n",
    "        raise ValueError(f\"A lista de features {list_not_in} do parâmetro list_features para o processo de modelagem não esta presente na tabela de input, especificado no parâmetro data_spark.\")\n",
    "\n",
    "    if list_not_in_oot != []:\n",
    "        raise ValueError(f\"A lista de features {list_not_in_oot} do parâmetro list_features para o processo de modelagem não esta presente na tabela de input, especificado no parâmetro data_spark_oot.\")\n",
    "\n",
    "    if target not in data_spark.columns:\n",
    "        raise ValueError(f\"A variavel {target} especificada no parâmetro target não esta presente no tabela de input, especificado no parâmetro data_spark.\")\n",
    "\n",
    "    if target not in data_spark_oot.columns:\n",
    "        raise ValueError(f\"A variavel {target} especificada no parâmetro target não esta presente no tabela de input, especificado no parâmetro data_spark_oot.\")\n",
    "\n",
    "\n",
    "\n",
    "    #validando se o target é binario\n",
    "    target_value  = data_spark.select(target).distinct().rdd.flatMap(lambda row: row).collect()\n",
    "    result_bool = all(value in [1, 0] for value in target_value)\n",
    "\n",
    "    target_value_oot  = data_spark_oot.select(target).distinct().rdd.flatMap(lambda row: row).collect()\n",
    "    result_bool_oot = all(value in [1, 0] for value in target_value_oot)\n",
    "\n",
    "    if result_bool == False:\n",
    "        raise ValueError(f\"A variavel {target} especificada no parâmetro target presente no parametro data_spark_oot possui os seguintes valores {target_value}, logo o processo de modelagem foi desenvolvido para problemas de classificação assumindo somente valores (0,1).\")\n",
    "\n",
    "    if result_bool_oot == False:\n",
    "        raise ValueError(f\"A variavel {target} especificada no parâmetro target presente no parametro data_spark_oot possui os seguintes valores {target_value}, logo o processo modelagem foi desenvolvido para problemas de classificação assumindo somente valores (0,1).\")\n",
    "\n",
    "\n",
    "    #Verificando se as colunas listadas como numericas são numericas no dataset\n",
    "    type_num_columns = [col.name for col in data_spark.selectExpr(*list_features).schema.fields  if isinstance(col.dataType, NumericType)]\n",
    "\n",
    "    type_num_columns_oot = [col.name for col in data_spark_oot.selectExpr(*list_features).schema.fields  if isinstance(col.dataType, NumericType)]\n",
    "\n",
    "\n",
    "    #comparando lista numerica vs. lista dataset numerica\n",
    "    type_num_list_not_in = [column for column in list_features if column not in type_num_columns]\n",
    "\n",
    "    type_num_list_not_in_oot = [column for column in list_features if column not in type_num_columns_oot]\n",
    "\n",
    "    if type_num_list_not_in != []:\n",
    "        raise ValueError(f\"A lista de features do parâmetro list_features precisam ser do tipo NumericType. As features {type_num_list_not_in} estão presentes na lista mas não são do tipo  NumericType na tabela de input, especificado no parâmetro data_spark.\")\n",
    "\n",
    "    if type_num_list_not_in_oot != []:\n",
    "        raise ValueError(f\"A lista de features do parâmetro list_features precisam ser do tipo NumericType. As features {type_num_list_not_in_oot} estão presentes na lista mas não são do tipo  NumericType na tabela de input, especificado no parâmetro data_spark_oot.\")\n",
    "\n",
    "    list_possible_metrics = ['ks2', 'gini', 'auc']\n",
    "    # Verifica se a métrica é válida, ignorando case sensitivity\n",
    "    metric_result_valid = [m for m in list_possible_metrics if m == metric.lower()]\n",
    "\n",
    "    # Levanta um erro se nenhuma correspondência for encontrada\n",
    "    if not metric_result_valid: \n",
    "        raise ValueError(f\"A métrica '{metric}' especificada no parâmetro 'metric' não está presente nas possibilidades: {list_possible_metrics}. \"f\"Escolha uma das opções disponíveis.\")\n",
    "\n",
    "    metric = metric.lower()\n",
    "\n",
    "    if threshold <= 0 or threshold > 1:\n",
    "        raise ValueError(\"O valor do threshold tem que ser maior do que 0 e menor do que 1.\")\n",
    "\n",
    "    if dev != None:\n",
    "        type_bool_columns = [col.name for col in data_spark.selectExpr(dev).schema.fields if isinstance(col.dataType, BooleanType)]\n",
    "\n",
    "        if type_bool_columns != [dev]:\n",
    "            raise ValueError(f\"A feature {dev} definida no parâmetro dev precisa ser do tipo booleano (True e False)\")\n",
    "\n",
    "    if min_diff < 2:\n",
    "        raise ValueError(\"O valor do min_diff tem que ser maior do que 1\")\n",
    "\n",
    "    \n",
    "    data_pandas = data_spark.toPandas()\n",
    "    data_pandas_oot = data_spark_oot.toPandas()\n",
    "\n",
    "\n",
    "    data_pandas['dev_lgbm_exp'] = True\n",
    "\n",
    "    if dev is None:\n",
    "        print(\"Não foi especificada uma coluna para treinar o modelo, logo será utilizado `100%` da sua base o desenvolvimento.\")\n",
    "        dev = 'dev_lgbm_exp'\n",
    "\n",
    "    \n",
    "    data_pandas = data_pandas[data_pandas[dev] == True]\n",
    "\n",
    "    # Avaliando tamanho da amostra\n",
    "    sizedata = len(data_pandas)\n",
    "    # Validando o tamanho da amostra\n",
    "    if sizedata > max_nsample:\n",
    "        print(f\"O dataframe definido no parâmetro data_spark tem um tamanho de {sizedata}. Foi selecionada uma amostra com tamanho {max_nsample} para o processo de modelagem\")\n",
    "        \n",
    "        data_pandas = data_pandas.sample(frac=max_nsample/sizedata, random_state=42)\n",
    "\n",
    "\n",
    "    feature_history = feature_selection_lgb(data_pandas = data_pandas, data_pandas_oot = data_pandas_oot, list_features= list_features, params = params, target = target, threshold = threshold, min_diff = min_diff)\n",
    "\n",
    "    plot_interactive_metric(feature_history, metric = metric)\n",
    "\n",
    "    return feature_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f09d4d5-5a00-447d-9d62-6e052dc83c15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Validação Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91acf2d9-f375-48cf-baa6-382cd928fd01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def graph_feature_importance(run_model, n_features = None, metric = \"gain\"):\n",
    "   \n",
    "    \"\"\"\n",
    "    Gera um gráfico de barras com a importância das features de um modelo LightGBM treinado.\n",
    "\n",
    "    Args:\n",
    "        run_model (str): Caminho do modelo registrado no MLflow.\n",
    "        n_features (int, opcional): Número de features a serem exibidas no gráfico. Exibe todas se for None.\n",
    "        metric (str, opcional): Tipo de importância das features ('gain' ou 'split'). O valor default é 'gain'.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame contendo as importâncias das features em porcentagem.\n",
    "\n",
    "    Example:\n",
    "        >>> df_importance = graph_feature_importance(run_model='1834hdajdafh1h1383141h41l4ndfoa1'', n_features=10,\n",
    "        metric='gain')\n",
    "    \"\"\"\n",
    "\n",
    "    logged_model = f'runs:/{run_model}/model'\n",
    "\n",
    "    lgb_model = mlflow.lightgbm.load_model(logged_model)\n",
    "\n",
    "    # Obter a importância das features usando 'gain' ou 'split'\n",
    "    feature_importances = lgb_model.feature_importance(importance_type=metric)  # gain ou 'split'\n",
    "    features = lgb_model.feature_name()\n",
    "\n",
    "    if n_features is None:\n",
    "       n_features = len(features)\n",
    "    \n",
    "    # Converter as importâncias para porcentagem\n",
    "    total_importance = sum(feature_importances)\n",
    "    feature_importances_percent = [(imp / total_importance).round(4) for imp in feature_importances]\n",
    "    # Criar DataFrame com as importâncias em porcentagem\n",
    "    importance_df = pd.DataFrame({\n",
    "                'Feature': features,\n",
    "                f'{metric}': feature_importances,\n",
    "                'Importance (%)': feature_importances_percent\n",
    "    })\n",
    "    importance_df = importance_df.sort_values(by='Importance (%)', ascending=False)\n",
    "    \n",
    "    importance_df['gain_acm'] = importance_df['Importance (%)'].cumsum().round(4)\n",
    "    # Plotar o gráfico de barras com as importâncias em porcentagem\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.barh(importance_df['Feature'][:n_features], importance_df['Importance (%)'][:n_features], color='#238662')\n",
    "    plt.xlabel(\"Feature Importance (%)\", fontsize=14)\n",
    "    plt.ylabel(\"Feature\", fontsize=14)\n",
    "    plt.title(f'Top {n_features} Most Important Features (Percentage)', fontsize=16)\n",
    "    plt.gca().invert_yaxis()  # Inverter eixo y para mostrar as features mais importantes no topo\n",
    "    plt.show()\n",
    "    return importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f50a7606-fba3-4c5e-a499-97899ccd0cd8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def graph_shap_value(data_spark , run_model):\n",
    "\n",
    "    \"\"\"\n",
    "    Gera um gráfico SHAP dos valores SHAP calculados para um modelo LightGBM treinado.\n",
    "\n",
    "    Args:\n",
    "        data_spark (DataFrame): DataFrame Spark contendo os dados de entrada.\n",
    "        run_model (str): Caminho do modelo registrado no MLflow.\n",
    "\n",
    "    Example:\n",
    "        >>> graph_shap_value(data_spark=df_spark, run_model='1834hdajdafh1h1383141h41l4ndfoa1')\n",
    "    \"\"\"\n",
    "\n",
    "    logged_model = f'runs:/{run_model}/model'\n",
    "    \n",
    "    #transformando pandas\n",
    "    data_pandas = data_spark.toPandas()\n",
    "    #carregando modelo\n",
    "    model_shap = mlflow.lightgbm.load_model(logged_model)\n",
    "    #listando variaveis do modelo\n",
    "    features = model_shap.feature_name()\n",
    "    #selecionando base para calculo\n",
    "    X_DEV = data_pandas.loc[:, features]\n",
    "    #calculo shap\n",
    "    shap_values = shap.TreeExplainer(model_shap).shap_values(X_DEV)\n",
    "    #plot shap\n",
    "    shap.summary_plot(shap_values, \n",
    "                  X_DEV, \n",
    "                  show = True,\n",
    "                  plot_type='violin',\n",
    "                  # plot_type='bar',\n",
    "                  plot_size = [15,7],\n",
    "                  max_display=X_DEV.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f5f8915-3727-4b29-84b5-97ccfc2ba8ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Salvar Artefatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "809da6de-5341-4756-83d1-53d0926a273f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def save_artefact_mlflow(data_spark, model_object, path_save_artefact, artefact_name):\n",
    "\n",
    "    \"\"\"\n",
    "    Salva um artefato de modelo no MLflow (GLM e Binning, Woe Process).\n",
    "\n",
    "    Args:\n",
    "        data_spark (DataFrame): DataFrame Spark contendo os dados de entrada.\n",
    "        model_object (object): Objeto do modelo a ser salvo.\n",
    "        path_save_artefact (str): Caminho para salvar o artefato.\n",
    "        artefact_name (str): Nome do artefato.\n",
    "\n",
    "    Example:\n",
    "        >>> save_artefact_mlflow(data_spark=df_spark, model_object=model, path_save_artefact='my_experiment', artefact_name='my_model')\n",
    "\n",
    "    Returns:\n",
    "            print(\"Seu objeto foi salvo como:\", f\"{experiment_id}/runs/{run_id}\") em que run_id é o código de\n",
    "            identicação do seu modelo.\n",
    "    \"\"\"\n",
    "\n",
    "    mlflow.set_experiment(f'{path_save_artefact}/{artefact_name}')\n",
    "\n",
    "    with mlflow.start_run() as run:\n",
    "        signature = infer_signature(data_spark)  \n",
    "        mlflow.sklearn.log_model(model_object, 'model', signature=signature)\n",
    "\n",
    "        run_id = run.info.run_id\n",
    "        experiment_id = run.info.experiment_id\n",
    "        \n",
    "    print(\"Seu objeto foi salvo como:\", f\"{experiment_id}/runs/{run_id}\")\n",
    "\n",
    "\n",
    "def load_artefact_mlflow(run_id):\n",
    "\n",
    "    \"\"\"\n",
    "    Carrega um artefato de modelo do MLflow (GLM e Binning, Woe Process).\n",
    "\n",
    "    Args:\n",
    "        run_id (str): ID da execução do MLflow.\n",
    "\n",
    "    Returns:\n",
    "        object: Objeto do modelo carregado.\n",
    "\n",
    "    Example:\n",
    "        >>> model = load_artefact_mlflow(run_id='12345')\n",
    "    \"\"\"\n",
    "    logged_model = f\"runs:/{run_id}/model\"\n",
    "\n",
    "    # Load model\n",
    "    return mlflow.sklearn.load_model(logged_model)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Funcoes_Credito_Teste",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}