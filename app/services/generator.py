import os
import json
import time
import google.generativeai as genai
from dotenv import load_dotenv
from app.models import ModelingRequest
from app.services.knowledge_loader import load_reference_cells
from google.api_core import exceptions

load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")
genai.configure(api_key=api_key)

def create_cell(source, cell_type="code"):
    return {
        "cell_type": cell_type,
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": source.splitlines(keepends=True)
    }

def generate_notebook_json(params: ModelingRequest) -> str:
    print("1. Lendo 'Manual de Instru√ß√µes' das fun√ß√µes...")
    # O Agente l√™ o arquivo local para APRENDER a usar as fun√ß√µes, n√£o para copiar.
    reference_context = load_reference_cells()
    
    # Modelo Lite (R√°pido e eficiente)
    model_name = 'models/gemini-2.0-flash-lite-preview-02-05'
    model = genai.GenerativeModel(model_name)
    
    # Prompt focado em AN√ÅLISE e EXECU√á√ÉO
    prompt = f"""
    ATUE COMO: Lead Data Scientist Especialista em Cr√©dito.
    OBJETIVO: Escrever o c√≥digo de EXECU√á√ÉO E AN√ÅLISE para um notebook Databricks.
    
    ### CEN√ÅRIO
    Todas as fun√ß√µes complexas (feature selection, binning, modelagem, m√©tricas) J√Å EXISTEM e ser√£o carregadas na mem√≥ria via comando m√°gico %run.
    N√ÉO redefina as fun√ß√µes. O seu trabalho √© US√Å-LAS para criar uma an√°lise completa.

    ### SUA BIBLIOTECA DE FERRAMENTAS (Apenas para consulta de uso):
    {reference_context}
    (Consulte acima: nomes dos par√¢metros e o que cada fun√ß√£o retorna para usar corretamente).

    ### DADOS DO PROJETO ATUAL:
    - Tabela Input: "{params.table_path}"
    - Target: "{params.target_column}"
    - Features: {params.features_text}
    - M√©trica de Sucesso: "{params.metric}"

    ### TAREFA: Gerar o Script de Execu√ß√£o (Python)
    Escreva um script Python longo e detalhado que fa√ßa o seguinte fluxo:

    1. Configura√ß√£o: Defina vari√°veis globais (TABLE_PATH, TARGET, FEATURES, METRIC).
    2. Leitura: Carregue os dados (spark.read.parquet). Se n√£o houver coluna 'dev', crie um split aleat√≥rio.
    3. Feature Engineering (Com An√°lise):
       - Chame `features_binning_process`.
       - Use `display()` nos dataframes retornados para mostrar a qualidade dos bins.
       - Chame `fs_iv` para calcular Information Value. D√™ `display()` na tabela de IV.
       - Chame `autoEliminateMulticollinearityHybrid`. Mostre a matriz de correla√ß√£o final.
    4. Modelagem (AutoML):
       - Chame a fun√ß√£o `main` (que roda o Optuna). Passe os dataframes processados.
       - D√™ `display()` no dataframe de resultados do Optuna, ordenado pela m√©trica escolhida.
    5. Visualiza√ß√£o Final:
       - Chame `plot_best_model_express` para gerar os gr√°ficos de performance (KS/AUC).
       - Chame `graph_feature_importance` e `graph_shap_value` usando o ID do melhor modelo (pegue do MLflow ou do retorno da fun√ß√£o main).

    ### REGRAS DE OURO:
    - Use `display(df)` do Databricks para TODAS as tabelas intermedi√°rias.
    - Adicione coment√°rios explicativos no c√≥digo (# Explicando o insight).
    - N√ÉO inclua blocos markdown (```python), apenas o c√≥digo puro.
    """

    print("2. Solicitando ao Gemini o Pipeline Anal√≠tico...")
    
    execution_content = ""
    max_retries = 3
    
    for attempt in range(max_retries):
        try:
            response = model.generate_content(prompt)
            execution_content = response.text.replace("```python", "").replace("```", "").strip()
            break
        except Exception as e:
            print(f"Tentativa {attempt+1} falhou: {e}")
            if attempt == max_retries - 1: raise ValueError(f"Erro na IA: {e}")
            time.sleep(5)

    notebook_cells = []

    notebook_cells.append(create_cell(f"# üìä Relat√≥rio de Modelagem Autom√°tica: {params.target_column}\nNotebook gerado por IA. Foco em an√°lise e interpretabilidade.", "markdown"))

    notebook_cells.append(create_cell("# Instala√ß√£o das bibliotecas necess√°rias\n%pip install --upgrade optbinning tqdm mlflow==2.11.2 shap optuna optuna-integration xgboost catboost scikit-learn\ndbutils.library.restartPython()", "code"))

    notebook_cells.append(create_cell(f"# üß† Carregando Base de Conhecimento (Fun√ß√µes de Cr√©dito)\n# Certifique-se que este caminho existe no seu Workspace\n%run \"{params.run_path}\"", "code"))

    notebook_cells.append(create_cell("# Imports locais para an√°lise\nimport pandas as pd\nimport numpy as np\nfrom pyspark.sql import functions as f\nimport mlflow", "code"))

    notebook_cells.append(create_cell("## üöÄ Execu√ß√£o do Pipeline Anal√≠tico", "markdown"))
    notebook_cells.append(create_cell(execution_content, "code"))

    notebook_cells.append(create_cell("# Fim da Execu√ß√£o. Verifique os artefatos no MLflow.", "markdown"))

    notebook_json = {
        "cells": notebook_cells,
        "metadata": {
            "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
            "language_info": {"name": "python", "version": "3.10"}
        },
        "nbformat": 4,
        "nbformat_minor": 4
    }
    
    return json.dumps(notebook_json, indent=2)